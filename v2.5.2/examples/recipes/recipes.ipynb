{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recipe Ingredients"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following simple example shows how to train a hierarchical model for predicting the\n",
    "type of cuisine from a set of used ingredients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The full environment, the script and the data are accessible [here](https://github.com/CTUAvastLab/JsonGrinder.jl/tree/master/docs/src/examples/recipes)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by activating the environment and installing required packages"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Activating project at `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/src/examples/recipes`\n",
      "Status `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/src/examples/recipes/Project.toml`\n",
      "  [587475ba] Flux v0.14.20\n",
      "  [0f8b85d8] JSON3 v1.14.0\n",
      "  [d201646e] JsonGrinder v2.5.2\n",
      "  [f1d291b0] MLUtils v0.4.4\n",
      "  [1d0525e4] Mill v2.10.5\n",
      "  [0b1bfda6] OneHotArrays v0.2.5\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We recommend to first read the [Mutagenesis](https://github.com/CTUAvastLab/JsonGrinder.jl/tree/master/docs/src/examples/mutagenesis) example,\n",
    "which introduces core concepts. This example shows application on another dataset and\n",
    "integration with [`JSON3.jl`](https://github.com/quinnj/JSON3.jl)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load all dependencies and fix the seed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JsonGrinder, Mill, Flux, OneHotArrays, JSON3, MLUtils, Statistics\n",
    "\n",
    "using Random; Random.seed!(42);"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "The full dataset and the problem description can be also found on [Kaggle](https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home), but for demonstration purposes we load only its small subset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "JSON3.Object{Base.CodeUnits{UInt8, String}, Vector{UInt64}} with 3 entries:\n  :id          => 7950\n  :ingredients => [\"large egg whites\", \"brown rice\", \"all-purpose flour\", \"larg…\n  :cuisine     => \"korean\""
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "dataset = JSON3.read.(readlines(\"recipes.jsonl\"));\n",
    "shuffle!(dataset);\n",
    "jss_train, jss_test = dataset[1:2000], dataset[2001:end];\n",
    "jss_train[1]"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Labels are stored in the `\"cuisine\"` field:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2000-element Vector{String}:\n \"korean\"\n \"chinese\"\n \"italian\"\n \"korean\"\n \"japanese\"\n \"italian\"\n \"korean\"\n \"mexican\"\n \"french\"\n \"chinese\"\n ⋮\n \"italian\"\n \"indian\"\n \"french\"\n \"mexican\"\n \"chinese\"\n \"chinese\"\n \"indian\"\n \"jamaican\"\n \"jamaican\""
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "y_train = getindex.(jss_train, \"cuisine\");\n",
    "y_test = getindex.(jss_test, \"cuisine\");\n",
    "y_train"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example we have more classes than two, so we also encode all training labels into one-hot vectors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20-element Vector{String}:\n \"korean\"\n \"chinese\"\n \"italian\"\n \"japanese\"\n \"mexican\"\n \"french\"\n \"greek\"\n \"british\"\n \"indian\"\n \"thai\"\n \"southern_us\"\n \"russian\"\n \"moroccan\"\n \"vietnamese\"\n \"brazilian\"\n \"jamaican\"\n \"cajun_creole\"\n \"spanish\"\n \"irish\"\n \"filipino\""
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "classes = unique(y_train)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20×2000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n 1  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1     ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  …  ⋅  1  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  1\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "y_train_oh = onehotbatch(y_train, classes)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create a schema:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mDictEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ├────── cuisine: \u001b[39m\u001b[39mLeafEntry (20 unique `String` values)\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ├─────────── id: \u001b[39m\u001b[39mLeafEntry (2000 unique `Real` values)\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ╰── ingredients: \u001b[39m\u001b[31mArrayEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  ╰── \u001b[39m\u001b[39mLeafEntry (2471 unique `String` values)\u001b[90m\u001b[3m 21632x update \u001b[23m\u001b[39m\u001b[90m⋯\u001b[39m"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = schema(jss_train)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function `schema` accepts an optional argument, a function first mapping all elements of\n",
    "an input array. We could thus reduce the schema creation into a single command\n",
    "`schema(JSON3.read, readlines(\"recipes.jsonl\"))`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the schema, we will delete the `\"cuisine\"` key storing the label, and also the `\"id\"` key,\n",
    "which is just the id of the sample, which is not useful in training:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mDictEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ╰── ingredients: \u001b[39m\u001b[31mArrayEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  ╰── \u001b[39m\u001b[39mLeafEntry (2471 unique `String` values)\u001b[90m\u001b[3m 21632x update \u001b[23m\u001b[39m\u001b[90m⋯\u001b[39m"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "delete!(sch.children, :cuisine);\n",
    "delete!(sch.children, :id);\n",
    "sch"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that only a single key `\"ingredients\"` is left. We can thus just take its content:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "13-element JSON3.Array{String, Base.CodeUnits{UInt8, String}, SubArray{UInt64, 1, Vector{UInt64}, Tuple{UnitRange{Int64}}, true}}:\n \"large egg whites\"\n \"brown rice\"\n \"all-purpose flour\"\n \"large eggs\"\n \"top sirloin steak\"\n \"garlic cloves\"\n \"low sodium soy sauce\"\n \"green onions\"\n \"rice vinegar\"\n \"canola oil\"\n \"sesame seeds\"\n \"sesame oil\"\n \"dark sesame oil\""
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "jss_train = getindex.(jss_train, \"ingredients\");\n",
    "jss_test = getindex.(jss_test, \"ingredients\");\n",
    "jss_train[1]"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can infer the schema again, or just take a subtree of the original schema"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can just take the only subtree of the original schema `sch`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mArrayEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ╰── \u001b[39m\u001b[39mLeafEntry (2471 unique `String` values)\u001b[90m\u001b[3m 21632x updated\u001b[23m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "sch[:ingredients]"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or infer it once again, this time `jss_train` is not a `Vector` of `Dict`s, but a `Vector` of `Vector`s:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mArrayEntry\u001b[39m\u001b[90m\u001b[3m 2000x updated\u001b[23m\u001b[39m\n\u001b[34m  ╰── \u001b[39m\u001b[39mLeafEntry (2471 unique `String` values)\u001b[90m\u001b[3m 21632x updated\u001b[23m\u001b[39m"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = schema(jss_train)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next step is to create an extractor:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mArrayExtractor\u001b[39m\n\u001b[34m  ╰── \u001b[39m\u001b[39mNGramExtractor(n=3, b=256, m=2053)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "e = suggestextractor(sch)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we have sufficient memory, we can extract all documents before training like in the\n",
    "[Mutagenesis](https://github.com/CTUAvastLab/JsonGrinder.jl/tree/master/docs/src/examples/mutagenesis) example:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mBagNode\u001b[39m\u001b[90m\u001b[3m  2000 obs, 31.336 KiB\u001b[23m\u001b[39m\n\u001b[34m  ╰── \u001b[39m\u001b[39mArrayNode(2053×21632 NGramMatrix with Int64 elements)\u001b[90m\u001b[3m  21632 obs, 586.46 \u001b[23m\u001b[39m\u001b[90m⋯\u001b[39m"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "extract(e, jss_train)"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, in this example we want to show how to extract online in the training loop."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We continue with the model definition, making use of some of the\n",
    "We continue with the model definition, making use of some of the\n",
    "`Mill.reflectinmodel` features."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dense(40 => 20) ∘ BagModel ↦ BagCount([SegmentedMean(40); SegmentedMax(40); SegmentedLSE(40)]) ↦ Dense(121 => 40, relu)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "encoder = reflectinmodel(sch, e, d -> Dense(d, 40, relu), d -> SegmentedMeanMaxLSE(d) |> BagCount)\n",
    "model = Dense(40, length(classes)) ∘ encoder"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define important components for the training:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "accuracy (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "pred(m, x) = softmax(m(x))\n",
    "opt_state = Flux.setup(Flux.Optimise.Adam(), model);\n",
    "minibatch_iterator = Flux.DataLoader((jss_train, y_train_oh), batchsize=32, shuffle=true);\n",
    "accuracy(p, y) = mean(onecold(p, classes) .== y)"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "And run the training:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└   accuracy = 0.3395\n",
      "┌ Info: Epoch 2\n",
      "└   accuracy = 0.506\n",
      "┌ Info: Epoch 3\n",
      "└   accuracy = 0.595\n",
      "┌ Info: Epoch 4\n",
      "└   accuracy = 0.662\n",
      "┌ Info: Epoch 5\n",
      "└   accuracy = 0.7115\n",
      "┌ Info: Epoch 6\n",
      "└   accuracy = 0.7645\n",
      "┌ Info: Epoch 7\n",
      "└   accuracy = 0.79\n",
      "┌ Info: Epoch 8\n",
      "└   accuracy = 0.8385\n",
      "┌ Info: Epoch 9\n",
      "└   accuracy = 0.863\n",
      "┌ Info: Epoch 10\n",
      "└   accuracy = 0.8865\n",
      "┌ Info: Epoch 11\n",
      "└   accuracy = 0.9195\n",
      "┌ Info: Epoch 12\n",
      "└   accuracy = 0.9265\n",
      "┌ Info: Epoch 13\n",
      "└   accuracy = 0.951\n",
      "┌ Info: Epoch 14\n",
      "└   accuracy = 0.9615\n",
      "┌ Info: Epoch 15\n",
      "└   accuracy = 0.969\n",
      "┌ Info: Epoch 16\n",
      "└   accuracy = 0.981\n",
      "┌ Info: Epoch 17\n",
      "└   accuracy = 0.985\n",
      "┌ Info: Epoch 18\n",
      "└   accuracy = 0.986\n",
      "┌ Info: Epoch 19\n",
      "└   accuracy = 0.9935\n",
      "┌ Info: Epoch 20\n",
      "└   accuracy = 0.9965\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "for i in 1:20\n",
    "    Flux.train!(model, minibatch_iterator, opt_state) do m, jss, y\n",
    "        x = Flux.@ignore_derivatives extract(e, jss)\n",
    "        Flux.Losses.logitcrossentropy(m(x), y)\n",
    "    end\n",
    "    @info \"Epoch $i\" accuracy=accuracy(pred(model, extract(e, jss_train)), y_train)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, let's measure the testing accuracy. In this case, the classifier is overfitted:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "accuracy(model(extract(e, jss_test)), y_test)"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
