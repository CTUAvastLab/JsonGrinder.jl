{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mutagenesis Example\n",
    "Following example demonstrates learning to [predict the mutagenicity on Salmonella typhimurium](https://relational.fit.cvut.cz/dataset/Mutagenesis) (dataset is stored in json format [in MLDatasets.jl](https://juliaml.github.io/MLDatasets.jl/stable/datasets/Mutagenesis/) for your convenience)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by installing JsonGrinder and few other packages we need for the example.\n",
    "Julia Ecosystem follows philosophy of many small single-purpose composable packages\n",
    "which may be different from e.g. python where we usually use fewer larger packages."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: The Pkg REPL mode is intended for interactive use only, and should not be used from scripts. It is recommended to use the functional API instead.\n",
      "└ @ Pkg.REPLMode /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.7/Pkg/src/REPLMode/REPLMode.jl:377\n",
      "     Cloning git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "    Updating git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "    Updating registry at `~/.julia/registries/General.toml`\n",
      "   Resolving package versions...\n",
      "   Installed Mill ─ v2.7.0\n",
      "┌ Warning: The active manifest file at `/home/runner/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml` has an old format that is being maintained.\n",
      "│ To update to the new format run `Pkg.upgrade_manifest()` which will upgrade the format without re-resolving.\n",
      "└ @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.7/Pkg/src/manifest.jl:287\n",
      "    Updating `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Project.toml`\n",
      "  [d201646e] ~ JsonGrinder v2.2.1 `~/work/JsonGrinder.jl/JsonGrinder.jl` ⇒ v2.2.1 `https://github.com/CTUAvastLab/JsonGrinder.jl.git#master`\n",
      "  [1d0525e4] ~ Mill v2.7.0 `https://github.com/CTUAvastLab/Mill.jl.git#master` ⇒ v2.7.0\n",
      "    Updating `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml`\n",
      "  [d201646e] ~ JsonGrinder v2.2.1 `~/work/JsonGrinder.jl/JsonGrinder.jl` ⇒ v2.2.1 `https://github.com/CTUAvastLab/JsonGrinder.jl.git#master`\n",
      "  [1d0525e4] ~ Mill v2.7.0 `https://github.com/CTUAvastLab/Mill.jl.git#master` ⇒ v2.7.0\n",
      "┌ Warning: The active manifest file is an older format with no julia version entry. Dependencies may have been resolved with a different julia version.\n",
      "└ @ ~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml:0\n",
      "Precompiling project...\n",
      "\u001b[33m  ✓ \u001b[39mMill\n",
      "\u001b[33m  ✓ \u001b[39mJsonGrinder\n",
      "  2 dependencies successfully precompiled in 22 seconds (162 already precompiled)\n",
      "  \u001b[33m2\u001b[39m dependencies precompiled but different versions are currently loaded. Restart julia to access the new versions\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "pkg\"add JsonGrinder#master MLDatasets Flux Mill MLDataPattern Statistics\""
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we include libraries all necessary libraries"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JsonGrinder, MLDatasets, Flux, Mill, MLDataPattern, Statistics"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we load all samples."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_x, train_y = MLDatasets.Mutagenesis.traindata();\n",
    "test_x, test_y = MLDatasets.Mutagenesis.testdata();"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define some basic parameters for the construction and training of the neural network.\n",
    "Minibatch size is self-explanatory, iterations is number of iterations of gradient descent\n",
    "Neurons is number of neurons in hidden layers for each version of part of the neural network."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "minibatchsize = 100\n",
    "iterations = 5_000\n",
    "neurons = 20"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create the schema of the training data, which is the first important step in using the JsonGrinder.\n",
    "This computes both the structure (also known as JSON schema) and histogram of occurrences of individual values in the training data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34m[Dict]\u001b[39m\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39m[Scalar - Float64], 98 unique values\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39m[Scalar - Int64], 1 unique values\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ⋮\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31m[List]\u001b[39m\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32m[Dict]\u001b[39m\u001b[90m \t# updated = 2529\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(train_x)"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we use it to create the extractor converting jsons to Mill structures.\n",
    "The `suggestextractor` is executed below with default setting, but it allows you heavy customization.\n",
    "We also prepare list of classes. This classification problem is two-class, but we want to infer it from labels."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element Vector{Int64}:\n 1\n 0"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "extractor = suggestextractor(sch)\n",
    "labelnames = unique(train_y)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model\n",
    "We create the model reflecting structure of the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductModel ↦ Dense(100, 2)\u001b[39m\u001b[90m \t# 2 arrays, 202 params, 888 bytes\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayModel(Dense(99, 20, relu))\u001b[90m \t# 2 arrays, 2_000 params, 7.891 KiB\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayModel(Dense(2, 20, relu))\u001b[90m \t# 2 arrays, 60 params, 320 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayModel(Dense(63, 20, relu))\u001b[90m \t# 2 arrays, 1_280 params, 5.078 KiB\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayModel(Dense(3, 20, relu))\u001b[90m \t# 2 arrays, 80 params, 400 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagModel ↦ [SegmentedMean(20); SegmentedMax(20)] ↦ Dense(40, 20, relu)\u001b[39m\u001b[90m \t# 4 arrays, 860 params, 3.516 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductModel ↦ Dense(61, 20, relu)\u001b[39m\u001b[90m \t# 2 arrays, 1_240 params, 4.922 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "model = reflectinmodel(sch, extractor,\n",
    "\tlayer -> Dense(layer, neurons, relu),\n",
    "\tbag -> SegmentedMeanMax(bag),\n",
    "\tfsm = Dict(\"\" => layer -> Dense(layer, length(labelnames))),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "this allows us to create model flexibly, without the need to hardcode individual layers.\n",
    "Individual arguments of `reflectinmodel` are explained in [Mill.jl documentation](https://CTUAvastLab.github.io/Mill.jl/stable/manual/reflectin/#Model-Reflection). But briefly: for every numeric array in the sample, model will create a dense layer with `neurons` neurons (20 in this example). For every vector of observations (called bag in Multiple Instance Learning terminology), it will create aggregation function which will take mean, maximum of feature vectors and concatenate them. The `fsm` keyword argument basically says that on the end of the NN, as a last layer, we want 2 neurons `length(labelnames)` in the output layer, not 20 as in the intermediate layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We convert jsons to mill data samples and prepare list of classes. This classification problem is two-class, but we want to infer it from labels.\n",
    "The extractor is callable, so we can pass it vector of samples to obtain vector of structures with extracted features."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Mill.ProductNode{NamedTuple{(:lumo, :inda, :logp, :ind1, :atoms), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000063, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000002, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000003f, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000003, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bonds, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bond_type, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000004, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}}:\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ⋮\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "train_data = extractor.(train_x)\n",
    "test_data = extractor.(test_x)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "Then, we define few handy functions and a loss function, which is categorical crossentropy in our case."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "loss (generic function with 2 methods)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "loss(x,y) = Flux.logitcrossentropy(model(x), Flux.onehotbatch(y, labelnames))\n",
    "accuracy(x,y) = mean(labelnames[Flux.onecold(model(x))] .== y)\n",
    "loss(xy::Tuple) = loss(xy...)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we can add a callback which will be printing train and test accuracy during the training\n",
    "and then we can start trining"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "#7 (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "cb = () -> begin\n",
    "\ttrain_acc = accuracy(train_data, train_y)\n",
    "\ttest_acc = accuracy(test_data, test_y)\n",
    "\tprintln(\"accuracy: train = $train_acc, test = $test_acc\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly we turn our training data to minibatches, and we can start training"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: train = 0.22, test = 0.11363636363636363\n",
      "accuracy: train = 0.95, test = 0.8409090909090909\n",
      "accuracy: train = 1.0, test = 0.8181818181818182\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.8181818181818182\n",
      "accuracy: train = 1.0, test = 0.7727272727272727\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.8181818181818182\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7727272727272727\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7954545454545454\n",
      "accuracy: train = 1.0, test = 0.7727272727272727\n",
      "accuracy: train = 1.0, test = 0.7727272727272727\n",
      "accuracy: train = 1.0, test = 0.7727272727272727\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "minibatches = RandomBatches((train_data, train_y), size = minibatchsize, count = iterations)\n",
    "Flux.Optimise.train!(loss, Flux.params(model), minibatches, ADAM(), cb = Flux.throttle(cb, 2))"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the accuracy rising and obtaining over 98% on training set quite quickly, and on test set we get over 70%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify test set\n",
    "The Last part is inference on test data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7954545454545454"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "probs = softmax(model(test_data))\n",
    "o = Flux.onecold(probs)\n",
    "pred_classes = labelnames[o]\n",
    "mean(pred_classes .== test_y)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "`pred_classes` contains the predictions for our test set.\n",
    "we see the accuracy is around 75% on test set\n",
    "predicted classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 1\n 1\n 0\n 0\n 1\n 1\n 1\n 0\n 1\n 1\n ⋮\n 1\n 1\n 1\n 1\n 1\n 1\n 0\n 1\n 1"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "pred_classes"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ground truth classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 1\n 1\n 1\n 0\n 1\n 1\n 0\n 0\n 1\n 1\n ⋮\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 0\n 1"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "test_y"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "probabilities for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×44 Matrix{Float32}:\n 0.999977    0.998857    0.00595558  …  0.311291  0.979187   0.999737\n 2.35166f-5  0.00114247  0.994044       0.688709  0.0208131  0.000262501"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "probs"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can look at individual samples. For instance, some sample from test set is"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductNode\u001b[39m\u001b[90m \t# 1 obs, 104 bytes\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayNode(99×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayNode(2×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayNode(63×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayNode(3×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagNode\u001b[39m\u001b[90m \t# 1 obs, 136 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductNode\u001b[39m\u001b[90m \t# 24 obs, 64 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "test_data[2]"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "and the corresponding classification is"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "pred_classes[2]"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "if you want to see the probability distribution, it can be obtained by applying `softmax` to the output of the network."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×1 Matrix{Float32}:\n 0.9988575\n 0.0011424734"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "softmax(model(test_data[2]))"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we can see that the probability that given sample is `mutagenetic` is almost 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "kernelspec": {
   "name": "julia-1.7",
   "display_name": "Julia 1.7.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
