{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutagenesis Example in Python\n",
    "\n",
    "Following example is the same as the julia version of the \n",
    "Following example demonstrates learning to predict the mutagenicity on Salmonella typhimurium using the [JuliaPy/pyjulia](https://github.com/JuliaPy/pyjulia), and demonstrates how can the JsonGrinder.jl be used entirely from python.\n",
    "\n",
    "We start by installing the pyjulia and use it to install the JsonGrinder and few other packages we need for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: julia in /opt/conda/lib/python3.9/site-packages (0.5.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia version info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.7.2\n",
      "Commit bf53498635 (2022-02-06 15:21 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  uname: Linux 5.10.16.3-microsoft-standard-WSL2 #1 SMP Fri Apr 2 22:23:49 UTC 2021 x86_64 x86_64\n",
      "  CPU: Intel(R) Core(TM) i7-9850H CPU @ 2.60GHz: \n",
      "              speed         user         nice          sys         idle          irq\n",
      "       #1  2592 MHz      10271 s          0 s       6263 s      77778 s          0 s\n",
      "       #2  2592 MHz      11955 s          0 s       7993 s      77455 s          0 s\n",
      "       \n",
      "  Memory: 1.9366111755371094 GB (866.65625 MB free)\n",
      "  Uptime: 10331.86 sec\n",
      "  Load Avg:  0.22  14.99  31.88\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-12.0.1 (ORCJIT, skylake)\n",
      "Environment:\n",
      "  JULIA_DEPOT_PATH = /opt/julia\n",
      "  JULIA_PKGDIR = /opt/julia\n",
      "  JULIA_VERSION = 1.7.2\n",
      "  PATH = /opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "  HOME = /home/jovyan\n",
      "  XDG_CACHE_HOME = /home/jovyan/.cache/\n",
      "  JULIA_DEPOT_PATH = /opt/julia\n",
      "  TERM = xterm-color\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Julia executable: /opt/julia-1.7.2/bin/julia\n",
      "[ Info: Trying to import PyCall...\n",
      "┌ Info: PyCall is already installed and compatible with Python executable.\n",
      "│ \n",
      "│ PyCall:\n",
      "│     python: /opt/conda/bin/python\n",
      "│     libpython: /opt/conda/lib/libpython3.9.so.1.0\n",
      "│ Python:\n",
      "│     python: /opt/conda/bin/python\n",
      "└     libpython: \n"
     ]
    }
   ],
   "source": [
    "julia.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/julia/core.py:703: FutureWarning: Accessing `Julia().<name>` to obtain Julia objects is deprecated.  Use `from julia import Main; Main.<name>` or `jl = Julia(); jl.eval('<name>')`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<julia.core.LegacyJulia at 0x7f0dce7c1280>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from julia import Julia\n",
    "Julia(compiled_modules=False)\n",
    "#Julia(runtime='C:\\\\Users\\\\racinsky\\\\AppData\\\\Local\\\\Programs\\\\Julia-1.7.2\\\\bin\\\\julia.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the correct version of Julia was installed. We need julia 1.6 or newer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap 1.7.2>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from julia import Base\n",
    "Base.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We install the packages using the julia package manager called from python\n",
    "\n",
    "Executing the following line may take few minutes, because the package manager needs to resolve proper versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Updating registry at `/opt/julia/registries/General.toml`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n",
      "    Updating git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "   Resolving package versions...\n",
      "  No Changes to `/opt/julia/environments/v1.7/Project.toml`\n",
      "  No Changes to `/opt/julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "from julia import Pkg\n",
    "Pkg.add(\"MLDatasets\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Mill\")\n",
    "Pkg.add(\"MLDataPattern\")\n",
    "Pkg.add(\"Statistics\")\n",
    "Pkg.add(name=\"JsonGrinder\", rev=\"master\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we include libraries all necessary libraries\n",
    "\n",
    "Executing the following cell may take few minutes to finish, which is expected, because there is lots of code being precompiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julia import JsonGrinder, MLDatasets, Flux, Mill, MLDataPattern, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load all samples.\n",
    "\n",
    "In order to download datasets automatically from jupyter notebook, make sure the environment variable `DATADEPS_ALWAYS_ACCEPT` is present and set to true. E.g. using this if you run the notebook from docker compose\n",
    "```\n",
    "services:\n",
    "  ...\n",
    "    environment:\n",
    "      - DATADEPS_ALWAYS_ACCEPT=true\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = MLDatasets.Mutagenesis.traindata();\n",
    "test_x, test_y = MLDatasets.Mutagenesis.testdata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some basic parameters for the construction and training of the neural network. Minibatch size is self-explanatory, iterations is number of iterations of gradient descent Neurons is number of neurons in hidden layers for each version of part of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatchsize = 100\n",
    "iterations = 5_000\n",
    "neurons = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the schema of the training data, which is the first important step in using the JsonGrinder. This computes both the structure (also known as JSON schema) and histogram of occurrences of individual values in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap DictEntry>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sch = JsonGrinder.schema(train_x)\n",
    "sch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use it to create the extractor converting jsons to Mill structures. The suggestextractor is executed below with default setting, but it allows you heavy customization. We also prepare list of classes. This classification problem is two-class, but we want to infer it from labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = JsonGrinder.suggestextractor(sch)\n",
    "labelnames = Base.unique(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "We create the model reflecting structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap ProductModel ↦ ArrayModel(Dense(100, 2))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mill.reflectinmodel(sch, extractor,\n",
    "    lambda input_dim: Flux.Dense(input_dim, neurons, Flux.relu),\n",
    "    lambda input_dim: Mill.SegmentedMeanMax(input_dim),\n",
    "    fsm = {\"\": lambda input_dim: Flux.Dense(input_dim, Base.length(labelnames))},\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert jsons to mill data samples and prepare list of classes. This classification problem is two-class, but we want to infer it from labels. The extractor is callable, so we can pass it vector of samples to obtain vector of structures with extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>,\n",
       " <PyCall.jlwrap ProductNode>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(map(extractor, train_x))\n",
    "test_data = list(map(extractor, test_x))\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Then, we define few handy functions and a loss function, which is categorical crossentropy in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function needs to be defined in julia, not in python, unfortunately, because of the https://github.com/JuliaPy/pyjulia/issues/491 bug. This is the only code which needs to be ran from julia, and this is the most obscure part of the notebook, which passes label names and model from python to julia so the gradient calculation works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x): return model(x).data\n",
    "def accuracy(x,y): return Statistics.mean(labelnames[Flux.onecold(inference(x))-1] == y)\n",
    "import julia.Main as jl\n",
    "def loss_factory(model, labelnames, loss_name):\n",
    "    jl.model__ = model\n",
    "    jl.labelnames__ = labelnames\n",
    "    return jl.eval(f\"(x, y) -> {loss_name}(model__(x).data, Flux.onehotbatch(y, labelnames__))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can add a callback which will be printing train and test accuracy during the training and then we can start trining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb():\n",
    "    train_acc = accuracy(train_data, train_y)\n",
    "    test_acc = accuracy(test_data, test_y)\n",
    "    print(f\"accuracy: {train_acc=}, {test_acc=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we turn our training data to minibatches, and we can start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatches = MLDataPattern.RandomBatches((train_data, train_y), size = minibatchsize, count = iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the actual loss function and store it in python variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyCall.jlwrap #18>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_loss = loss_factory(model, labelnames, \"Flux.logitcrossentropy\")\n",
    "my_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can finally start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: train_acc=0.88, test_acc=0.8409090909090909\n",
      "accuracy: train_acc=0.92, test_acc=0.8409090909090909\n",
      "accuracy: train_acc=0.97, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=0.98, test_acc=0.75\n",
      "accuracy: train_acc=0.99, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.8409090909090909\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.75\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.75\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7727272727272727\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.8181818181818182\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n",
      "accuracy: train_acc=1.0, test_acc=0.7954545454545454\n"
     ]
    }
   ],
   "source": [
    "Flux.Optimise.train_b(my_loss, Flux.params(model), minibatches, Flux.ADAM(), cb = Flux.throttle(cb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy rising and obtaining over 99% on training set quite quickly, and on test set we get over 79%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify test set\n",
    "The Last part is inference on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954545454545454"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = Flux.softmax(model(test_data).data)\n",
    "o = Flux.onecold(probs) - 1\n",
    "pred_classes = labelnames[o]\n",
    "Statistics.mean(pred_classes == test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pred_classes` contains the predictions for our test set. we see the accuracy is around 75% on test set predicted classes for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth classes for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probabilities for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99987364e-01, 9.97891963e-01, 8.30009487e-03, 9.97200375e-04,\n",
       "        9.93917823e-01, 9.97030973e-01, 9.94567633e-01, 3.73403668e-01,\n",
       "        9.96551633e-01, 9.99986172e-01, 5.99438548e-01, 7.75109977e-02,\n",
       "        9.73641872e-01, 9.98892844e-01, 6.51718020e-01, 5.34612298e-01,\n",
       "        9.99948621e-01, 6.08506978e-01, 6.43978885e-04, 3.65056068e-01,\n",
       "        9.76465583e-01, 1.30008530e-05, 9.90937948e-01, 9.99985695e-01,\n",
       "        9.02300358e-01, 9.99958515e-01, 6.98983550e-01, 9.99988675e-01,\n",
       "        1.00000000e+00, 9.99984026e-01, 9.95685101e-01, 2.45655611e-01,\n",
       "        1.75017258e-03, 2.73398310e-02, 9.99971986e-01, 9.92810369e-01,\n",
       "        9.99029279e-01, 9.99971271e-01, 9.99995947e-01, 9.97915804e-01,\n",
       "        9.99993920e-01, 4.54691052e-01, 9.95735168e-01, 9.99857545e-01],\n",
       "       [1.26657187e-05, 2.10803282e-03, 9.91699874e-01, 9.99002874e-01,\n",
       "        6.08217902e-03, 2.96906126e-03, 5.43241017e-03, 6.26596332e-01,\n",
       "        3.44841368e-03, 1.38119785e-05, 4.00561422e-01, 9.22489047e-01,\n",
       "        2.63581797e-02, 1.10714487e-03, 3.48281950e-01, 4.65387672e-01,\n",
       "        5.14135754e-05, 3.91492993e-01, 9.99355972e-01, 6.34943962e-01,\n",
       "        2.35343687e-02, 9.99987006e-01, 9.06206574e-03, 1.43456973e-05,\n",
       "        9.76996347e-02, 4.15257164e-05, 3.01016420e-01, 1.13670121e-05,\n",
       "        1.65483205e-09, 1.59387782e-05, 4.31492599e-03, 7.54344344e-01,\n",
       "        9.98249829e-01, 9.72660124e-01, 2.79940123e-05, 7.18970597e-03,\n",
       "        9.70682304e-04, 2.87666680e-05, 4.00260842e-06, 2.08421401e-03,\n",
       "        6.10218285e-06, 5.45308948e-01, 4.26478451e-03, 1.42486475e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at individual samples. For instance, some sample from test set is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductNode  # 1 obs, 104 bytes\n",
      "  ├─── lumo: ArrayNode(99×1 OneHotArray with Bool elements)  # 1 obs, 60 bytes\n",
      "  ├─── inda: ArrayNode(2×1 OneHotArray with Bool elements)  # 1 obs, 60 bytes\n",
      "  ├─── logp: ArrayNode(63×1 OneHotArray with Bool elements)  # 1 obs, 60 bytes\n",
      "  ├─── ind1: ArrayNode(3×1 OneHotArray with Bool elements)  # 1 obs, 60 bytes\n",
      "  ╰── atoms: BagNode  # 1 obs, 136 bytes\n",
      "               ╰── ProductNode  # 25 obs, 64 bytes\n",
      "                     ├──── element: ArrayNode(7×25 OneHotArray with Bool elements)  # 25 obs, 156 bytes\n",
      "                     ├────── bonds: BagNode  # 25 obs, 488 bytes\n",
      "                     │                ╰── ProductNode  # 54 obs, 32 bytes\n",
      "                     │                      ├──── element: ArrayNode(7×54 OneHotArray with Bool elements)  # 54 obs, 272 bytes\n",
      "                     │                      ├── bond_type: ArrayNode(4×54 OneHotArray with Bool elements)  # 54 obs, 272 bytes\n",
      "                     │                      ├───── charge: ArrayNode(1×54 Array with Float32 elements)  # 54 obs, 264 bytes\n",
      "                     │                      ╰── atom_type: ArrayNode(29×54 OneHotArray with Bool elements)  # 54 obs, 272 bytes\n",
      "                     ├───── charge: ArrayNode(1×25 Array with Float32 elements)  # 25 obs, 148 bytes\n",
      "                     ╰── atom_type: ArrayNode(29×25 OneHotArray with Bool elements)  # 25 obs, 156 bytes"
     ]
    }
   ],
   "source": [
    "Mill.printtree(test_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the corresponding classification is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see the probability distribution, it can be obtained by applying softmax to the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00830009],\n",
       "       [0.9916999 ]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flux.softmax(model(test_data[2]).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can see that the probability that given sample is `mutagenetic` is almost 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
