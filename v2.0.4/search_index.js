var documenterSearchIndex = {"docs":
[{"location":"schema/#Schema","page":"Schema","title":"Schema","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"The schema helps to understand the structure of JSON files, by which we understand the types of nodes (Dict, Array, Values) and frequency of occurences of values and lengths of arrays. The schema also holds statistics about how many times the node has been presented. All these informations are taken into the account by suggestextractor function, which takes a schema and using few reasonable heuristic suggest an extractor, which convert jsons to Mill structure. The schema might be also useful for formats with enforced schema to collect statistics on leafs.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The main function to create schema is schema, which accepts a list of (unparsed) JSONs and producing schema. Schema can be always updated to reflect new JSONs and allow streaming by update! function. Moreover, schema accepts an optional argument a function converting an item of and array to a JSON. Thism a function creating schema from all jsons in a dictionaty can look like","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"schema(readdir(\"jsons\", join = true)) do s\n\topen(s,\"r\") do fio\n\t\tread(fio, String)\n\tend |> JSON.parse\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"A schema can be further updated by calling function update!(sch, json). Schemas can be merged using the overloaded merge function, which facilitates distributed creation of schema. Schema can be saved in html by generate_html allowing their interactive exploration.","category":"page"},{"location":"schema/#Implementation-details","page":"Schema","title":"Implementation details","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"Statistics are collected in a hierarchical structure reflecting the structured composed of DictEntry, ArrayEntry, and Entry. These structures reflects the those in JSON: Dict, Array, and Value (either String or a Number). Sometimes, data are stored in JSONs not adhering to a stable schema, which happens if one key have childs of different type. An example of such would be ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\" = [1,2,3]}\n{\"a\" = {b = 1}}\n{\"a\" = \"hello\"}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"For these cases, we have introduced additional Entry, a MultiEntry, but we discourage to rely on this feature and recommend to adapts JSONs to have stable schema (if possible).","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Each subtype of JSONEntry implements and update! function, which recursively update of the schema.","category":"page"},{"location":"schema/#Entry","page":"Schema","title":"Entry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct Entry{T} <: JSONEntry\n\tcounts::Dict{T,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Entry keeps information about leaf-values (e.g. \"a\" = 3) (strings or numbers) in JSONs. It consists of two statistics","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"updated counts how many times the leaf with a given key was observed,\ncounts counts how many times a particular value of the leaf was observed.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To keep counts from becoming too large, once its length exceeds updatemaxkeys (default 10 000), then the new values will be dropped. This value can be changed by updatemaxkeys!, but of course the new limit will be applied to newly processed values.","category":"page"},{"location":"schema/#ArrayEntry","page":"Schema","title":"ArrayEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ArrayEntry keeps information about arrays (e.g. \"a\" = [1,2,3,4]). Statistics about individual items of the array are deffered to item, which can be <:JSONEntry. l stores keeps histogram of lengts of arrays, and updated is keep number of times this key has been observed.","category":"page"},{"location":"schema/#DictEntry","page":"Schema","title":"DictEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct DictEntry <: JSONEntry\n\tchilds::Dict{Symbol, Any}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"deferes all statistics about its children to them, and the only statistic is again a counter updated, about observation times.","category":"page"},{"location":"schema/#MultiEntry","page":"Schema","title":"MultiEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{JSONEntry}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"is a failsave for cases, where the schema is not stable. For example in following two JSONs","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\" = \"Hello\"}\n{\"a\" = [\"Hello\",\" world\"]}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"the type of a value of a key \"a\" is String, whereas in the second it is \"Vector\". The JsonGrinder will deal with this by first creating an Entry, since the value is scalar, and upon encountering the second JSON, it will replace Entry with MultiEntry having Entry and ArrayEntry as childs (this is the reason why entries are declared mutable). ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"While JsonGrinder can deal with non-stable jsons, it is strongly discouraged as it might have negative effect on the performance.","category":"page"},{"location":"schema/#Extra-functions","page":"Schema","title":"Extra functions","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"While schema can be printed to REPL, it can contain quite a lot of information. Therefore JsonGrinder.generate_html exports it to HTML, where parts can be expanded at wish.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.generate_html","category":"page"},{"location":"schema/#JsonGrinder.generate_html","page":"Schema","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(sch::DictEntry, file_name ; max_vals=100, max_len=1_000)\n\nexport schema to HTML including CSS style allowing to expand / hide\nsub-parts of schema, countmaps, and lengthmaps.\n\n`max_vals` controls maximum number of exported values in countmap\n`max_len` controls maximum number of exported lengts of arrays\n`file_name` a name of file to save HTML with schema\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema supports merging using Base.merge, which facilitates paralel computation of schemas. An example might be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, div(length(jsons), Threads.nthreads())))","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.prune_json","category":"page"},{"location":"schema/#JsonGrinder.prune_json","page":"Schema","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nremove keys from json which are not part of the schema\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxkeys!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxkeys!","page":"Schema","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of nodes in JSON. Default value is 10000.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxlen!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxlen!","page":"Schema","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum size of string values in statistics of nodes in JSON. Default value is 10000.\nLonger strings will be trimmed and their length and hash will be appended to retain the uniqueness.\nThis is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"function"},{"location":"exfunctions/#Extractor-functions","page":"Extractor functions","title":"Extractor functions","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Below, we first describe extractors of values (i.e. lists of JSON tree), then proceed to description of extractors of Array and Dict, and finish with some specials.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extractors of scalar values are arguably the most important, but also fortunatelly the most undersood ones. They control, how values are converted to a Vector (or generally tensor) for the neural networks. For example they control, if number should be represented as a number, or as one-hot encoded categorical variable. Similarly, it constrols how String should be treated, although we admit to natively support on ngrams. Recall ","category":"page"},{"location":"exfunctions/#Numbers","page":"Extractor functions","title":"Numbers","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractScalar{T}\n\tc::T\n\ts::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extract a numerical value, centred by subtracting c and scaled by multiplying by s.  Strings are converted to numbers. The extractor returnes ArrayNode{Matrix{T}}  with a single row. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"using JsonGrinder, Mill, JSON #hide\ne = ExtractScalar(Float32, 0.5, 4.0)\ne(\"1\").data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Strings","page":"Extractor functions","title":"Strings","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractString{T}\n\tdatatype::Type{T}\n\tn::Int\n\tb::Int\n\tm::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Represent String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractString()\ne(\"Hello\")","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Categorical","page":"Extractor functions","title":"Categorical","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractCategorical{V,I} <: AbstractExtractor\n\tkeyvalemap::Dict{V,I}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Converts a single item to a one-hot encoded vector. For a safety, there is always an  extra item reserved for an unknown value. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractCategorical([\"A\",\"B\",\"C\"])\ne([\"A\",\"B\",\"C\",\"D\"]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Array-(Lists-/-Sets)","page":"Extractor functions","title":"Array (Lists / Sets)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractArray{T}\n\titem::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Convert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc = ExtractArray(ExtractCategorical([\"A\",\"B\",\"C\"]))\nsc([\"A\",\"B\",\"C\",\"D\"])","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Empty arrays are represented as an empty bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc([]).bags","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The data of empty bag can be either missing or a empty sample, which is more convenient as it makes all samples of the same type, which is nicer to AD. This behavior is controlled by Mill.emptyismissing. The extractor of a BagNode can signal to child extractors to extract a sample with zero observations using a special singleton JsonGrinder.extractempty. For example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(true)\nsc([]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(false)\nsc([]).data","category":"page"},{"location":"exfunctions/#Dict","page":"Extractor functions","title":"Dict","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractDict\n\tdict::Dict{Symbol,Any}\nend\n","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extracts all items in dict and return them as a ProductNode. Key in dict corresponds to keys in JSON. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = ExtractDict(Dict(:a => ExtractScalar(), \n\t:b => ExtractString(), \n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Missing keys are replaced by missing and handled by child extractors.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex(Dict(:a => \"1\",\n\t:c => \"A\"))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Describe extractempty to signal that we need to extract empty variable","category":"page"},{"location":"exfunctions/#Specials","page":"Extractor functions","title":"Specials","text":"","category":"section"},{"location":"exfunctions/#ExtractKeyAsField","page":"Extractor functions","title":"ExtractKeyAsField","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered uses structure to hold an array for named lists (or other types). Having computer security background a prototypical example is storing a list of DLLs with a corresponding list of imported function in a single structure. For example a JSON","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"{ \"foo.dll\" : [\"print\",\"write\", \"open\",\"close\"],\n  \"bar.dll\" : [\"send\", \"recv\"]\n}","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"should be better written as ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\"key\" = \"foo.dll\",\n  \"item\" = [\"print\",\"write\", \"open\",\"close\"]},\n  {\"key = \"bar.dll\",\n  \"item\" = [\"send\", \"recv\"]}\n]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"JsonGrinder tries to detect these cases, as they are typically manisfested by Dicts with excessively large number of keys in a schema. The detection logic of this case in suggestextractor(e::DictEntry) is simple, if the number of keys is greater than settings.key_as_field = 500.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is simple as well. For the case above, it would look like ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"s = JSON.parse(\"{ \\\"foo.dll\\\" : [\\\"print\\\",\\\"write\\\", \\\"open\\\",\\\"close\\\"],\n  \\\"bar.dll\\\" : [\\\"send\\\", \\\"recv\\\"]\n}\")\nex = ExtractKeyAsField(ExtractString(),ExtractArray(ExtractString()))\nex(s)","category":"page"},{"location":"exfunctions/#MultipleRepresentation","page":"Extractor functions","title":"MultipleRepresentation","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Provides a dual representation for a single key. For example imagine that are extracting strings with some very freuquently occuring values and a lots of clutter, which might be important and you do not know about it. MultipleRepresentation(extractors::Tuple) contains a Tuple or NamedTuple of extractors and apply them to a single sub-tree in a json. The corresponding Mill structure will contain ProductNode of both representation.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"For example String with Categorical and NGram representation will look like.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = MultipleRepresentation((c = ExtractCategorical([\"Hello\",\"world\"]), s = ExtractString()))\nreduce(catobs,ex.([\"Hello\",\"world\",\"from\",\"Prague\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"MultipleRepresentation together with handling of missing values enables JsonGrinder to deal with JSONs with non-stable schema.","category":"page"},{"location":"exfunctions/#ExtractOneHot(ks,-k,-v)","page":"Extractor functions","title":"ExtractOneHot(ks, k, v)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered encode histograms in a an array containing structures with a name of the bin and its count. In the example below, the name of the bin (further called key) and corresponding count in the bin is called value. In example below, key is equal to name and the value is equal to count.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1},\n{\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"This histogram is extracted as a BagNode with a wrapped SparseMatrix containing the key-value pairs, each pair in a separate We represent them as SparseMatrices with one line per item for example as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"vs = JSON.parse(\"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1}, {\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]\")\ne = ExtractOneHot([\"a\",\"b\"], \"name\", \"count\");\ne(vs).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Notice that the matrix has an extra dimension  reserved for unknown keys. The array is handled as a bag. For example for the above example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(vs)","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is a structure defined as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractOneHot{K,I,V} <: AbstractExtractor\n\tk::K\n\tv::V\n\tkey2id::Dict{I,Int}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"where k / v is the name of an entry indetifying key / value, and key2id converts the value of the key to the the index in the sparse array. A constructor ExtractOneHot(ks, k, v) assumes k and v as above and ks being list of key values. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"#explain, how to customize conversion of schema to extractors extractors to ","category":"page"},{"location":"extractors/#Creating-extractor","page":"Creating extractors","title":"Creating extractor","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor is responsible for converting json to Mill structures. The main design idea is that the extractor for a whole json is created by composing (sub-)extractors while reflecting the JSON structure. This composability is achieved by the commitment of each extractor returning a subtype of Mill.AbstractDataNode. Extractor can be any function, but to ensure a composability, it is should be a subtype of AbstractExtractor, which means all of them being implemented as functors (also because they contain parameters). ","category":"page"},{"location":"extractors/#Manual-creation-of-extractors","page":"Creating extractors","title":"Manual creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The simples way to create a custom extractor is the compose it from provided extractor functions. Imagine for example json file as follows.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"name\" = \"Karl\",\n \"siblings\" = [\"Gertruda\", \"Heike\", \"Fritz\"],\n \"hobby\" = [\"running\", \"pingpong\"],\n \"age\" = 21,\n}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"A corresponding extractor might look like","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"using JsonGrinder, Mill, JSON #hide\nex = ExtractDict(Dict(\n\t:name => ExtractString(),\n\t:siblings => ExtractArray(ExtractString()),\n\t:hobby => ExtractArray(ExtractCategorical([\"running\", \"swimming\",\"yoga\"])),\n\t:age => ExtractScalar(),\n\t))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Notice, how the composability of extractors simplifies the desing and allow to reflect the same feature of JSON documents.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Applying the extractor ex on the above json yield the corresponding Mill structure.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"s = JSON.parse(\"{\\\"name\\\" : \\\"Karl\\\",\n \\\"siblings\\\" : [\\\"Gertruda\\\", \\\"Heike\\\", \\\"Fritz\\\"],\n \\\"hobby\\\" : [\\\"running\\\", \\\"pingpong\\\"],\n \\\"age\\\" : 21\n}\")\nex(s)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The list of composable extractor function that we have found handy during our experiments are listed in Extractor functions section of the doc.","category":"page"},{"location":"extractors/#Semi-automatic-creation-of-extractors","page":"Creating extractors","title":"Semi-automatic creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Manually creating extractors is boring and error-prone process. Function suggestextractor(schema) tries to simplify this, since creation of most of the extractors is straightforward, once the the schema is known. This is especially true for Dict and Arrays, while extractors for leafs can be tricky, as one needs to decide, if the leaf should be represented as a  Float and String are represented as Categorical variables. suggestextractor(schema) uses a simple heuristic (described below) choosing reasonable extractors, but it can make errors. It is therefore highly recommended to check the proposed extractor manually, if it makes sense. A typical error, especially if schema is created from a small number of samples, is that some variable is treated as a categorical, while it should be String / Float.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"JsonGrinder.suggestextractor(schema, settings::NamedTuple)\n","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"allows to pass your own heuristic and rules for handling scalars. By default, settings = (scalar_extractors = default_scalar_extractor()). Extractors for Dict and Arrays are not configurable, as we do not feel the pressure to so, as there does not seems to be much to do, but of course there is some dark magic described below.","category":"page"},{"location":"extractors/#Scalars","page":"Creating extractors","title":"Scalars","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors is a list of tuples, where the first is a condition and the second is a function creating the extractor in case of a true. The default heuristic is following and  you can adjust according to your liking. ","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"function default_scalar_extractor()\n\t[\n\t# all floatable keys are also intable AFAIK\n\t(e -> length(keys(e)) <= 100 && is_floatable(e),\n\t\te -> ExtractCategorical(keys(e))),\n\t# it's important that condition here would be lower than maxkeys\n\t(e -> (keys_len = length(keys(e)); keys_len / e.updated < 0.1 && keys_len < 10000),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> is_intable(e),\n\t\te -> extractscalar(Int32, e)),\n\t(e -> is_floatable(e),\n\t \te -> extractscalar(FloatType, e)),\n\t(e -> true,\n\t\te -> extractscalar(unify_types(e), e)),]\nend","category":"page"},{"location":"extractors/#Arrays","page":"Creating extractors","title":"Arrays","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for ArrayEntry is most of the time ExtractArray converting Arrays to Mill.BagNodes. The exception is the case, when vectors are of the same length and their items are numbers. In this case, the suggestextractor returns ExtractVector, which treats convert the array to a Mill.ArrayNode, as we believe the array to represent a feature vector.","category":"page"},{"location":"extractors/#Dict","page":"Creating extractors","title":"Dict","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for DictEntry is most of the time ExtractDict converting Dicts to ProductNodes. Again, there is an excetion. Sometimes, people use Dicts with names of keys being values. For example consider following two jsons","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"a.dll\" = [\"f\", \"g\", \"h\"],\n \"b.dll\" = [\"a\", \"b\", \"c\"]}\n{\"c.dll\" = [\"x\", \"y\", \"z\"]}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"in the case, keys [\"a.dll\",\"b.dll\",\"c.dll\"] are actually values (names of libraries), and arrays are values as well. The dictionary therefore contain an array. If this case is detected, it is suggested to use ExtractKeyAsField, which interprests the above JSON as ","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"[{key = \"a.dll\", \n  field = [\"f\", \"g\", \"h\"]},\n {key = \"b.dll\",\n field = [\"a\", \"b\", \"c\"]}\n]\n[{key = \"c.dll\",\nfield = [\"x\", \"y\", \"z\"]}]","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"ExtractKeyAsField extractor convert it to Mill.BagNode(Mill.ProductNode((key=..., field=...)))","category":"page"},{"location":"developers/#For-developers-and-tweakers","page":"Developers","title":"For developers and tweakers","text":"","category":"section"},{"location":"developers/#Implementing-new-extractor-function","page":"Developers","title":"Implementing new extractor function","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Requirements on an extractor","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The extractor should implemented as a functor (a callable structure) with an abstract supertype JsonGrinder.AbstractExtractor.  \nThe extractor has to return a subtype of Mill.AbstractNode with the correct number of samples. \nThe extractor has to handle missing, typically by delegating this to appropriate Mill structures.\nThe extractor has to create a sample with zero observations (extractempty).","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Let's demonstrate the creation of a new extractor on an extractor, that would represent the sentence as a bag of words.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"using JsonGrinder, Mill\nstruct ExtractSentence{S} <: JsonGrinder.AbstractExtractor\n\tstring2mill::S\nend\n\nExtractSentence() = ExtractSentence(ExtractString())","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for extracting strings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(s::String)\n\tss = String.(split(s, \" \"))\n\tBagNode(e.string2mill(ss), [1:length(ss)])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for handling missing, which creates an  empty bag. An empty bag can contain either missing as its child, which  can create an explosion of types of extracted samples, or it can signal  to extractors underneath to extract a structure with zero observations.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::Missing)\n\tx = Mill.emptyismissing() ? missing : e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, [0:-1])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::JsonGrinder.ExtractEmpty)\n\tx = e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, Mill.AlignedBags(Array{UnitRange{Int64},1}()))\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"And to make the function more error prone, we recommed to treat unknowns as missings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"(e::ExtractSentence)(s) = e(missing)","category":"page"},{"location":"developers/#Handling-empty-bags","page":"Developers","title":"Handling empty bags","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Handling empty bags is (almost) straigtforward by creating an empty bag, i.e. BagNode(x, [0:-1]). The fundamental question is, what the x should be? There are two philosophically different ways with different tradeoffs (both are supported).","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"x = missing is the natural approach, since empty bag does not have any instances and the inference (or backprop) on a sample does not need to descend into children. The drawback is that if one is processing a JSONs with sufficiently big schema, each BagNode can potentially create two types â€“- one with missing and the other with x <: AbstractNode. This will trigger a lot of compilation, which at the moment can take quite some time especially when calculating gradients with Zygote.\nx <: AbstractNode with nobs(x) = 0. In other words, x would be the same type as it is if it contains instances, but it does not any observations. This has the advantage that all extracted samples will be of the same type and therefore there will be only single compilation for inference (and gradients). This is nice, but at the expense of less elegant code and probably small overhead caused by descending into childrens. This approach also needs a support from extractors, as creating an empty sample might be a bit tricky. As mentioned in preceding section, if an extractor wants its children to extract this special sample with zero observations, it asks them to extract a special singleton JsonGrider.extractempty. See above  (e::ExtractSentence)(::Missing) for an example. ","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The behavior is controled by Mill.emptyismissing!() switch, where true means the first approach, false the second.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Every neural network created by Mill can by default always handle both versions, even though it was trained with the other one. Finally, catobs can handle these situations seamlessly as well.","category":"page"},{"location":"#JsonGrinder.jl","page":"Home","title":"JsonGrinder.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Imagine that you want to train a classifier on data looking like","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"services\": [\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 80\n    },\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 443\n    },\n  ],\n  \"ip\": \"192.168.1.109\",\n  \"device_id\": \"2717684b-3937-4644-a33a-33f4226c43ec\",\n  \"upnp\": [\n    {\n      \"device_type\": \"urn:schemas-upnp-org:device:MediaServer:1\",\n      \"services\": [\n        \"urn:upnp-org:serviceId:ContentDirectory\",\n        \"urn:upnp-org:serviceId:ConnectionManager\"\n      ],\n      \"manufacturer\": \"ARRIS\",\n      \"model_name\": \"Verizon Media Server\",\n      \"model_description\": \"Media Server\"\n    }\n  ],\n  \"device_class\": \"MEDIA_BOX\",\n  \"ssdp\": [\n    {\n      \"st\": \"\",\n      \"location\": \"http://192.168.1.109:9098/device_description.xml\",\n      \"method\": \"\",\n      \"nt\": \"upnp:rootdevice\",\n      \"server\": \"ARRIS DIAL/1.7.2 UPnP/1.0 ARRIS Settop Box\",\n      \"user_agent\": \"\"\n    },\n    {\n      \"st\": \"\",\n      \"location\": \"http://192.168.1.109:8091/XD/21e13e66-1dd2-11b2-9b87-44e137a2ec6a\",\n      \"method\": \"\",\n      \"nt\": \"upnp:rootdevice\",\n      \"server\": \"Allegro-Software-RomPager/5.41 UPnP/1.0 ARRIS Settop Box\",\n      \"user_agent\": \"\"\n    },\n   ],\n  \"mac\": \"44:e1:37:a2:ec:c1\"\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"With most machine learning libraries assuming your data being stored as tensors of a fixed dimension, or a sequence, you will have a bad time. Contrary, JsonGrider.jl assumes your data to be stored in a flexible JSON format and tries to automatize most labor using reasonable default, but it still gives you an option to control and tweak almost everything. JsonGrinder.jl is built on top of Mill.jl which itself is built on top of Flux.jl (we do not reinvent the wheel). Although JsonGrinder was designed for JSON files, you can easily adapt it to XML, ProtoBuffers, MessagePacks,...","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are four steps to create a classifier once you load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create a schema of JSON files (using sch = JsonGrinder.schema).\nCreate an extractor converting JSONs to Mill structures (extractor = suggestextractor(sch))). Schema sch  from previous step is very helpful, as it helps to identify, how to convert nodes (Dict, Array) to (Mill.ProductNode and Mill.BagNode) and how to convert values in leafs to (Float32, Vector{Float32}, String, Categorical).\nCreate a model for your JSONs, which can be easily done by (using model = reflectinmodel(sch, extractor,...))\nUse your favourite methods to train the model, it is 100% compatible with Flux.jl tooling.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first two steps are handled by JsonGrinder.jl the third step by Mill.jl and the fourth by a combination of Mill.jl and Flux.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Authors see the biggest advantage in the model being hierarchical and reflecting the JSON structure. Thanks to Mill.jl, it can handle missing values at all levels. ","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Our idealized workflow is demonstrated in examples/identification.jl solving device identification challenge looks as follows (for many datasets which fits in memory it suggest just to change the key with labels (:device_class) and names of files):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, IterTools, Statistics, BenchmarkTools, ThreadTools, StatsBase\nusing JsonGrinder: suggestextractor\nusing Mill: reflectinmodel\n\nsamples = map(readlines(\"/Users/tomas.pevny/Work/Presentations/JuliaMeetup/dataset/train.json\")) do s\n           JSON.parse(s)\n       end;\n\nlabelkey = \"device_class\"\nminibatchsize = 100\niterations = 10_000\nneurons = 20 \t\t# neurons per layer\n\ntargets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\nforeach(i -> delete!(i, \"id\"), samples)\n\n#####\n#  Create the schema and extractor\n#####\nsch = JsonGrinder.schema(samples)\nextractor = suggestextractor(sch)\n\n#####\n#  Convert samples to Mill structure and extract targets\n#####\ndata = tmap(extractor, samples)\nlabelnames = unique(targets)\n\n#####\n#  Create the model\n#####\nmodel = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> SegmentedMeanMax(d),\n\tb = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)\n\n#####\n#  Train the model\n#####\nfunction minibatch()\n\tidx = sample(1:length(data), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = mean(map(xy -> labelnames[argmax(model(xy[1]).data[:])] == xy[2], zip(x, y)))\n\ncb = () -> println(\"accuracy = \", accuracy(data, targets))\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))\n\n#####\n#  Classify test data\n#####\ntest_samples = map(readlines(\"test.json\")) do s\n\textractor(JSON.parse(s))\nend\no = Flux.onecold(model(reduce(catobs, test_samples)).data);\nns = extract_target[:device_class].keyvalemap\nns = Dict([ v => k for (k,v) in ns]...)\no = [ns[i] for i in o]\n","category":"page"},{"location":"#A-walkthrough-of-the-example","page":"Home","title":"A walkthrough of the example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Include libraries and load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, IterTools, Statistics, BenchmarkTools, ThreadTools, StatsBase\nusing JsonGrinder: suggestextractor\nusing Mill: reflectinmodel\n\nsamples = map(readlines(\"train.json\")) do s\n\tJSON.parse(s)\nend;","category":"page"},{"location":"","page":"Home","title":"Home","text":"labelkey = \"device_class\"\nminibatchsize = 100\niterations = 10_000\nneurons = 20 \t\t# neurons per layer","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create labels and remove them from data, such that we do not use them as features. We also remove id key, such that we do not predict it","category":"page"},{"location":"","page":"Home","title":"Home","text":"targets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\nforeach(i -> delete!(i, \"id\"), samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the schema of data","category":"page"},{"location":"","page":"Home","title":"Home","text":"sch = JsonGrinder.schema(samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the extractor converting jsons to Mill structure. The suggestextractor is executed below with default setting, but it allows you heavy customizing.","category":"page"},{"location":"","page":"Home","title":"Home","text":"extractor = suggestextractor(sch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Convert jsons to mill data samples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = tmap(extractor, samples)\nlabelnames = unique(targets)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the model according to the data","category":"page"},{"location":"","page":"Home","title":"Home","text":"model = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> SegmentedMeanMax(d),\n\tb = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"After definiting few usual function, we start training.","category":"page"},{"location":"","page":"Home","title":"Home","text":"function minibatch()\n\tidx = sample(1:length(data), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = mean(map(xy -> labelnames[argmax(model(xy[1]).data[:])] == xy[2], zip(x, y)))\n\ncb = () -> println(\"accuracy = \", accuracy(data, targets))\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))","category":"page"}]
}
