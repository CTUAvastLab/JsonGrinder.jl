{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recipe Ingredients Example\n",
    "Following example demonstrates prediction of cuisine from set of ingredients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A gentle introduction to creation of neural networks reflexing structure of JSON documents\n",
    "\n",
    "This notebook serves as an introduction to `Mill` and `JsonGrinder` libraries.\n",
    "The former provides support for Multi-instance learning problems, their cascades, and their Cartesian product ([see the paper](https://arxiv.org/abs/2105.09107) for theoretical explanation).\n",
    "The latter `JsonGrinder` simplifies processing of JSON documents. It allows to infer schema of JSON documents from which it suggests an extractor to convert JSON document to a `Mill` structure.\n",
    "`JsonGrinder` defines basic set of \"extractors\" converting values of keys to numeric representation (matrices) or to convert them to corresponding structures in `Mill`. Naturally, this set of extractors can be extended.\n",
    "\n",
    "Below, the intended workflow is demonstrated on a simple problem of guessing type of a cuisine from a list of ingredients.\n",
    "The whole dataset and problem description can be found [on this Kaggle page](https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home).\n",
    "Note that the goal is not to achieve state of the art, but to demonstrate the workflow."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Caution**\n",
    "\n",
    "To reduce we keep locally in the repo only a subset of the whole dataset (`39774`).\n",
    "To decrease the computational load we use only `5000` samples, size of the validation data = `100`, size of the minibatch `10` and train for 20 iterations.\n",
    "Of course these numbers are useless in practice, and therefore the resulting accuracy is poor.\n",
    "Using all samples (`39774`), leaving `4774` samples for validation, setting minibatch size to `1000`, and training for `1000` iterations gives you accuracy 0.73 on validation data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5000, 100, 10, 20)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "n_samples, n_val, minibatchsize, iterations = 5_000, 100, 10, 20"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "n_samples, n_val, minibatchsize, iterations = 39_774, 4_774, 1_000, 1_000"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by installing JsonGrinder and few other packages we need for the example.\n",
    "Julia Ecosystem follows philosophy of many small single-purpose composable packages\n",
    "which may be different from e.g. python where we usually use fewer larger packages."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Updating git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "   Resolving package versions...\n",
      "┌ Warning: The active manifest file at `/home/runner/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml` has an old format that is being maintained.\n",
      "│ To update to the new format run `Pkg.upgrade_manifest()` which will upgrade the format without re-resolving.\n",
      "└ @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.7/Pkg/src/manifest.jl:287\n",
      "  No Changes to `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Project.toml`\n",
      "  No Changes to `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml`\n",
      "┌ Warning: The active manifest file is an older format with no julia version entry. Dependencies may have been resolved with a different julia version.\n",
      "└ @ ~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml:0\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "pkg\"add JsonGrinder#master Flux Mill MLDataPattern Statistics JSON\""
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by importing all libraries we will need."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JsonGrinder, Flux, Mill, MLDataPattern, Statistics, JSON"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing data\n",
    "After importing libraries we load all samples. Of course we can afford it only for small datasets, but\n",
    "for the sake of simplicity we keep whole dataset in memory, while recognizing this is usually not\n",
    "feasible in real-world scenarios.\n",
    "Data are stored in a format \"json per line\".\n",
    "This means that each sample is one JSON document stored in each line.\n",
    "These samples are loaded and parsed to an array. On the end, one sample is printed to show, how data looks like."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 10259,\n",
      "  \"ingredients\": [\n",
      "    \"romaine lettuce\",\n",
      "    \"black olives\",\n",
      "    \"grape tomatoes\",\n",
      "    \"garlic\",\n",
      "    \"pepper\",\n",
      "    \"purple onion\",\n",
      "    \"seasoning\",\n",
      "    \"garbanzo beans\",\n",
      "    \"feta cheese crumbles\"\n",
      "  ],\n",
      "  \"cuisine\": \"greek\"\n",
      "}\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "data_file = \"../../../data/recipes.json\"\n",
    "samples = open(data_file,\"r\") do fid\n",
    "\tVector{Dict}(JSON.parse(read(fid, String)))\n",
    "end\n",
    "JSON.print(samples[1],2)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we create schema of the JSON.\n",
    "Unlike XML or ProtoBuf, JSON documents do not have any schema by default.\n",
    "Therefore *JsonGrinder* attempts to infer the schema, which is then used to recommend the extractor."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34m[Dict]\u001b[39m\u001b[90m \t# updated = 5000\u001b[39m\n\u001b[34m  ├─────────── id: \u001b[39m\u001b[39m[Scalar - Int64], 5000 unique values\u001b[90m \t# updated = 5000\u001b[39m\n\u001b[34m  ├────── cuisine: \u001b[39m\u001b[39m[Scalar - String], 20 unique values\u001b[90m \t# updated = 5000\u001b[39m\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31m[List]\u001b[39m\u001b[90m \t# updated = 5000\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39m[Scalar - String], 3476 unique values\u001b[90m \t# updated = 53299\u001b[39m"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(samples[1:n_samples])"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "ID is deleted from the schema (keys not in the schema are not\n",
    "reflected into extractor and hence not propagated into dataset)."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dict{Symbol, Any} with 2 entries:\n  :cuisine     => Entry\n  :ingredients => ArrayEntry"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "delete!(sch.childs,:id)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the schema, we can create the extractor."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mDict\u001b[39m\n\u001b[34m  ├────── cuisine: \u001b[39m\u001b[39mCategorical d = 21\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31mArray of\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39mCategorical d = 3477"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "extractor = suggestextractor(sch)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since cuisine is a class label we want to predict,\n",
    "the extractor needs to be split into two.\n",
    "`extract_data` will extract the sample and `extract_target` will extract the target."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dict{Symbol, JsonGrinder.AbstractExtractor} with 1 entry:\n  :ingredients => ExtractArray"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "extract_data = ExtractDict(deepcopy(extractor.dict))\n",
    "extract_target = ExtractDict(deepcopy(extractor.dict))\n",
    "delete!(extract_target.dict, :ingredients)\n",
    "delete!(extract_data.dict, :cuisine)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, `extract_data` is a functor extracting samples and `extract_target` extract targets. Let's first demonstrate extractor of datas."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×1 Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000015, 1, 2, Vector{UInt32}}, Nothing}:\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n 1\n ⋅\n ⋅\n ⋅\n ⋮\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "extract_data(samples[1])\n",
    "extract_target(samples[1])[:cuisine]"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we use these extractors to convert JSONs to Mill structures which behave as our datasets."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductNode\u001b[39m\u001b[90m \t# 5000 obs, 16 bytes\u001b[39m\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31mBagNode\u001b[39m\u001b[90m \t# 5000 obs, 78.188 KiB\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39mArrayNode(3477×53299 OneHotArray with Bool elements)\u001b[90m \t# 53299 obs, 208.254 KiB\u001b[39m"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "data = extract_data.(samples[1:n_samples])\n",
    "data = reduce(catobs, data)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the `data` variable is a Mill structure containing `n_samples` obs (observations).\n",
    "Each observation there is a sample from the dataset.\n",
    "The root of this tree-like structure is ProductNode containing `ingredients` key, reflecting the\n",
    "same name as samples have in training data, and then we have `BagNode` of `ArrayNode` of `OneHotArray`,\n",
    "which is how the ingredients are represented. Each sample has set of ingredients, which are set of words,\n",
    "`e.g. [\"black\",\"olives\"]`., where each ingredient is encoded into one-hot vector of dimension 3477 (for the 5000 samples, it's larger if we use whole dataset).\n",
    "And we do the same with targets, the extractor converts them to one-hot encoded matrix."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×5000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  1  ⋅  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  1  1  1  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "target = extract_target.(samples[1:n_samples])\n",
    "target = reduce(catobs, target)[:cuisine].data"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that target is `21x5000` One-hot matrix in case of 5000 samples. There are 21 cuisines which are the prediction targets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Note about data representation\n",
    "This approach, where we catobs all data to single sample, and then we slice it to obtain mini-batches, is usable only\n",
    "for datasets which fit into the memory, which is not suited for many real-world tasks, but is usable for playing with\n",
    "small datasets. The other approach can be seen in the Mutagenesis Example example.\n",
    "Theoretically this approach is useful when you train in multiple epochs and all data fit into the memory,\n",
    "because you perform the catobs only once."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining the model reflecting the structure of data\n",
    "\n",
    "Since manually creating a model reflecting the structure can be tedious, Mill support a semi-automated procedure.\n",
    "The function `reflectinmodel` takes as an input data sample and function, which for a given input dimension provides a feed-forward network.\n",
    "In the example below, the function creates a feed forward network with a single fully-connected layer with twenty neurons and relu non-linearity.\n",
    "The structure of the network corresponds to the  structure of input data.\n",
    "You can observe that each module dealing with multiple-instance data contains an aggregation layer with element-wise mean and maximum."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductModel ↦ ArrayModel(Dense(20, 21))\u001b[39m\u001b[90m \t# 2 arrays, 441 params, 1.801 KiB\u001b[39m\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31mBagModel ↦ [SegmentedMean(20); SegmentedMax(20)] ↦ ArrayModel(Dense(40, 20, relu))\u001b[39m\u001b[90m \t# 4 arrays, 860 params, 3.516 KiB\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39mArrayModel(Dense(3477, 20, relu))\u001b[90m \t# 2 arrays, 69_560 params, 271.797 KiB\u001b[39m"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "m = reflectinmodel(sch, extract_data,\n",
    "\tlayer -> Dense(layer,20,relu),\n",
    "\tbag -> SegmentedMeanMax(bag),\n",
    "\tfsm = Dict(\"\" => layer -> Dense(layer, size(target, 1))),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training the model\n",
    "Mill library is compatible with MLDataPattern for manipulating with data (training / testing / minibatchsize preparation) and with Flux.\n",
    "Please, refer to these two libraries for support.\n",
    "Below, data are first split into training and validation sets.\n",
    "Then Adam optimizer for training the model is initialized, and loss function is defined.\n",
    "We also define callback which perpetually reports accuracy on validation data during the training."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "#9 (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "valdata, valtarget = data[n_samples-n_val:n_samples], target[:,n_samples-n_val:n_samples]\n",
    "traindata, traintarget = data[1:n_samples-n_val], target[:,1:n_samples-n_val]\n",
    "opt = Flux.Optimise.ADAM()\n",
    "loss(x, y) = Flux.logitcrossentropy(m(x).data, y)\n",
    "loss(xy::Tuple) = loss(xy...)\n",
    "cb = () -> println(\"accuracy = \",mean(Flux.onecold(m(valdata).data) .== Flux.onecold(valtarget)))"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we compute the accuracy."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.06897959183673469"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "cell_type": "code",
   "source": [
    "mean(Flux.onecold(m(traindata).data) .== Flux.onecold(traintarget))"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we obtain the trainable parameters from the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Params([Float32[0.041041154 -0.01617369 … 0.0063797124 -0.017034061; 0.037732817 0.024376592 … -0.0028466952 -0.029412467; … ; -0.007948674 0.03527807 … -0.00081654266 0.0001483182; 0.03573877 -0.016277228 … 0.011694804 0.031276625], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.2374293 0.08604232 … 0.20610823 0.038974207; 0.025234412 -0.051515754 … 0.08548961 -0.22369963; … ; -0.09654004 0.20820796 … -0.10044876 -0.13736232; 0.2993193 0.026034877 … -0.28702736 0.23350024], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.0450968 -0.063696 … -0.17814659 0.38099957; -0.24863204 -0.21428676 … 0.14623253 -0.19950746; … ; 0.0970263 0.20243138 … 0.030860305 0.0034465864; 0.35531366 0.16033764 … 0.1858498 0.26288825], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "ps = Flux.params(m)"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use `MLDataPattern.RandomBatches` to make mini-batches from the training data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomBatches(::Tuple{Mill.ProductNode{NamedTuple{(:ingredients,), Tuple{Mill.BagNode{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000d95, 1, 2, Vector{UInt32}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}, Flux.OneHotArray{UInt32, 0x00000015, 1, 2, Vector{UInt32}}}, 10, 20, (ObsDim.Undefined(), ObsDim.Last()))\n Iterator providing 20 batches of size 10"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "minibatches = RandomBatches((traindata, traintarget), size = minibatchsize, count = iterations)"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we try to compute the loss and perform single step of the gradient descend to see if all works correctly."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "loss(first(minibatches))\n",
    "gs = gradient(() -> loss(first(minibatches)), ps)\n",
    "Flux.Optimise.update!(opt, ps, gs)"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this step we finally train the classifier using the loss we have defined above."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.0297029702970297\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "Flux.Optimise.train!(loss, ps, minibatches, opt, cb = Flux.throttle(cb, 2))"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reporting accuracy on validation data\n",
    "As last steps, we calculate accuracy on training and validation data after the model has been trained."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0297029702970297"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "mean(Flux.onecold(m(traindata).data) .== Flux.onecold(traintarget))\n",
    "mean(Flux.onecold(m(valdata).data) .== Flux.onecold(valtarget))"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "This concludes our example on training the classifier to recogninze cuisine based on ingredients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: describe differences between this approach when we catobs everything and catobsing using minibatches"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "kernelspec": {
   "name": "julia-1.7",
   "display_name": "Julia 1.7.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
