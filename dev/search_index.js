var documenterSearchIndex = {"docs":
[{"location":"#JsonGrinder.jl","page":"Home","title":"JsonGrinder.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JsonGrinder is a collection of routines that facilitates conversion of JSON documents into structures used by Mill.jl project.","category":"page"},{"location":"#Motivation","page":"Home","title":"Motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Imagine that you want to train a classifier on data looking like this","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"ind1\": 1,\n  \"inda\": 0,\n  \"logp\": 6.01,\n  \"lumo\": -2.184,\n  \"mutagenic\": 1,\n  \"atoms\": [\n\t{\n\t  \"element\": \"c\",\n\t  \"atom_type\": 22,\n\t  \"charge\": -0.118,\n\t  \"bonds\": [\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 22,\n\t\t  \"charge\": -0.118\n\t\t},\n\t\t{\n\t\t  \"bond_type\": 1,\n\t\t  \"element\": \"h\",\n\t\t  \"atom_type\": 3,\n\t\t  \"charge\": 0.141\n\t\t},\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 22,\n\t\t  \"charge\": -0.118\n\t\t}\n\t  ]\n\t},\n\t⋮\n\t{\n\t  \"element\": \"c\",\n\t  \"atom_type\": 27,\n\t  \"charge\": 0.012,\n\t  \"bonds\": [\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 22,\n\t\t  \"charge\": -0.118\n\t\t},\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 27,\n\t\t  \"charge\": -0.089\n\t\t},\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 22,\n\t\t  \"charge\": -0.118\n\t\t}\n\t  ]\n\t}\n  ]\n},\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the task is to predict the value in key mutagenic (in this sample it's 1) from the rest of the JSON.","category":"page"},{"location":"","page":"Home","title":"Home","text":"With most machine learning libraries assuming your data being stored as tensors of a fixed dimension, or a sequence, you will have a bad time. Contrary, JsonGrider.jl assumes your data to be stored in a flexible JSON format and tries to automate most labor using reasonable default, but it still gives you an option to control and tweak almost everything. JsonGrinder.jl is built on top of Mill.jl which itself is built on top of Flux.jl (we do not reinvent the wheel). Although JsonGrinder was designed for JSON files, you can easily adapt it to XML, Protocol Buffers, MessagePack, and other similar structures","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are four steps to create a classifier once you load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create a schema of JSON files (using sch = JsonGrinder.schema).\nCreate an extractor converting JSONs to Mill structures (extractor = suggestextractor(sch))). Schema sch from previous step is very helpful, as it helps to identify, how to convert nodes (Dict, Array) to (Mill.ProductNode and Mill.BagNode) and how to convert values in leaves to (Float32, Vector{Float32}, String, Categorical).\nExtract your JSON files into Mill structures using extractor extractbatch(extractor, samples)\nCreate a model for your JSONs, which can be easily done by (using model = reflectinmodel(sch, extractor,...))\nUse your favourite methods to train the model, it is 100% compatible with Flux.jl tooling.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first three steps are handled by JsonGrinder.jl, the fourth step by Mill.jl and the fourth by a combination of Mill.jl and Flux.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Authors see the biggest advantage in the model being hierarchical and reflecting the JSON structure. Thanks to Mill.jl, it can handle missing values at all levels.","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Our idealized workflow is demonstrated in examples/mutagenesis.jl determining mutagenicity on Salmonella typhimurium and it looks as follows (for many datasets which fits in memory it's sufficient just to change the key with labels (labelkey) and names of files to use the example on them):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, Statistics, IterTools, StatsBase, ThreadTools\nusing JsonGrinder: suggestextractor, ExtractDict\nusing Mill: reflectinmodel\n\nsamples = Vector{Dict}(open(JSON.parse, \"../data/mutagenesis/data.json\"))\n\nmetadata = open(JSON.parse, \"data/mutagenesis/meta.json\")\nlabelkey = metadata[\"label\"]\nval_num = metadata[\"val_samples\"]\ntest_num = metadata[\"test_samples\"]\nminibatchsize = 100\niterations = 1_000\nneurons = 20 \t\t# neurons per layer\n\ntargets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\n\ntrain_indices = 1:length(samples)-val_num-test_num\nval_indices = length(samples)-val_num-test_num+1:length(samples)-test_num\ntest_indices = length(samples)-test_num+1:length(samples)\n\n#####\n#  Create the schema and extractor\n#####\nsch = JsonGrinder.schema(samples)\nextractor = suggestextractor(sch)\n\n#####\n#  Convert samples to Mill structure and extract targets\n#####\ndata = tmap(extractor, samples)\nlabelnames = unique(targets)\n\n#####\n#  Create the model\n#####\nmodel = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> meanmax_aggregation(d),\n\tfsm = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)\n\n#####\n#  Train the model\n#####\nfunction minibatch()\n\tidx = sample(1:length(data[train_indices]), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = mean(labelnames[Flux.onecold(model(x).data)] .== y)\n\ntrainset = reduce(catobs, data[train_indices])\nvalset = reduce(catobs, data[val_indices])\ntestset = reduce(catobs, data[test_indices])\n\ncb = () -> begin\n\ttrain_acc = accuracy(trainset, targets[train_indices])\n\tval_acc = accuracy(valset, targets[val_indices])\n\ttest_acc = accuracy(testset, targets[test_indices])\n\tprintln(\"accuracy: train = $train_acc, val = $val_acc, test = $test_acc\")\nend\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))\n\n###############################################################\n#  Classify test set\n###############################################################\n\nprobs = softmax(model(testset).data)\no = Flux.onecold(probs)\npred_classes = labelnames[o]\n\nprint(mean(pred_classes .== targets[test_indices]))\n# we see the accuracy is around 79% on test set\n\n#predicted classes for test set\nprint(pred_classes)\n#gt classes for test set\nprint(targets[test_indices])\n# probabilities for test set\nprint(probs)","category":"page"},{"location":"#A-walkthrough-of-the-example","page":"Home","title":"A walkthrough of the example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here we include libraries and load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, Statistics, IterTools, StatsBase, ThreadTools\nusing JsonGrinder: suggestextractor, ExtractDict\nusing Mill: reflectinmodel\nsamples = Vector{Dict}(open(JSON.parse, \"../../data/mutagenesis/data.json\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"we load metadata, which store which class is to be predicted and how many samples to be used for validation and for testing","category":"page"},{"location":"","page":"Home","title":"Home","text":"metadata = open(JSON.parse, \"../../data/mutagenesis/meta.json\")\nval_num = metadata[\"val_samples\"]\ntest_num = metadata[\"test_samples\"]\nminibatchsize = 100\niterations = 1_000\nneurons = 20 \t\t# neurons per layer\nlabelkey = metadata[\"label\"]","category":"page"},{"location":"","page":"Home","title":"Home","text":"we see  that label to be predicted is mutagenic.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We create labels and remove them from data, such that we do not use them as features. We also prepare indices of train, test and validation data here.","category":"page"},{"location":"","page":"Home","title":"Home","text":"targets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\n\ntrain_indices = 1:length(samples)-val_num-test_num\nval_indices = length(samples)-val_num-test_num+1:length(samples)-test_num\ntest_indices = length(samples)-test_num+1:length(samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We create the schema of data","category":"page"},{"location":"","page":"Home","title":"Home","text":"sch = JsonGrinder.schema(samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then we use it to create the extractor converting jsons to Mill structure. The suggestextractor is executed below with default setting, but it allows you heavy customization.","category":"page"},{"location":"","page":"Home","title":"Home","text":"extractor = suggestextractor(sch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We convert jsons to mill data samples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = tmap(extractor, samples)\nlabelnames = unique(targets)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We create the model reflecting structure of the data","category":"page"},{"location":"","page":"Home","title":"Home","text":"model = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> meanmax_aggregation(d),\n\tfsm = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"individual arguments of reflectinmodel are explained in Mill.jl documentation","category":"page"},{"location":"","page":"Home","title":"Home","text":"Lastly, we define few handy functions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"function minibatch()\n\tidx = sample(1:length(data[train_indices]), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = mean(labelnames[Flux.onecold(model(x).data)] .== y)\n\ntrainset = reduce(catobs, data[train_indices])\nvalset = reduce(catobs, data[val_indices])\ntestset = reduce(catobs, data[test_indices])\n\ncb = () -> begin\n\ttrain_acc = accuracy(trainset, targets[train_indices])\n\tval_acc = accuracy(valset, targets[val_indices])\n\ttest_acc = accuracy(testset, targets[test_indices])\n\tprintln(\"accuracy: train = $train_acc, val = $val_acc, test = $test_acc\")\nend\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and then we can start trining","category":"page"},{"location":"","page":"Home","title":"Home","text":"Flux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can see the accuracy rising and obtaining over 98% on training set quite quickly, and on validation and test set we get over 70%.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Last part is inference on test data","category":"page"},{"location":"","page":"Home","title":"Home","text":"probs = softmax(model(testset).data)\no = Flux.onecold(probs)\npred_classes = labelnames[o]\n\nprint(mean(pred_classes .== targets[test_indices]))","category":"page"},{"location":"","page":"Home","title":"Home","text":"pred_classes contains the predictions for our test set.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can look at individual samples. For instance, first sample in te test_samples[2] is","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"ind1\": 1,\n  \"inda\": 0,\n  \"logp\": 3.92,\n  \"lumo\": -3.406,\n  \"mutagenic\": 1,\n  \"atoms\": [\n\t{\n\t  \"element\": \"c\",\n\t  \"atom_type\": 22,\n\t  \"charge\": -0.109,\n\t  \"bonds\": [\n\t\t{\n\t\t  \"bond_type\": 1,\n\t\t  \"element\": \"h\",\n\t\t  \"atom_type\": 3,\n\t\t  \"charge\": 0.151\n\t\t},\n\t\t...\n\t\t{\n\t\t  \"bond_type\": 7,\n\t\t  \"element\": \"c\",\n\t\t  \"atom_type\": 22,\n\t\t  \"charge\": -0.109\n\t\t}\n\t  ]\n\t}\n\t...\n\t]\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the corresponding classification is","category":"page"},{"location":"","page":"Home","title":"Home","text":"pred_classes[1]","category":"page"},{"location":"","page":"Home","title":"Home","text":"if you want to see the probability distribution, it can be obtained by applying softmax to the output of the network.","category":"page"},{"location":"","page":"Home","title":"Home","text":"softmax(model(testset[1]).data)","category":"page"},{"location":"","page":"Home","title":"Home","text":"so we can see that the probability that given sample is mutagenetic is almost 1.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This concludes a simple classifier for JSON data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"But keep in mind the framework is general and given its ability to embed hierarchical data into fixed-size vectors, it can be used for classification, regression, and various other ML tasks.","category":"page"},{"location":"api/#API-Documentation","page":"API Documentation","title":"API Documentation","text":"","category":"section"},{"location":"api/","page":"API Documentation","title":"API Documentation","text":"Modules = [JsonGrinder]\nOrder   = [:function, :type, :constant]","category":"page"},{"location":"api/#Base.delete!-Tuple{JsonGrinder.JSONEntry,AbstractString,AbstractString}","page":"API Documentation","title":"Base.delete!","text":"Deletes field at the specified path from the schema sch. For instance, the following: \tdelete!(schema, \".field.subfield.[]\", \"x\") deletes the field x from schema at: \tschema.childs[:field].childs[:subfield].items.childs\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.merge-Tuple{Vararg{JsonGrinder.DictEntry,N} where N}","page":"API Documentation","title":"Base.merge","text":"Dispatch of Base.merge on JsonGrinder.JSONEntry structures. Allows to merge multiple schemas to single one.\n\nmerge(es::Entry...)\nmerge(es::DictEntry...)\nmerge(es::ArrayEntry...)\nmerge(es::MultiEntry...)\nmerge(es::JsonGrinder.JSONEntry...)\n\nit can be used to distribute calculation of schema across multiple workers to merge their partial results into bigger one.\n\nExample\n\nIf we want to calculate schema from e.g. array of jsons in a distributed manner, if we have jsons array and , we can do it using\n\nusing ThreadsX\nThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, length(jsons) ÷ Threads.nthreads()))\n\nor\n\nusing ThreadTools\nmerge(tmap(schema, Threads.nthreads(), Iterators.partition(jsons, length(jsons) ÷ Threads.nthreads()))\n\nor, if you like to split it into multiple jobs and having them processed by multiple threads, it can look like\n\nusing ThreadTools\nmerge(tmap(schema, Threads.nthreads(), Iterators.partition(jsons, 1_000))\n\nwhere we split array to smaller array of size 1k and let all available threads create partial schemas.\n\nIf your data is too large to fit into ram, following approach works well also with filenames and similar other ways to process large data.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.extract_missing_bag-Tuple{JsonGrinder.BagExtractor,Any}","page":"API Documentation","title":"JsonGrinder.extract_missing_bag","text":"returns missing bag of 1 observation\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.extractscalar","page":"API Documentation","title":"JsonGrinder.extractscalar","text":"extractscalar(Type{String}, n = 3, b = 256, m = 2053)\n\nrepresents strings as ngrams with\n\nn (the degree of ngram),\nb base of string,\nm modulo on index of the token to reduce dimension\n\nextractscalar(Type{Number}, m = 0, s = 1)\n\nextracts number subtracting m and multiplying by s\n\nExample\n\njulia> JsonGrinder.extractscalar(String, 3, 256, 2053, true)(\"5\")\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n \"5\"\n\njulia> JsonGrinder.extractscalar(Int32, 3, 256, true)(\"5\")\n1×1 Mill.ArrayNode{Array{Union{Missing, Int32},2},Nothing}:\n 512\n\njulia> JsonGrinder.extractscalar(String, 3, 256, 2053, false)(\"5\")\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{String,Int64},Nothing}:\n \"5\"\n\njulia> JsonGrinder.extractscalar(Int32, 3, 256, false)(\"5\")\n1×1 Mill.ArrayNode{Array{Int32,2},Nothing}:\n 512\n\n\n\n\n\n","category":"function"},{"location":"api/#JsonGrinder.generate_html-Tuple{JsonGrinder.DictEntry}","page":"API Documentation","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(file_name, sch::DictEntry; max_vals=100, max_len=1_000)\n\nexports schema to HTML including CSS style and JS allowing to expand / hide sub-parts of schema, countmaps, and lengthmaps.\n\nArguments\n\nmax_vals controls maximum number of exported values in countmap\nmax_len controls maximum number of exported lengts of arrays\nfile_name a name of file to save HTML with schema\n\nReturn\n\nIf provided filename, it does not return anything. If not, it returns the generated HTML+CSS+JS as a String.\n\nExample\n\nYou can either open the html file in any browser, or open it directly using ElectronDisplay\n\nusing ElectronDisplay\nusing ElectronDisplay: newdisplay\ngenerated_html = generate_html(sch, max_vals = 100)\ndisplay(newdisplay(), MIME{Symbol(\"text/html\")}(), generated_html)\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.make_empty_bag-Tuple{Any,Any}","page":"API Documentation","title":"JsonGrinder.make_empty_bag","text":"returns empty bag of 0 observations\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.newentry-Tuple{Dict}","page":"API Documentation","title":"JsonGrinder.newentry","text":"newentry(v)\n\ncreates new entry describing json according to the type of v\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.prune_json-Tuple{Any,JsonGrinder.Entry}","page":"API Documentation","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nRemoves keys from json which are not part of the schema.\n\nExample\n\njulia> using JSON\n\njulia> j1 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1, \\\"b\\\": 1}}\");\n\njulia> j2 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1}}\");\n\njulia> sch = JsonGrinder.schema([j1,j2])\n[Dict] (updated = 2)\n  ├── a: [Scalar - Int64], 1 unique values, updated = 2\n  └── b: [Dict] (updated = 2)\n           ├── a: [Scalar - Int64], 1 unique values, updated = 2\n           └── b: [Scalar - Int64], 1 unique values, updated = 1\n\njulia> j3 = Dict(\"a\" => 4, \"b\" => Dict(\"a\"=>1), \"c\" => 1, \"d\" => 2)\nDict{String,Any} with 4 entries:\n  \"c\" => 1\n  \"b\" => Dict(\"a\"=>1)\n  \"a\" => 4\n  \"d\" => 2\n\njulia> JsonGrinder.prune_json(j3, sch)\nDict{Any,Any} with 2 entries:\n  \"b\" => Dict{Any,Any}(\"a\"=>1)\n  \"a\" => 4\n\nso the JsonGrinder.prune_json removes keys c and d.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.schema-Tuple{AbstractArray,Function}","page":"API Documentation","title":"JsonGrinder.schema","text":"schema(samples::AbstractArray{<:Dict})\nschema(samples::AbstractArray{<:AbstractString})\nschema(samples::AbstractArray, map_fun::Function)\nschema(map_fun::Function, samples::AbstractArray)\n\ncreates schema from an array of parsed or unparsed JSONs.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.suggestextractor","page":"API Documentation","title":"JsonGrinder.suggestextractor","text":"suggestextractor(e::DictEntry, settings = NamedTuple())\n\ncreate convertor of json to tree-structure of DataNode\n\ne top-level of json hierarchy, typically returned by invoking schema\nsettings can be any container supporting get function\nsettings.mincountkey contains minimum repetition of the key to be included into the extractor (if missing it is equal to zero)\nsettings.key_as_field of the number of keys exceeds this value, it is assumed that keys contains a value, which means that they will be treated as strings.\nsettings.scalar_extractors contains rules for determining which extractor to use for leaves. Default value is return value of default_scalar_extractor(), it's array of pairs where first element is predicate and if it matches, second element, function which maps schema to specific extractor, is called.\n\n\n\n\n\n","category":"function"},{"location":"api/#JsonGrinder.update!-Union{Tuple{T}, Tuple{JsonGrinder.Entry{T},Number}} where T<:Number","page":"API Documentation","title":"JsonGrinder.update!","text":"function update!(a::Entry, v)\n\nupdates the entry when seeing value v\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.updatemaxkeys!-Tuple{Int64}","page":"API Documentation","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of leaves in JSON. Default value is 10_000.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.updatemaxlen!-Tuple{Int64}","page":"API Documentation","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum length of string values in statistics of nodes in JSON. Default value is 10_000. Longer strings will be trimmed and their length and hash will be appended to retain the uniqueness. This is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.ArrayEntry","page":"API Documentation","title":"JsonGrinder.ArrayEntry","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend\n\nkeeps statistics about an array entry in JSON.\n\nitems is typeof Entry or nothing and keeps statistics about the elements of the array\nl keeps histogram of message length\nupdated counts how many times the struct was updated.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.AuxiliaryExtractor","page":"API Documentation","title":"JsonGrinder.AuxiliaryExtractor","text":"struct AuxiliaryExtractor <: AbstractExtractor\n\textractor::AbstractExtractor\n\textract_fun::Function\nend\n\nUniversal extractor for applying any function, which lets you ambed any transformation into the AbstractExtractor machinery. Useful e.g. for extractors accompanying trained models, where you need to apply yet another transformation.\n\njulia> e1 = ExtractDict(Dict(:a=>ExtractString(), :b=>ExtractString()));\n\njulia> e2 = AuxiliaryExtractor(e1, (e,x)->e[:a](x[\"a\"]))\nAuxiliary extractor with\n  └── Dict\n        ├── a: String\n        └── b: String\n\njulia> e2(Dict(\"a\"=>\"Hello\", \"b\"=>\"World\"))\nArrayNode{NGramMatrix{String,Array{String,1},Int64},Nothing}:\n \"Hello\"\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.Entry","page":"API Documentation","title":"JsonGrinder.Entry","text":"mutable struct Entry <: JSONEntry\n\tcounts::Dict{Any,Int}\n\tupdated::Int\nend\n\nKeeps statistics about scalar values of a one key and also about items inside a key\n\ncounts counts how many times given value appeared (at most max_keys is held)\nupdated counts how many times the entry was updated\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractArray","page":"API Documentation","title":"JsonGrinder.ExtractArray","text":"struct ExtractArray{T}\n\titem::T\nend\n\nConvert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.\n\nExamples\n\njulia> ec = ExtractArray(ExtractCategorical(2:4));\n\njulia> ec([2,3,1,4]).data\n4×4 Mill.ArrayNode{Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}},Nothing}:\n  true  false  false  false\n false   true  false  false\n false  false  false   true\n false  false   true  false\n\njulia> es = ExtractArray(ExtractScalar());\n\njulia> es([2,3,4])\nBagNode with 1 obs\n  └── ArrayNode(1×3 Array with Union{Missing, Float32} elements) with 3 obs\n\njulia> es([2,3,4]).data\n1×3 Mill.ArrayNode{Array{Union{Missing, Float32},2},Nothing}:\n 2.0f0  3.0f0  4.0f0\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractCategorical","page":"API Documentation","title":"JsonGrinder.ExtractCategorical","text":"struct ExtractCategorical{V,I} <: AbstractExtractor\n\tkeyvalemap::Dict{V,I}\n\tn::Int\n\tuniontypes::Bool\nend\nExtractCategorical(s::Entry, uniontypes = true)\nExtractCategorical(s::UnitRange, uniontypes = true)\nExtractCategorical(s::Vector, uniontypes = true)\n\nConverts a single item to a one-hot encoded vector. Converts array of items into matrix of one-hot encoded columns. There is always alocated an extra element for a unknown value. If passed missing, if uniontypes is true, returns column of missing values, otherwise raises error. If uniontypes is true, it allows extracting missing values and all extracted values will be of type Union{Missing, <other type>} due to type stability reasons. Otherwise missings extraction is not allowed.\n\nExamples\n\njulia> e = ExtractCategorical(2:4, true);\n\njulia> e([2,3,1,4]).data\n4×4 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n  true  false  false  false\n false   true  false  false\n false  false  false   true\n false  false   true  false\n\njulia> e([1,missing,5]).data\n4×3 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n false  missing  false\n false  missing  false\n false  missing  false\n  true  missing   true\n\njulia> e(4).data\n4×1 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n false\n false\n  true\n false\n\njulia> e(missing).data\n4×1 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n missing\n missing\n missing\n missing\n\njulia> e = ExtractCategorical(2:4, false);\n\njulia> e([2,3,1,4]).data\n4×4 Mill.MaybeHotMatrix{Int64,Int64,Bool}:\n 1  0  0  0\n 0  1  0  0\n 0  0  0  1\n 0  0  1  0\n\njulia> e(4).data\n4×1 Mill.MaybeHotMatrix{Int64,Int64,Bool}:\n 0\n 0\n 1\n 0\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractDict","page":"API Documentation","title":"JsonGrinder.ExtractDict","text":"struct ExtractDict{S} <: AbstractExtractor\n\tdict::S\nend\n\nextracts all items in dict and return them as a Mill.ProductNode. If a key is missing in extracted dict, nothing is passed to the child extractors.\n\nExamples\n\njulia> e = ExtractDict(Dict(:a=>ExtractScalar(Float32, 2, 3), :b=>ExtractCategorical(1:5)))\nDict\n  ├── a: Float32\n  └── b: Categorical d = 6\n\njulia> res1 = e(Dict(\"a\"=>1, \"b\"=>1))\nProductNode with 1 obs\n  ├── a: ArrayNode(1×1 Array with Union{Missing, Float32} elements) with 1 obs\n  └── b: ArrayNode(6×1 MaybeHotMatrix with Union{Missing, Bool} elements) with 1 obs\n\njulia> res1[:a].data\n1×1 Array{Union{Missing, Float32},2}:\n -3.0f0\n\njulia> res1[:b].data\n6×1 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n  true\n false\n false\n false\n false\n false\n\njulia> res2 = e(Dict(\"a\"=>0))\nProductNode with 1 obs\n  ├── a: ArrayNode(1×1 Array with Union{Missing, Float32} elements) with 1 obs\n  └── b: ArrayNode(6×1 MaybeHotMatrix with Union{Missing, Bool} elements) with 1 obs\n\njulia> res2[:a].data\n1×1 Array{Union{Missing, Float32},2}:\n -6.0f0\n\njulia> res2[:b].data\n6×1 Mill.MaybeHotMatrix{Union{Missing, Int64},Int64,Union{Missing, Bool}}:\n missing\n missing\n missing\n missing\n missing\n missing\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractEmpty","page":"API Documentation","title":"JsonGrinder.ExtractEmpty","text":"struct ExtractEmpty end\n\nConcrete type to dispatch on for extraction of empty samples.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractKeyAsField","page":"API Documentation","title":"JsonGrinder.ExtractKeyAsField","text":"struct ExtractKeyAsField{S,V} <: AbstractExtractor\n\tkey::S\n\titem::V\nend\n\nextracts all items in vec and in other and return them as a ProductNode.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractScalar","page":"API Documentation","title":"JsonGrinder.ExtractScalar","text":"struct ExtractScalar{T} <: AbstractExtractor\n\tc::T\n\ts::T\n\tuniontypes::Bool\nend\n\nExtracts a numerical value, centred by subtracting c and scaled by multiplying by s. Strings are converted to numbers.\n\nThe extractor returns ArrayNode{Matrix{Union{Missing, Int64}},Nothing} or it subtypes. If passed missing, it extracts missing values which Mill understands and can work with.\n\nThe uniontypes field determines whether extractor may or may not accept missing. If uniontypes is false, it does not accept missing values. If uniontypes is true, it accepts missing values, and always returns Mill structure of type Union{Missing, T} due to type stability reasons.\n\nIt can be created also using extractscalar(Float32, 5, 2)\n\nExample\n\njulia> ExtractScalar(Float32, 2, 3, true)(1)\n1×1 Mill.ArrayNode{Array{Union{Missing, Float32},2},Nothing}:\n -3.0f0\n\njulia> ExtractScalar(Float32, 2, 3, true)(missing)\n1×1 Mill.ArrayNode{Array{Union{Missing, Float32},2},Nothing}:\n missing\n\njulia> ExtractScalar(Float32, 2, 3, false)(1)\n1×1 Mill.ArrayNode{Array{Float32,2},Nothing}:\n -3.0\n\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractString","page":"API Documentation","title":"JsonGrinder.ExtractString","text":"struct ExtractString{T} <: AbstractExtractor\n\tn::Int\n\tb::Int\n\tm::Int\n\tuniontypes::Bool\nend\n\nRepresents String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.\n\nThe uniontypes field determines whether extractor may or may not accept missing. If uniontypes is false, it does not accept missing values. If uniontypes is true, it accepts missing values, and always returns Mill structure of type Union{Missing, T} due to type stability reasons.\n\nExample\n\njulia> ExtractString(true)(\"hello\")\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n \"hello\"\n\njulia> ExtractString(true)([\"hello\", \"world\"])\n2053×2 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n \"hello\"\n \"world\"\n\njulia> ExtractString(true)([\"hello\", missing])\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n missing\n\njulia> ExtractString(true)(missing)\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n missing\n\njulia> ExtractString(false)(\"hello\")\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{String,Int64},Nothing}:\n \"hello\"\n\njulia> ExtractString(false)([\"hello\", \"world\"])\n2053×2 Mill.ArrayNode{Mill.NGramMatrix{String,Int64},Nothing}:\n \"hello\"\n \"world\"\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractVector","page":"API Documentation","title":"JsonGrinder.ExtractVector","text":"struct ExtractVector{T} <: AbstractExtractor\n    n::Int\n    uniontypes::Bool\nend\n\nrepresents an array of a fixed length, typically a feature vector of numbers of type T\n\njulia> sc = ExtractVector(4)\njulia> sc([2,3,1,4]).data\n3×1 Array{Float32,2}:\n 2.0\n 3.0\n 1.0\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.MultiEntry","page":"API Documentation","title":"JsonGrinder.MultiEntry","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{Any}\nend\n\nsupport for JSON which does not adhere to a fixed type. Container for multiple types of entry which are observed on the same place in JSON.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.MultipleRepresentation","page":"API Documentation","title":"JsonGrinder.MultipleRepresentation","text":"MultipleRepresentation(extractors::Tuple)\n\nExtractor extracts item to a ProductNode where each item is different extractor and item is extracted by all extractors in multirepresentation.\n\nExamples\n\nExample of both categorical and string representation\n\nOne of usecases is to use string representation for strings and categorical variable representation for most frequent values. This allows model to more easily learn frequent or somehow else significant values, which creating meaningful representation for previously unseen inputs.\n\njulia> e = MultipleRepresentation((ExtractString(false), ExtractCategorical([\"tcp\", \"udp\", \"dhcp\"], false)));\n\njulia> s1 = e(\"tcp\")\nProductNode with 1 obs\n  ├── e1: ArrayNode(2053×1 NGramMatrix with Int64 elements) with 1 obs\n  └── e2: ArrayNode(4×1 MaybeHotMatrix with Bool elements) with 1 obs\n\njulia> s1[:e1]\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{String,Int64},Nothing}:\n \"tcp\"\n\njulia> s1[:e2]\n4×1 Mill.ArrayNode{Mill.MaybeHotMatrix{Int64,Int64,Bool},Nothing}:\n 0\n 1\n 0\n 0\n\njulia> s2 = e(\"http\")\nProductNode with 1 obs\n  ├── e1: ArrayNode(2053×1 NGramMatrix with Int64 elements) with 1 obs\n  └── e2: ArrayNode(4×1 MaybeHotMatrix with Bool elements) with 1 obs\n\njulia> s2[:e1]\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{String,Int64},Nothing}:\n \"http\"\n\njulia> s2[:e2]\n4×1 Mill.ArrayNode{Mill.MaybeHotMatrix{Int64,Int64,Bool},Nothing}:\n 0\n 0\n 0\n 1\n\nExample of irregular schema representation\n\nThe other usecase is to handle irregular schema, where extractor returns missing representation if it's unable to extract it properly. Of course there do not have to be only leaf value extractors, some extractors may be ExtractDict, while other are extracting leaves etc.\n\njulia> e = MultipleRepresentation((ExtractString(), ExtractScalar(Float32, 2, 3)));\n\njulia> s1 = e(5)\nProductNode with 1 obs\n  ├── e1: ArrayNode(2053×1 NGramMatrix with Union{Missing, Int64} elements) with 1 obs\n  └── e2: ArrayNode(1×1 Array with Union{Missing, Float32} elements) with 1 obs\n\njulia> s1[:e1]\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n missing\n\njulia> s1[:e2]\n1×1 Mill.ArrayNode{Array{Union{Missing, Float32},2},Nothing}:\n 9.0f0\n\njulia> s2 = e(\"hi\")\nProductNode with 1 obs\n  ├── e1: ArrayNode(2053×1 NGramMatrix with Union{Missing, Int64} elements) with 1 obs\n  └── e2: ArrayNode(1×1 Array with Union{Missing, Float32} elements) with 1 obs\n\njulia> s2[:e1]\n2053×1 Mill.ArrayNode{Mill.NGramMatrix{Union{Missing, String},Union{Missing, Int64}},Nothing}:\n \"hi\"\n\njulia> s2[:e2]\n1×1 Mill.ArrayNode{Array{Union{Missing, Float32},2},Nothing}:\n missing\n\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.extractempty","page":"API Documentation","title":"JsonGrinder.extractempty","text":"extractempty\n\nA singleton of type ExtractEmpty is used to signal downstream extractors that they should extract an empty sample.\n\n\n\n\n\n","category":"constant"},{"location":"hierarchical/#HierarchicalUtils.jl","page":"External tools","title":"HierarchicalUtils.jl","text":"","category":"section"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"JsonGrinder.jl uses HierarchicalUtils.jl which brings a lot of additional features.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"using HierarchicalUtils","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"Let's say we gave complex schema and we want to find type instabilities.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"After creating the schema as","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"using JSON, JsonGrinder\nj1 = JSON.parse(\"\"\"{\"a\": 4, \"b\": \"birb\"}\"\"\")\nj2 = JSON.parse(\"\"\"{\"a\": { \"a\": \"hello\", \"b\":[5,6]}, \"b\": \"bird\"}\"\"\")\nj3 = JSON.parse(\"\"\"{\"a\": [1, 2, 3, \"hi\"], \"b\": \"word\"}\"\"\")\n\nsch = schema([j1, j2, j3])","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"In small enough schema, you can immediately see all types of nodes, but it gets more complicated if the schema does not fit your screen. Let's see how we can leverage HierarchicalUtils to programmatically examine shema.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"This can be used to print a non-truncated version of a model:","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"printtree(sch)","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"Callling with trav=true enables convenient traversal functionality with string indexing:","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"printtree(sch, trav=true)","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"This way any element in the schema is swiftly accessible, which may come in handy when inspecting model parameters or simply deleting/replacing/inserting nodes to tree (for instance when constructing adversarial samples). All tree nodes are accessible by indexing with the traversal code:","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"sch[\"N\"]","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"The following two approaches give the same result:","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"sch[\"N\"] === sch.childs[:a][2][:a]","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"We can even search for specific elements in schema. Let's examine occurrences of irregularities a.k.a. MultiEntry by running","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"TypeIterator(JsonGrinder.MultiEntry, sch) |> collect","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"which tells us there are 2 multientries, but does not tell us where they are.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"Using this","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"filter(e->sch[e] isa JsonGrinder.MultiEntry, list_traversal(sch))","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"we can see that sch[\"E\"] and sch[\"S\"] are indeed MultiEntry, but we don't have easy way to see where they are in schema.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"using Mill\nlenses = [only(code2lens(sch, e)) for e in list_traversal(sch) if sch[e] isa JsonGrinder.MultiEntry]","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"gives us lenses to access them and also information about path from root. @lens is part of Setfield.jl package which allows creating lenses which let you easily describe and apply accessors for hierarchical structures.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"get(sch, lenses[1])","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"returns the first MultiEntry and","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"get(sch, lenses[2])","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"returns the second one.","category":"page"},{"location":"hierarchical/","page":"External tools","title":"External tools","text":"For the complete showcase of possibilities, refer to HierarchicalUtils.jl and this notebook","category":"page"},{"location":"citation/#Citation","page":"Citation","title":"Citation","text":"","category":"section"},{"location":"citation/","page":"Citation","title":"Citation","text":"For citing, please use the following entry:","category":"page"},{"location":"citation/","page":"Citation","title":"Citation","text":"@misc{JsonGrinder2019,\n    author = {Tomáš Pevný and Matěj Račinský},\n    title = {{JsonGrinder.jl}},\n    year = 2019,\n    howpublished = \"\\url{https://github.com/CTUAvastLab/JsonGrinder.jl}\"\n}","category":"page"},{"location":"schema/#Schema","page":"Schema","title":"Schema","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"The schema helps to understand the structure of JSON files, by which we understand the types of nodes (Dict, Array, Values) and frequency of occurrences of values and lengths of arrays. The schema also holds statistics about how many times the node has been present. All this information is taken into the account by suggestextractor function, which takes a schema and using few reasonable heuristic, suggests an extractor, which convert jsons to Mill structure. The schema might be also useful for formats with enforced schema to collect statistics on leaves.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The main function to create schema is schema, which accepts a list of (unparsed) JSONs and producing schema. Schema can be always updated to reflect new JSONs and allow streaming by update! function. Moreover, schema accepts an optional argument, a function converting an element of an array to a JSON. This a function creating schema from all jsons in a dictionary can look like","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"schema(readdir(\"jsons\", join = true)) do s\n\topen(s,\"r\") do fio\n\t\tread(fio, String)\n\tend |> JSON.parse\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"schema function has following default behavior: If passed array of strings, it consideres them to be json documents as strings passes each element as an argument to JSON.parse function.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"A schema can be further updated by calling function update!(sch, json). Schemas can be merged using the overloaded merge function, which facilitates distributed creation of schema following map-reduce paradigm.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema can be saved in html by generate_html allowing their interactive exploration. Calling generate_html(filename, sch) will generate self-contained file with HTML+CSS+JS. The generated visualization is interactive, implemented using VanillaJS.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema assumes the root of each JSON is dictionary.","category":"page"},{"location":"schema/#Implementation-details","page":"Schema","title":"Implementation details","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"Statistics are collected in a hierarchical structure reflecting the structured composed of DictEntry, ArrayEntry, and Entry. These structures reflect those in JSON: Dict, Array, and Value (either String or a Number). Sometimes, data are stored in JSONs not adhering to a stable schema, which happens if one key have children of different type. An example of such would be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\": [1,2,3]}\n{\"a\": {\"b\": 1}}\n{\"a\": \"hello\"}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"For such cases, we have introduced additional JSONEntry, a MultiEntry, but we discourage to rely on this feature and recommend to adapt JSONs to have stable schema (if possible). This can be achieved by modifying each sample before it's passed into the schema.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Each subtype of JSONEntry implements the update! function, which recursively updates the schema.","category":"page"},{"location":"schema/#Entry","page":"Schema","title":"Entry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct Entry{T} <: JSONEntry\n\tcounts::Dict{T,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Entry keeps information about leaf-values (e.g. \"a\" = 3) (strings or numbers) in JSONs. It consists of two statistics","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"updated counts how many times the leaf in a given position in JSON was observed,\ncounts counts how many times a particular value of that leaf was observed.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To keep counts dictionary from becoming too large, once its length exceeds JsonGrinder.max_keys (default is 10_000), then the new values will be dropped. This value can be changed by JsonGrinder.updatemaxkeys!(some_higher_value), but of course the new limit will be applied only to newly processed values, so it's advised to set it in the beginning of your scripts.","category":"page"},{"location":"schema/#ArrayEntry","page":"Schema","title":"ArrayEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ArrayEntry keeps information about arrays (e.g. \"a\": [1,2,3,4]). Statistics about individual items of the array are deferred to item, which can be <:JSONEntry. l keeps histogram of lengths of arrays, and updated is number of times an array has been observed in particular place in JSON.","category":"page"},{"location":"schema/#DictEntry","page":"Schema","title":"DictEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct DictEntry <: JSONEntry\n\tchilds::Dict{Symbol, Any}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"defers all statistics about its children to them, and the only statistic is again a counter updated about number of observations. Fields childs contains all keys which were observed in specific Dictionary and their corresponding <:JSONEntry values with statistics about values observed under given key.","category":"page"},{"location":"schema/#MultiEntry","page":"Schema","title":"MultiEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{JSONEntry}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"is a failsafe for cases, where the schema is not stable. For example in following two JSONs","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\": \"Hello\"}\n{\"a\": [\"Hello\",\" world\"]}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"the type of a value of a key \"a\" is String, whereas in the second it is \"Vector\". The JsonGrinder will deal with this by first creating an Entry, since the value is scalar, and upon encountering the second JSON, it will replace Entry with MultiEntry having Entry and ArrayEntry as children (this is the reason why entries are declared mutable).","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"While JsonGrinder can deal with non-stable jsons, it is strongly discouraged as it might have negative effect on the performance.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Usefulness of such feature comes into play also when you don't know if your schema is stable or not. In that case, you can calculate the schema, and then search for MultiEntry nodes.","category":"page"},{"location":"schema/#Illustrative-example","page":"Schema","title":"Illustrative example","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"Let's say we have following jsons. We take them and create a schema.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"using JSON, JsonGrinder\njsons = [\n       \"\"\"{\"a\": \"Hello\", \"b\":{\"c\":1, \"d\":1}}\"\"\",\n       \"\"\"{\"a\": [\"Hi\", \"Julia\"], \"b\":{\"c\":1, \"d\":[1,2,3]}}\"\"\",\n       \"\"\"{\"a\": \"World\", \"b\":{\"c\":2, \"d\":2}}\"\"\",\n]\nsch = schema(JSON.parse, jsons)","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"you can visualize schema by","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> display(sch)\n[Dict] (updated = 3)\n  ├── a: [MultiEntry] (updated = 3)\n  │        ├── 1: [Scalar - String], 2 unique values, updated = 2\n  │        └── 2: [List] (updated = 1)\n  │                 ⋮\n  └── b: [Dict] (updated = 3)\n           ├── c: [Scalar - Int64], 2 unique values, updated = 3\n           └── d: [MultiEntry] (updated = 3)\n                    ⋮","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"which shows only reasonable part.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To see whole schema, we can use printtree(ds; htrunc=Inf, vtrunc=Inf, trav=true) from HierarchicalUtils.jl which prints the whole schema, together with identifiers of individual nodes:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> printtree(sch; htrunc=Inf, vtrunc=Inf, trav=true)\n[Dict] (updated = 3) [\"\"]\n  ├── a: [MultiEntry] (updated = 3) [\"E\"]\n  │        ├── 1: [Scalar - String], 2 unique values, updated = 2 [\"I\"]\n  │        └── 2: [List] (updated = 1) [\"M\"]\n  │                 └── [Scalar - String], 2 unique values, updated = 2 [\"O\"]\n  └── b: [Dict] (updated = 3) [\"U\"]\n           ├── c: [Scalar - Int64], 2 unique values, updated = 3 [\"Y\"]\n           └── d: [MultiEntry] (updated = 3) [\"c\"]\n                    ├── 1: [Scalar - Int64], 2 unique values, updated = 2 [\"d\"]\n                    └── 2: [List] (updated = 1) [\"e\"]\n                             └── [Scalar - Int64], 3 unique values, updated = 3 [\"eU\"]","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Strings at the end of each row can be used as a key to access individual elements of the schema. To learn more about HierarchicalUtils.jl check their docs or section about HierarchicalUtils.jl in Mill.jl documentation","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Here, we see that we have 2 MultiEntry, thus 2 type instabilities in our jsons. The first MultiEntry (key \"E\") has 2 children: Entry and ArrayEntry.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The sch[\"E\"].updated is 3, because value under key a in json has been observed 3 times. The sch[\"I\"].updated is 2, because string value was seen 2 times under a. As expected, we can see","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"I\"].counts\nDict{String,Int64} with 2 entries:\n  \"Hello\" => 1\n  \"World\" => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"and in the ArrayEntry we can see sch[\"M\"].updated is 1, because array has been observed once in key a. The freqency of lengths is following:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"M\"].l\nDict{Int64,Int64} with 1 entry:\n  2 => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"because we have observed one array of length 2. sch[\"M\"].items is Entry.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The Entry (can be accessed by sch[\"M\"].items or by sch[\"O\"]) has fields with following values:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"sch[\"O\"].updated is 2, because we have observed 2 elements in array under key a.  ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"counts is","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"O\"].counts\nDict{String,Int64} with 2 entries:\n\"Hi\"    => 1\n\"Julia\" => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"which corresponds to individual elements of an array we have observed.","category":"page"},{"location":"schema/#Extra-functions","page":"Schema","title":"Extra functions","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"While schema can be printed to REPL, it can contain quite a lot of information. Therefore JsonGrinder.generate_html exports it to HTML, where parts can be expanded at wish.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.generate_html","category":"page"},{"location":"schema/#JsonGrinder.generate_html","page":"Schema","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(file_name, sch::DictEntry; max_vals=100, max_len=1_000)\n\nexports schema to HTML including CSS style and JS allowing to expand / hide sub-parts of schema, countmaps, and lengthmaps.\n\nArguments\n\nmax_vals controls maximum number of exported values in countmap\nmax_len controls maximum number of exported lengts of arrays\nfile_name a name of file to save HTML with schema\n\nReturn\n\nIf provided filename, it does not return anything. If not, it returns the generated HTML+CSS+JS as a String.\n\nExample\n\nYou can either open the html file in any browser, or open it directly using ElectronDisplay\n\nusing ElectronDisplay\nusing ElectronDisplay: newdisplay\ngenerated_html = generate_html(sch, max_vals = 100)\ndisplay(newdisplay(), MIME{Symbol(\"text/html\")}(), generated_html)\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema supports merging using Base.merge, which facilitates parallel computation of schemas. An example might be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, div(length(jsons), Threads.nthreads())))","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.prune_json","category":"page"},{"location":"schema/#JsonGrinder.prune_json","page":"Schema","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nRemoves keys from json which are not part of the schema.\n\nExample\n\njulia> using JSON\n\njulia> j1 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1, \\\"b\\\": 1}}\");\n\njulia> j2 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1}}\");\n\njulia> sch = JsonGrinder.schema([j1,j2])\n[Dict] (updated = 2)\n  ├── a: [Scalar - Int64], 1 unique values, updated = 2\n  └── b: [Dict] (updated = 2)\n           ├── a: [Scalar - Int64], 1 unique values, updated = 2\n           └── b: [Scalar - Int64], 1 unique values, updated = 1\n\njulia> j3 = Dict(\"a\" => 4, \"b\" => Dict(\"a\"=>1), \"c\" => 1, \"d\" => 2)\nDict{String,Any} with 4 entries:\n  \"c\" => 1\n  \"b\" => Dict(\"a\"=>1)\n  \"a\" => 4\n  \"d\" => 2\n\njulia> JsonGrinder.prune_json(j3, sch)\nDict{Any,Any} with 2 entries:\n  \"b\" => Dict{Any,Any}(\"a\"=>1)\n  \"a\" => 4\n\nso the JsonGrinder.prune_json removes keys c and d.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxkeys!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxkeys!","page":"Schema","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of leaves in JSON. Default value is 10_000.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxlen!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxlen!","page":"Schema","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum length of string values in statistics of nodes in JSON. Default value is 10_000. Longer strings will be trimmed and their length and hash will be appended to retain the uniqueness. This is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"function"},{"location":"exfunctions/#Extractors-overview","page":"Extractors overview","title":"Extractors overview","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Below, we first describe extractors of values (i.e. leaves of JSON tree), then proceed to description of extractors of Array and Dict, and finish with some specials.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Extractors of scalar values are arguably the most important, but also fortunately the most understood ones. They control, how values are converted to a Vector (or generally tensor) for the neural networks. For example they control, if number should be represented as a number, or as one-hot encoded categorical variable. Similarly, they control how String should be treated, although we admit to natively support only n-grams.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Because mapping from JSON (or different hierarchical structure) to Mill structures can be non-trivial, extractors have keyword argument store_input, which, if true, causes input data to be stored as metadata of respective Mill structure. By default, it's false, because it can cause type-instability in case of irregular input data and thus suffer from performance loss. The store_input argument is propagated to leaves and is used to store primarily leaf values.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Because JsonGrinder supports working with missing values, each leaf extractor has uniontypes field which determines if it can return missing values or not, and based on this field, extractor returns appropriate data type. By default, uniontypes is true, so it supports missing values of the shelf, but we advice to set it during extractor construction according to your data because it may create unnecessarily many parameters otherwise. suggestextractor takes into account where missing values can be observed and where not based on statistics in schema and provides sensible default extractor.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Recall","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"using JsonGrinder, Mill, JSON, StatsBase","category":"page"},{"location":"exfunctions/#Numbers","page":"Extractors overview","title":"Numbers","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"struct ExtractScalar{T} <: AbstractExtractor\n\tc::T\n\ts::T\n\tuniontypes::Bool\nend","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Extracts a numerical value, centered by subtracting c and scaled by multiplying by s. Strings are converted to numbers. The extractor returns ArrayNode{Matrix{T}} with a single row if uniontypes if false, and ArrayNode{Matrix{Union{Missing, T}}} with a single row if uniontypes if true.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e = ExtractScalar(Float32, 0.5, 4.0, true)\ne(\"1\").data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(missing)","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"the e(\"1\") is equivalent to e(\"1\", store_input=false). To see input data in metadata of ArrayNode, we can run","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(\"1\", store_input=true).metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"data remain unchanged","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(\"1\", store_input=true).data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"by default, metadata contains nothing.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"And if uniontypes is false, it looks as follows","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e = ExtractScalar(Float32, 0.5, 4.0, true)\ne(\"1\").data\ne(\"1\", store_input_true=true).data\ne(\"1\", store_input_true=true).metadata\ne(missing)","category":"page"},{"location":"exfunctions/#Strings","page":"Extractors overview","title":"Strings","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"struct ExtractString <: AbstractExtractor\n\tn::Int\n\tb::Int\n\tm::Int\n\tuniontypes::Bool\nend","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Represents String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e = ExtractString()\ne(\"Hello\")","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(missing)","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Storing input works in the same manner as for ExtractScalar, see","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(\"Hello\", store_input=true).metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"it works the same also with missing values","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(missing, store_input=true).metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"and if we know we won't have missing strings, we can disable uniontypes:","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e = ExtractString(false)\ne(\"Hello\")\ne(missing)\ne(\"Hello\", store_input=true).metadata","category":"page"},{"location":"exfunctions/#Categorical","page":"Extractors overview","title":"Categorical","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"struct ExtractCategorical{V,I} <: AbstractExtractor\n\tkeyvalemap::Dict{V,I}\n\tn::Int\n\tuniontypes::Bool\nend","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Converts a single item to a one-hot encoded vector. For a safety, there is always an extra item reserved for an unknown value.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e = ExtractCategorical([\"A\",\"B\",\"C\"])\ne([\"A\",\"B\",\"C\",\"D\"]).data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e(missing)","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Storing input in this case looks as follows","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"e([\"A\",\"B\",\"C\",\"D\"], store_input=true).metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"uniontypes settings works the same as with scalars or strings.","category":"page"},{"location":"exfunctions/#Array-(Lists-/-Sets)","page":"Extractors overview","title":"Array (Lists / Sets)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"struct ExtractArray{T}\n\titem::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Convert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"sc = ExtractArray(ExtractCategorical([\"A\",\"B\",\"C\"]))\nsc([\"A\",\"B\",\"C\",\"D\"])","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Empty arrays are represented as an empty bag.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"sc([]).bags","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"The data of empty bag can be either missing or a empty sample, which is more convenient as it makes all samples of the same type, which is nicer to AD. This behavior is controlled by Mill.emptyismissing. The extractor of a BagNode can signal to child extractors to extract a sample with zero observations using a special singleton JsonGrinder.extractempty. For example","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Mill.emptyismissing!(true)\nsc([]).data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Mill.emptyismissing!(false)\nsc([]).data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Storing input is delegated to leaf extractors, so metadata of bag itself are empty","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"sc([\"A\",\"B\",\"C\",\"D\"], store_input=true).metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"but metadata of underlying ArrayNode contain inputs.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"sc([\"A\",\"B\",\"C\",\"D\"], store_input=true).data.metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"In case of empty arrays, input is stored in metadata of BagNode itself, because there might not be any underlying ArrayNode.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"sc([], store_input=true).metadata","category":"page"},{"location":"exfunctions/#exfuctions_ExtractDict","page":"Extractors overview","title":"Dict","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"struct ExtractDict{S} <: AbstractExtractor\n\tdict::S\nend","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Extracts all items in dict and return them as a ProductNode. Key in dict corresponds to keys in JSON.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex = ExtractDict(Dict(:a => ExtractScalar(),\n\t:b => ExtractString(),\n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]))","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Missing keys are replaced by missing and handled by child extractors.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex(Dict(:a => \"1\",\n\t:c => \"A\"))","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Storing input data works in similar manner as for ExtractArray, input data are delegated to leaf extractors.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex(Dict(:a => \"1\",\n\t:c => \"A\"), store_input=true).metadata\nex(Dict(:a => \"1\",\n\t:c => \"A\"), store_input=true)[:a].metadata\nex(Dict(:a => \"1\",\n\t:c => \"A\"), store_input=true)[:b].metadata\nex(Dict(:a => \"1\",\n\t:c => \"A\"), store_input=true)[:c].metadata\nex(Dict(:a => \"1\",\n\t:c => \"A\"), store_input=true)[:d].metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"or","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true).metadata\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true)[:a].metadata\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true)[:b].metadata\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true)[:c].metadata\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true)[:d].metadata\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]), store_input=true)[:d].data.metadata","category":"page"},{"location":"exfunctions/#Specials","page":"Extractors overview","title":"Specials","text":"","category":"section"},{"location":"exfunctions/#ExtractKeyAsField","page":"Extractors overview","title":"ExtractKeyAsField","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Some JSONs we have encountered use Dicts to hold an array of named lists (or other types). Having computer security background a prototypical example is storing a list of DLLs with a corresponding list of imported function in a single structure. For example a JSON","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"{ \"foo.dll\" : [\"print\",\"write\", \"open\",\"close\"],\n  \"bar.dll\" : [\"send\", \"recv\"]\n}","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"should be better written as","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"[{\"key\": \"foo.dll\",\n  \"item\": [\"print\",\"write\", \"open\",\"close\"]},\n  {\"key\": \"bar.dll\",\n  \"item\": [\"send\", \"recv\"]}\n]","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"JsonGrinder tries to detect these cases, as they are typically manifested by Dicts with excessively large number of keys in a schema. The detection logic of this case in suggestextractor(e::DictEntry) is simple, if the number of unique keys in a specific Dict is greater than settings.key_as_field = 500, such Dict is considered to hold values in keys and ExtractKeyAsField is used instead of ExtractDict. key_as_field can be set to any value based on specific data or domain, but we have found 500 to be reasonable default.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"The extractor itself is simple as well. For the case above, it would look like","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"s = JSON.parse(\"{ \\\"foo.dll\\\" : [\\\"print\\\",\\\"write\\\", \\\"open\\\",\\\"close\\\"],\n  \\\"bar.dll\\\" : [\\\"send\\\", \\\"recv\\\"]\n}\")\nex = ExtractKeyAsField(ExtractString(),ExtractArray(ExtractString()))\nex(s)","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"As you might expect, inputs are stored in leaf metadata if needed","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex(s, store_input=true).metadata\nex(s, store_input=true).data[:key].metadata\nex(s, store_input=true).data[:item].data.metadata","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Because it returns BagNode, missing values are treated in similar manner as in ExtractArray and settings of Mill.emptyismissing applies here too.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Mill.emptyismissing!(true)\nex(Dict()).data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Mill.emptyismissing!(false)\nex(Dict()).data","category":"page"},{"location":"exfunctions/#MultipleRepresentation","page":"Extractors overview","title":"MultipleRepresentation","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Provides a way to have multiple representations for a single value or subtree in JSON. For example imagine that are extracting strings with some very frequently occurring values and a lots of clutter, which might be important and you do not know about it. MultipleRepresentation(extractors::Tuple) contains a Tuple or NamedTuple of extractors and apply them to a single sub-tree in a json. The corresponding Mill structure will contain ProductNode of both representation.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"For example String with Categorical and NGram representation will look like","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex = MultipleRepresentation((c = ExtractCategorical([\"Hello\",\"world\"]), s = ExtractString()))\nreduce(catobs,ex.([\"Hello\",\"world\",\"from\",\"Prague\"]))","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Because it produces ProductNode, missing values are delegated to leaf extractors.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex(missing)","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"MultipleRepresentation together with handling of missing values enables JsonGrinder to deal with JSONs with non-stable schema.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"Minimalistic example of such non-stable schema can be json which sometimes has string and sometimes has array of numbers under same key. Let's create appropriate MultipleRepresentation (although in real-world usage most suitable MultipleRepresentation is proposed based on observed data in suggestextractor):","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ex = MultipleRepresentation((ExtractString(), ExtractArray(ExtractScalar(Float32))));\ne_hello = ex(\"Hello\")\ne_hello[:e1].data\ne_hello[:e2].data\ne_123 = ex([1,2,3])\ne_123[:e1].data\ne_123[:e2].data\ne_2 = ex([2])\ne_2[:e1].data\ne_2[:e2].data\ne_world = ex(\"world\")\ne_world[:e1].data\ne_world[:e2].data","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"in this example we can see that every time one representation is always missing, and the other one contains data.","category":"page"},{"location":"exfunctions/#ExtractEmpty","page":"Extractors overview","title":"ExtractEmpty","text":"","category":"section"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"As mentioned in earlier, ExtractEmpty is a type used to extract observation with 0 samples. There is singleton extractempty which can be used to obtain instance of instance of ExtractEmpty type. StatsBase.nobs(ex(JsonGrinder.extractempty)) == 0 is required to hold for every extractor in order to work correctly.","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"All above-mentioned extractors are able to extract this, as we can see here","category":"page"},{"location":"exfunctions/","page":"Extractors overview","title":"Extractors overview","text":"ExtractString()(JsonGrinder.extractempty)\nExtractString()(JsonGrinder.extractempty) |> nobs\nExtractCategorical([\"A\",\"B\"])(JsonGrinder.extractempty)\nExtractCategorical([\"A\",\"B\"])(JsonGrinder.extractempty) |> nobs\nExtractScalar()(JsonGrinder.extractempty)\nExtractScalar()(JsonGrinder.extractempty) |> nobs\nExtractArray(ExtractString())(JsonGrinder.extractempty)\nExtractArray(ExtractString())(JsonGrinder.extractempty) |> nobs\nExtractDict(Dict(:a => ExtractScalar(),\n\t:b => ExtractString(),\n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))(JsonGrinder.extractempty)\nExtractDict(Dict(:a => ExtractScalar(),\n\t:b => ExtractString(),\n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))(JsonGrinder.extractempty) |> nobs","category":"page"},{"location":"extractors/#Creating-an-Extractor","page":"Creating extractors","title":"Creating an Extractor","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor is responsible for converting json to Mill structures. The main design idea is that the extractor for a whole json is created by composing (sub-)extractors while reflecting the JSON structure. This composability is achieved by the commitment of each extractor returning a subtype of Mill.AbstractDataNode. Extractor can be any function, but to ensure a composability, it is should be a subtype of AbstractExtractor, which means all of them are implemented as functors (also because they contain parameters).","category":"page"},{"location":"extractors/#Manual-creation-of-extractors","page":"Creating extractors","title":"Manual creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The simplest way to create a custom extractor is the compose it from provided extractor functions. Imagine for example json file as follows.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"name\": \"Karl\",\n \"siblings\": [\"Gertruda\", \"Heike\", \"Fritz\"],\n \"hobby\": [\"running\", \"pingpong\"],\n \"age\": 21\n}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"A corresponding extractor might look like","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"using JsonGrinder, Mill, JSON #hide\nex = ExtractDict(Dict(\n\t:name => ExtractString(),\n\t:siblings => ExtractArray(ExtractString()),\n\t:hobby => ExtractArray(ExtractCategorical([\"running\", \"swimming\",\"yoga\"])),\n\t:age => ExtractScalar(),\n))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Notice, how the composability of extractors simplifies the desing and allow to reflect the same feature of JSON documents.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Applying the extractor ex on the above json yields the corresponding Mill structure.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"s = JSON.parse(\"{\\\"name\\\" : \\\"Karl\\\",\n \\\"siblings\\\" : [\\\"Gertruda\\\", \\\"Heike\\\", \\\"Fritz\\\"],\n \\\"hobby\\\" : [\\\"running\\\", \\\"pingpong\\\"],\n \\\"age\\\" : 21\n}\")\nex(s)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The list of all extractors that we have found handy during our experiments and are part of JsonGrinder can be found in Extractors overview.","category":"page"},{"location":"extractors/#Semi-automatic-creation-of-extractors","page":"Creating extractors","title":"Semi-automatic creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Manually creating extractors is boring and error-prone process. Function suggestextractor(schema) tries to simplify this, since creation of most of the extractors is straightforward, once the schema is known.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"This is especially true for Dict and Arrays, while extractors for leaves can be tricky, as one needs to decide, if the leaf should be represented as a Scalar and String or as Categorical variable.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"suggestextractor(schema, settings) uses a simple heuristic (described below) for choosing reasonable extractors, but it can make errors. It is therefore highly recommended to check the proposed extractor manually, if it makes sense. A typical error, especially if schema is created from a small number of samples, is that some variable is treated as a Categorical, while it should be String / Scalar.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor for Dict can be configured to use either ExtractDict or ExtractKeyAsField based on properties number of keys in schema.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor for Array is not configurable, as we do not feel the pressure to so, as there does not seems to be much to do.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"JsonGrinder.suggestextractor(schema, settings = NamedTuple())","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"allows to pass following parameters inside the settings argument","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors\nkeyasfield\nmincountkey","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors allows to pass your own heuristic and rules for handling scalars.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"By default, it's settings = (; scalar_extractors = default_scalar_extractor()).","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"key_as_field is an Int parameter which configures how Dicts are extracted. If number of unique keys in dict is >= key_as_field, ExtractKeyAsField is used, otherwise ExtractDict is used.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"By default, it's settings = (; key_as_field = 500).","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"minkountkey is an Int parameter which allows you to skip sparse keys in Dict to avoid creation of unnecessarily large model. minkountkey contains minimum number of observations of the key in schema to be included in extractor. All keys, whose updated field in schema for specific key is > minkountkey are included in resulting ExtractDict. This settings applies only to Dicts which are not consideted to be \"key as field\". If a certain Dict is considered to be extracted by ExtractKeyAsField, minkountkey does not apply to it.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"By default, it's settings = (; minkountkey = 0), thus no keys are omitted by default.","category":"page"},{"location":"extractors/#Scalars","page":"Creating extractors","title":"Scalars","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors is a list of tuples, where the first is a condition and the second is a function creating the extractor in case of a true. The default heuristic is following and you can adjust according to your liking.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"function default_scalar_extractor()\n\t[\n\t(e -> length(keys(e)) <= 100 && (is_intable(e) || is_floatable(e)),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> is_intable(e),\n\t\te -> extractscalar(Int32, e)),\n\t(e -> is_floatable(e),\n\t \te -> extractscalar(FloatType, e)),\n\t# it's important that condition here would be lower than maxkeys\n\t(e -> (keys_len = length(keys(e)); keys_len / e.updated < 0.1 && keys_len < 10000 && !(is_intable(e) || is_floatable(e))),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> true,\n\t\te -> extractscalar(unify_types(e), e)),]\nend","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Note that order matters here, as the extractors are suggested using following logic","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"for (c, ex) in get(settings, :scalar_extractors, default_scalar_extractor())\n\tc(e) && return ex(e)\nend","category":"page"},{"location":"extractors/#Arrays","page":"Creating extractors","title":"Arrays","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for ArrayEntry is most of the time ExtractArray converting Arrays to Mill.BagNodes. The exception is the case, when vectors are of the same length and their items are numbers. In this case, the suggestextractor returns ExtractVector, which treats convert the array to a Mill.ArrayNode, as we believe the array to represent a feature vector.","category":"page"},{"location":"extractors/#Dict","page":"Creating extractors","title":"Dict","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for DictEntry is most of the time ExtractDict converting Dicts to ProductNodes. As mentioned above, there is an excetion. Sometimes, people use Dicts with names of keys being values. For example consider following two jsons","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"a.dll\": [\"f\", \"g\", \"h\"],\n \"b.dll\": [\"a\", \"b\", \"c\"]}\n{\"c.dll\": [\"x\", \"y\", \"z\"]}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"in the case, keys [\"a.dll\",\"b.dll\",\"c.dll\"] are actually values (names of libraries), and arrays are values as well. The dictionary therefore contain an array. If this case is detected, it is suggested to use ExtractKeyAsField, which interprets the above JSON as","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"[{\"key\": \"a.dll\",\n  \"field\": [\"f\", \"g\", \"h\"]},\n {\"key\": \"b.dll\",\n \"field\": [\"a\", \"b\", \"c\"]}\n]\n[{\"key\": \"c.dll\",\n\"field\": [\"x\", \"y\", \"z\"]}]","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"To demonstrate difference between them, let's compare resulting Mill structures.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"s1 = JSON.parse(\"{\\\"a.dll\\\": [\\\"f\\\", \\\"g\\\", \\\"h\\\"],\n \\\"b.dll\\\": [\\\"a\\\", \\\"b\\\", \\\"c\\\"]}\")\ns2 = JSON.parse(\"{\\\"c.dll\\\": [\\\"x\\\", \\\"y\\\", \\\"z\\\"]}\")\nex_dict = ExtractDict(Dict(\n\tSymbol(\"a.dll\") => ExtractArray(ExtractString()),\n\tSymbol(\"b.dll\") => ExtractArray(ExtractString()),\n\tSymbol(\"c.dll\") => ExtractArray(ExtractString()),\n))\nex_key_as_field = ExtractKeyAsField(\n\tExtractString(), ExtractArray(ExtractString()\n))\nex_dict(s1)\nex_key_as_field(s1)\nex_dict(s2)\nex_key_as_field(s2)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"As we can see ExtractKeyAsField extracts data to more sensible structures in this case.","category":"page"},{"location":"extractors/#Modifying-extractor","page":"Creating extractors","title":"Modifying extractor","text":"","category":"section"},{"location":"extractors/#Passing-different-scalar_extractors","page":"Creating extractors","title":"Passing different scalar_extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Let's demonstrate how can we set extraction of all strings to be MultiRepresentation of String and Categorical, where Categorical will have 20 most frequent values. In general, there are 2 approaches:","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"prepending your own extractors to default_scalar_extractor()\nproviding your own function independent on default_scalar_extractor()","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The first case may look as follows:","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"# we import necessary functions\nusing JsonGrinder: is_intable, is_floatable, unify_types, extractscalar\n# define a helper function\ntop_n_keys(e::Entry, n::Int) = map(x->x[1], sort(e.counts |> collect, by=x->x[2], rev=true)[begin:min(n, end)])\n# we call the default extractor inside our\nfunction string_multi_representation_scalar_extractor()\n\tvcat([\n\t(e -> unify_types(sch[:paper_id]) <: String,\n\t\te -> MultipleRepresentation((\n\t\t\tExtractCategorical(top_n_keys(e, 20)),\n\t\t\textractscalar(unify_types(e), e)\n\t\t))\n\t], JsonGrinder.default_scalar_extractor()))\nend\n# call the suggestextractor with out extractors\nsuggestextractor(sch, (; scalar_extractors = string_multi_representation_scalar_extractor()))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The second case may look as follows: Let's take contents default_scalar_extractor() function and modify it","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"# we import necessary functions\nusing JsonGrinder: is_intable, is_floatable, unify_types, extractscalar\n# define a helper function\ntop_n_keys(e::Entry, n::Int) = map(x->x[1], sort(e.counts |> collect, by=x->x[2], rev=true)[begin:min(n, end)])\nfunction string_multi_representation_scalar_extractor()\n\t[\n\t(e -> length(keys(e)) <= 100 && (is_intable(e) || is_floatable(e)),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> is_intable(e),\n\t\te -> extractscalar(Int32, e)),\n\t(e -> is_floatable(e),\n\t \te -> extractscalar(FloatType, e)),\n\t# it's important that condition here would be lower than maxkeys\n\t(e -> (keys_len = length(keys(e)); keys_len / e.updated < 0.1 && keys_len < 10000 && !(is_intable(e) || is_floatable(e))),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> true,\n\t\te -> MultipleRepresentation((\n\t\t\tExtractCategorical(e, 20),\n\t\t\textractscalar(unify_types(e), e)\n\t\t\t)\n\t\t)),]\nend\n# call the suggestextractor with out extractors\nsuggestextractor(sch, (; scalar_extractors = string_multi_representation_scalar_extractor()))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Note that in the first case, the condition for new extractor is evaluated first, but in the latter case, it's the latest condition, so it's used only when the previous ones are not met.","category":"page"},{"location":"extractors/#Manual-modifications-of-extractor","page":"Creating extractors","title":"Manual modifications of extractor","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Because the extractor can be quite big, by default the Base.show shows only structure to depth of 3 and 20 children for each element.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The full extractor can by seen by HierarchicalUtils.printtree(extractor). Usually edge-cases and complex cases are seen only on large schemas and extractors, which don't suit the documentation format. Thus the examination of schema and extractor, and manual modifications are in dedicated example examples/schema_examination.jl which creates schema and extractor based on data in examples/documents. We advice to check it out and try to run it by yourself.","category":"page"},{"location":"developers/#For-developers-and-tweakers","page":"Developers","title":"For developers and tweakers","text":"","category":"section"},{"location":"developers/#Implementing-new-extractor-function","page":"Developers","title":"Implementing new extractor function","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Requirements on an extractor","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The extractor should implemented as a functor (a callable structure) with an abstract supertype JsonGrinder.AbstractExtractor.  \nThe extractor has to return a subtype of Mill.AbstractNode with the correct number of samples.\nThe extractor has to handle missing, typically by delegating this to appropriate Mill structures, (see more details in Handling empty bags).\nThe extractor has to create a sample with zero observations when extractempty is passed as argument.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Let's demonstrate the creation of a new extractor on an extractor, that would represent the sentence as a bag of words.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"using JsonGrinder, Mill\nstruct ExtractSentence{S} <: JsonGrinder.AbstractExtractor\n\tstring2mill::S\nend\n\nExtractSentence() = ExtractSentence(ExtractString())","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for extracting strings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(s::String)\n\tss = String.(split(s, \" \"))\n\tBagNode(e.string2mill(ss), [1:length(ss)])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for handling missing, which creates an empty bag. An empty bag can contain either missing as its child, which can create an explosion of types of extracted samples, or it can signal to extractors underneath to extract a structure with zero observations.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::Missing)\n\tx = Mill.emptyismissing() ? missing : e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, [0:-1])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::JsonGrinder.ExtractEmpty)\n\tx = e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, Mill.AlignedBags(Array{UnitRange{Int64},1}()))\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"And to make the function more error prone, we recommend to treat unknowns as missings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"(e::ExtractSentence)(s) = e(missing)","category":"page"},{"location":"developers/#Handling-empty-bags","page":"Developers","title":"Handling empty bags","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Handling empty bags is (almost) straightforward by creating an empty bag, i.e. BagNode(x, [0:-1]). The fundamental question is, what the x should be? There are two philosophically different ways with different tradeoffs (both are supported).","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"x = missing is the natural approach, since empty bag does not have any instances and the inference (or backprop) on a sample does not need to descend into children. The drawback is that if one is processing a JSONs with sufficiently big schema, each BagNode can potentially create two types –- one with missing and the other with x <: AbstractNode. This will trigger a lot of compilation, which at the moment can take quite some time especially when calculating gradients with Zygote.\nx <: AbstractNode with nobs(x) = 0. In other words, x would be the same type as it is if it contains instances, but it does not any observations. This has the advantage that all extracted samples will be of the same type and therefore there will be only single compilation for inference (and gradients). This is nice, but at the expense of less elegant code and probably small overhead caused by descending into children. This approach also needs a support from extractors, as creating an empty sample might be a bit tricky. As mentioned in preceding section, if an extractor wants its children to extract this special sample with zero observations, it asks them to extract a special singleton JsonGrider.extractempty. See above  (e::ExtractSentence)(::Missing) for an example.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The behavior is controlled by Mill.emptyismissing!() switch, where true means the first approach, false the second.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Every neural network created by Mill can by default always handle both versions, even though it was trained with the other one. Finally, catobs can handle these situations seamlessly as well.","category":"page"},{"location":"automl/#Integrating-with-Hyperopt.jl","page":"AutoML","title":"Integrating with Hyperopt.jl","text":"","category":"section"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"JsonGrinder.jl and Mill.jl went long way to simplify creation of classifiers from data stored in JSONs, but they purposefully skipped the optimization of the architecture, as we authors believe this should be handled by other special-purpose libraries. Below, we show how to use Hyperopt.jl to do this optimization for us. Even though it is far from optimal, we can run it and forget it. The example will be based on DeviceID example, but it is quite oblivious. We start by explaining the core concepts and at the end we will include it into a full-fleged example. ","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"First, we create a simple function, which creates a feed-forward neural networks with input dimenions idim, nlayers number of hidden layers, nneurons number of neurons in hidden and output layer, fun  nonlinearity, and bnfun  nonlinearity ( nothing meanins disabled)","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"function ffnn(idim, nneurons, nlayers, fun, bnfun)\n  c = []\n  for i in 1:nlayers\n    idim = i == 1 ? idim : nneurons\n    push!(c, Dense(idim, nneurons, fun))\n    if bnfun != nothing\n      push!(c, BatchNorm(nneurons, bnfun))\n    end\n  end\n  Chain(c...)\nend","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"In our example, we will use Hyperband algorithm for its simplicity (and hopefully good results). It requires us to define two functions: first initializes the model, the second trains it for predefined number of iterations while supporting warm-start.","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"function evaluatemodel(specimen, nneurons, nlayers, fun, bnfun, η)\n  model = reflectinmodel(specimen, \n    d -> ffnn(d, nneurons, nlayers, fun, bnfun),\n    SegmentedMeanMax, \n    fsm = Dict(\"\" => d -> Chain(ffnn(d, nneurons, nlayers, fun, bnfun)..., Dense(nneurons, 2)))\n    )\n  opt = ADAM(η)\n  evaluatemodel(2000, model, opt)\nend\n\nfunction evaluatemodel(iterations, model, opt)\n  ps = Flux.params(model);\n  train!((x...) -> loss(model, x...), ps, minibatch, opt, iterations)\n  e =  error(validation_set)\n  (e, (model, opt, cby))\nend","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"The call of Hyperband from hyperband.jl, where we prescribed the possible values for each value (for futher details see docs of Hyperopt.jl). (Hyperband does not use the parameter i, therefore I set it to zero. Parameter R determines number of resources, which corresponds to the number of tried confgiurations created by RandomSamples and η determines fraction of distarded solutions (which means that 18 solutions will be discarded in the second step). The invokation of hyperband looks like","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"ho = @hyperopt for i=0,\n            sampler = Hyperband(R=27, η=3, inner=RandomSampler()),\n            nneurons = [8,16,32,64,128],\n            nlayers = [1,2,3],\n            fun = [relu, tanh],\n            # bnfun = [nothing, identity, relu, tanh],\n            bnfun = [nothing],\n            η = [1e-2,1e-3,1e-4]\n  if state === nothing\n    @show (nneurons, nlayers, fun, bnfun, η)\n    res = evaluatemodel(specimen, nneurons, nlayers, fun, bnfun, η)\n  else\n     \n      res = evaluatemodel(3000, state...)\n  end\n  res\nend\n\nmodel, opt = ho.minimizer","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"and we can fine-tune the model","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"final = evaluatemodel(20000, model, opt)\ntrn = = accuracy(model, trnfiles)","category":"page"}]
}
