var documenterSearchIndex = {"docs":
[{"location":"#JsonGrinder.jl","page":"Home","title":"JsonGrinder.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JsonGrinder is a collection of routines that facilitates conversion of JSON documents into structures used by Mill.jl project.","category":"page"},{"location":"#Motivation","page":"Home","title":"Motivation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Imagine that you want to train a classifier on data looking like this","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n  \"services\": [\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 80\n    },\n    {\n      \"protocol\": \"tcp\",\n      \"port\": 443\n    },\n  ],\n  \"ip\": \"192.168.1.109\",\n  \"device_id\": \"2717684b-3937-4644-a33a-33f4226c43ec\",\n  \"upnp\": [\n    {\n      \"device_type\": \"urn:schemas-upnp-org:device:MediaServer:1\",\n      \"services\": [\n        \"urn:upnp-org:serviceId:ContentDirectory\",\n        \"urn:upnp-org:serviceId:ConnectionManager\"\n      ],\n      \"manufacturer\": \"ARRIS\",\n      \"model_name\": \"Verizon Media Server\",\n      \"model_description\": \"Media Server\"\n    }\n  ],\n  \"device_class\": \"MEDIA_BOX\",\n  \"ssdp\": [\n    {\n      \"st\": \"\",\n      \"location\": \"http://192.168.1.109:9098/device_description.xml\",\n      \"method\": \"\",\n      \"nt\": \"upnp:rootdevice\",\n      \"server\": \"ARRIS DIAL/1.7.2 UPnP/1.0 ARRIS Settop Box\",\n      \"user_agent\": \"\"\n    },\n    {\n      \"st\": \"\",\n      \"location\": \"http://192.168.1.109:8091/XD/21e13e66-1dd2-11b2-9b87-44e137a2ec6a\",\n      \"method\": \"\",\n      \"nt\": \"upnp:rootdevice\",\n      \"server\": \"Allegro-Software-RomPager/5.41 UPnP/1.0 ARRIS Settop Box\",\n      \"user_agent\": \"\"\n    },\n   ],\n  \"mac\": \"44:e1:37:a2:ec:c1\"\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the task is to predict the value in key device_class (in this sample it's MEDIA_BOX) from the rest of the JSON.","category":"page"},{"location":"","page":"Home","title":"Home","text":"With most machine learning libraries assuming your data being stored as tensors of a fixed dimension, or a sequence, you will have a bad time. Contrary, JsonGrider.jl assumes your data to be stored in a flexible JSON format and tries to automate most labor using reasonable default, but it still gives you an option to control and tweak almost everything. JsonGrinder.jl is built on top of Mill.jl which itself is built on top of Flux.jl (we do not reinvent the wheel). Although JsonGrinder was designed for JSON files, you can easily adapt it to XML, Protocol Buffers, MessagePack, and other similar structures","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are four steps to create a classifier once you load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create a schema of JSON files (using sch = JsonGrinder.schema).\nCreate an extractor converting JSONs to Mill structures (extractor = suggestextractor(sch))). Schema sch from previous step is very helpful, as it helps to identify, how to convert nodes (Dict, Array) to (Mill.ProductNode and Mill.BagNode) and how to convert values in leaves to (Float32, Vector{Float32}, String, Categorical).\nCreate a model for your JSONs, which can be easily done by (using model = reflectinmodel(sch, extractor,...))\nUse your favourite methods to train the model, it is 100% compatible with Flux.jl tooling.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first two steps are handled by JsonGrinder.jl the third step by Mill.jl and the fourth by a combination of Mill.jl and Flux.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Authors see the biggest advantage in the model being hierarchical and reflecting the JSON structure. Thanks to Mill.jl, it can handle missing values at all levels.","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Our idealized workflow is demonstrated in examples/identification.jl solving device identification challenge looks as follows (for many datasets which fits in memory it suggest just to change the key with labels (:device_class) and names of files):","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, IterTools, Statistics, ThreadTools, StatsBase\nusing JsonGrinder: suggestextractor\nusing Mill: reflectinmodel\n\nsamples = map(readlines(\"/Users/tomas.pevny/Work/Presentations/JuliaMeetup/dataset/train.json\")) do s\n           JSON.parse(s)\n       end;\n\nlabelkey = \"device_class\"\nminibatchsize = 100\niterations = 10_000\nneurons = 20 \t\t# neurons per layer\n\ntargets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\nforeach(i -> delete!(i, \"device_id\"), samples)\n\n#####\n#  Create the schema and extractor\n#####\nsch = schema(samples)\nextractor = suggestextractor(sch)\n\n#####\n#  Convert samples to Mill structure and extract targets\n#####\ndata = tmap(extractor, samples)\nlabelnames = unique(targets)\n\n#####\n#  Create the model\n#####\nmodel = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> SegmentedMeanMax(d),\n\tfsm = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)\n\n#####\n#  Train the model\n#####\nfunction minibatch()\n\tidx = sample(1:length(data), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = map(xy -> labelnames[argmax(model(xy[1]).data[:])] == xy[2], x, y) |> mean\n\ncb = () -> println(\"accuracy = \", accuracy(data, targets))\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))\n\n#####\n#  Classify test data\n#####\ntest_samples = map(JSON.parse, readlines(\"data/dataset/test.json\"))\ntest_data = tmap(extractor, test_samples)\no = Flux.onecold(model(reduce(catobs, test_data)).data)\npredicted_classes = labelnames[o]\n","category":"page"},{"location":"#A-walkthrough-of-the-example","page":"Home","title":"A walkthrough of the example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Include libraries and load the data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Flux, MLDataPattern, Mill, JsonGrinder, JSON, IterTools, Statistics, BenchmarkTools, ThreadTools, StatsBase\nusing JsonGrinder: suggestextractor\nusing Mill: reflectinmodel\n\nsamples = map(readlines(\"train.json\")) do s\n\tJSON.parse(s)\nend;","category":"page"},{"location":"","page":"Home","title":"Home","text":"labelkey = \"device_class\"\nminibatchsize = 100\niterations = 10_000\nneurons = 20 \t\t# neurons per layer","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create labels and remove them from data, such that we do not use them as features. We also remove device_id key, such that we do not predict it","category":"page"},{"location":"","page":"Home","title":"Home","text":"targets = map(i -> i[labelkey], samples)\nforeach(i -> delete!(i, labelkey), samples)\nforeach(i -> delete!(i, \"device_id\"), samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the schema of data","category":"page"},{"location":"","page":"Home","title":"Home","text":"sch = JsonGrinder.schema(samples)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the extractor converting jsons to Mill structure. The suggestextractor is executed below with default setting, but it allows you heavy customization.","category":"page"},{"location":"","page":"Home","title":"Home","text":"extractor = suggestextractor(sch)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Convert jsons to mill data samples.","category":"page"},{"location":"","page":"Home","title":"Home","text":"data = tmap(extractor, samples)\nlabelnames = unique(targets)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Create the model according to the data","category":"page"},{"location":"","page":"Home","title":"Home","text":"model = reflectinmodel(sch, extractor,\n\tk -> Dense(k, neurons, relu),\n\td -> SegmentedMeanMax(d),\n\tfsm = Dict(\"\" => k -> Dense(k, length(labelnames))),\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"individual arguments of reflectinmodel are explained in Mill.jl documentation","category":"page"},{"location":"","page":"Home","title":"Home","text":"Lastly, we define few handy functions and then we start training.","category":"page"},{"location":"","page":"Home","title":"Home","text":"function minibatch()\n\tidx = sample(1:length(data), minibatchsize, replace = false)\n\treduce(catobs, data[idx]), Flux.onehotbatch(targets[idx], labelnames)\nend\n\naccuracy(x,y) = map(xy -> labelnames[argmax(model(xy[1]).data[:])] == xy[2], x, y) |> mean\n\ncb = () -> println(\"accuracy = \", accuracy(data, targets))\nps = Flux.params(model)\nloss = (x,y) -> Flux.logitcrossentropy(model(x).data, y)\nFlux.Optimise.train!(loss, ps, repeatedly(minibatch, iterations), ADAM(), cb = Flux.throttle(cb, 2))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We should see something like","category":"page"},{"location":"","page":"Home","title":"Home","text":"accuracy = 0.09138949331675474\naccuracy = 0.19093012813870755\naccuracy = 0.24213380306013194\naccuracy = 0.28872655683348875\naccuracy = 0.32968949677062825\naccuracy = 0.7267295271647153\naccuracy = 0.8373916347183367\naccuracy = 0.8743480813732601\naccuracy = 0.8886298483749525\naccuracy = 0.9020999550996442\naccuracy = 0.9089213552999689\naccuracy = 0.9155182537215487\naccuracy = 0.920940835146617\naccuracy = 0.926518840880047\naccuracy = 0.9258971436465997\naccuracy = 0.9276931578765586\naccuracy = 0.9289883604462404\naccuracy = 0.9305080647946672\naccuracy = 0.9309225296169654\naccuracy = 0.931526957482817\naccuracy = 0.9333057023451801\naccuracy = 0.9349808310019687\naccuracy = 0.9332884329775843\naccuracy = 0.9330812005664353\naccuracy = 0.9359997236901184\naccuracy = 0.9372431181570131\naccuracy = 0.9357924912789694\naccuracy = 0.9347390598556281\naccuracy = 0.9369840776430767\naccuracy = 0.9368286533347149","category":"page"},{"location":"","page":"Home","title":"Home","text":"accuracy rising and obtaining over 93% on training set quite quickly.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Last part is inference on test data","category":"page"},{"location":"","page":"Home","title":"Home","text":"test_samples = map(JSON.parse, readlines(\"data/dataset/test.json\"))\ntest_data = tmap(extractor, test_samples)\no = Flux.onecold(model(reduce(catobs, test_data)).data)\npredicted_classes = labelnames[o]","category":"page"},{"location":"","page":"Home","title":"Home","text":"predicted_classes contains the predictions for our test set.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can look at individual samples. For instance, test_samples[2] is","category":"page"},{"location":"","page":"Home","title":"Home","text":"{\n    \"mac\":\"64:b5:c6:66:2b:ab\",\n    \"ip\":\"192.168.1.46\",\n    \"dhcp\":[\n        {\n            \"paramlist\":\"1,3,6,15,28,33\",\n            \"classid\":\"\"\n        }\n    ],\n    \"device_id\":\"addb3142-6b4a-4aef-9d00-ce7ab250c05c\"\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"and the corresponding classification is","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> predicted_classes[2]\n\"GENERIC_IOT\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"if you want to see the probability distribution, it can be obtained by applying softmax to the output of the network.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> softmax(model(test_data[2]).data)\n13×1 Array{Float32,2}:\n 0.0015072504\n 0.009823966\n 0.00017151577\n 0.00082577823\n 0.86119044\n 0.017357541\n 0.0006594112\n 0.0073490166\n 0.020295186\n 0.006199604\n 0.010532198\n 0.06407002\n 1.791575f-5","category":"page"},{"location":"","page":"Home","title":"Home","text":"so we can see that the probability that given sample is GENERIC_IOT is ~86% (in 5th element of array).","category":"page"},{"location":"","page":"Home","title":"Home","text":"This concludes a simple classifier for JSON data.","category":"page"},{"location":"","page":"Home","title":"Home","text":"But keep in mind the framework is general and given its ability to embed hierarchical data into fixed-size vectors, it can be used for classification, regression, and various other ML tasks.","category":"page"},{"location":"api/#API-Documentation","page":"API Documentation","title":"API Documentation","text":"","category":"section"},{"location":"api/","page":"API Documentation","title":"API Documentation","text":"Modules = [JsonGrinder]\nOrder   = [:function, :type, :constant]","category":"page"},{"location":"api/#Base.delete!-Tuple{JsonGrinder.JSONEntry,AbstractString,AbstractString}","page":"API Documentation","title":"Base.delete!","text":"Deletes field at the specified path from the schema sch. For instance, the following: \tdelete!(schema, \".field.subfield.[]\", \"x\") deletes the field x from schema at: \tschema.childs[:field].childs[:subfield].items.childs\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.merge-Tuple{Vararg{JsonGrinder.DictEntry,N} where N}","page":"API Documentation","title":"Base.merge","text":"Dispatch of Base.merge on JsonGrinder.JSONEntry structures. Allows to merge multiple schemas to single one.\n\nmerge(es::Entry...)\nmerge(es::DictEntry...)\nmerge(es::ArrayEntry...)\nmerge(es::MultiEntry...)\nmerge(es::JsonGrinder.JSONEntry...)\n\nit can be used to distribute calculation of schema across multiple workers to merge their partial results into bigger one.\n\nExample\n\nIf we want to calculate schema from e.g. array of jsons in a distributed manner, if we have jsons array and , we can do it using\n\nusing ThreadsX\nThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, length(jsons) ÷ Threads.nthreads()))\n\nor\n\nusing ThreadTools\nmerge(tmap(schema, Threads.nthreads(), Iterators.partition(jsons, length(jsons) ÷ Threads.nthreads()))\n\nor, if you like to split it into multiple jobs and having them processed by multiple threads, it can look like\n\nusing ThreadTools\nmerge(tmap(schema, Threads.nthreads(), Iterators.partition(jsons, 1_000))\n\nwhere we split array to smaller array of size 1k and let all available threads create partial schemas.\n\nIf your data is too large to fit into ram, following approach works well also with filenames and similar other ways to process large data.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.extractscalar-Union{Tuple{Type{T}}, Tuple{T}, Tuple{Type{T},Any}, Tuple{Type{T},Any,Any}, Tuple{Type{T},Any,Any,Any}} where T<:AbstractString","page":"API Documentation","title":"JsonGrinder.extractscalar","text":"extractscalar(Type{String}, n = 3, b = 256, m = 2053)\n\nrepresents strings as ngrams with\n\nn (the degree of ngram),\nb base of string,\nm modulo on index of the token to reduce dimension\n\nextractscalar(Type{Number}, m = 0, s = 1)\n\nextracts number subtracting m and multiplying by s\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.generate_html-Tuple{JsonGrinder.DictEntry}","page":"API Documentation","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(file_name, sch::DictEntry; max_vals=100, max_len=1_000)\n\nexports schema to HTML including CSS style and JS allowing to expand / hide sub-parts of schema, countmaps, and lengthmaps.\n\nArguments\n\nmax_vals controls maximum number of exported values in countmap\nmax_len controls maximum number of exported lengts of arrays\nfile_name a name of file to save HTML with schema\n\nReturn\n\nIf provided filename, it does not return anything. If not, it returns the generated HTML+CSS+JS as a String.\n\nExample\n\nYou can either open the html file in any browser, or open it directly using ElectronDisplay\n\nusing ElectronDisplay\nusing ElectronDisplay: newdisplay\ngenerated_html = generate_html(sch, max_vals = 100)\ndisplay(newdisplay(), MIME{Symbol(\"text/html\")}(), generated_html)\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.newentry-Tuple{Dict}","page":"API Documentation","title":"JsonGrinder.newentry","text":"newentry(v)\n\ncreates new entry describing json according to the type of v\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.prune_json-Tuple{Any,JsonGrinder.Entry}","page":"API Documentation","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nRemoves keys from json which are not part of the schema.\n\nExample\n\njulia> using JSON\n\njulia> j1 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1, \\\"b\\\": 1}}\");\n\njulia> j2 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1}}\");\n\njulia> sch = JsonGrinder.schema([j1,j2])\n[Dict] (updated = 2)\n  ├── a: [Scalar - Int64], 1 unique values, updated = 2\n  └── b: [Dict] (updated = 2)\n           ├── a: [Scalar - Int64], 1 unique values, updated = 2\n           └── b: [Scalar - Int64], 1 unique values, updated = 1\n\njulia> j3 = Dict(\"a\" => 4, \"b\" => Dict(\"a\"=>1), \"c\" => 1, \"d\" => 2)\nDict{String,Any} with 4 entries:\n  \"c\" => 1\n  \"b\" => Dict(\"a\"=>1)\n  \"a\" => 4\n  \"d\" => 2\n\njulia> JsonGrinder.prune_json(j3, sch)\nDict{Any,Any} with 2 entries:\n  \"b\" => Dict{Any,Any}(\"a\"=>1)\n  \"a\" => 4\n\nso the JsonGrinder.prune_json removes keys c and d.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.schema-Tuple{AbstractArray,Function}","page":"API Documentation","title":"JsonGrinder.schema","text":"schema(samples::AbstractArray{<:Dict})\nschema(samples::AbstractArray{<:AbstractString})\nschema(samples::AbstractArray, map_fun::Function)\nschema(map_fun::Function, samples::AbstractArray)\n\ncreates schema from an array of parsed or unparsed JSONs.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.suggestextractor","page":"API Documentation","title":"JsonGrinder.suggestextractor","text":"\tsuggestextractor(e::DictEntry, settings = NamedTuple())\n\n\tcreate convertor of json to tree-structure of `DataNode`\n\n\t`e` top-level of json hierarchy, typically returned by invoking schema\n\t`settings.mincount` contains minimum repetition of the key to be included into\n\tthe extractor (if missing it is equal to zero)\n\t`settings.key_as_field` of the number of keys exceeds this value, it is assumed that\n\tkeys contains a value, which means that they will be treated as strings.\n\t`settings` can be any container supporting `get` function\n\n\n\n\n\n","category":"function"},{"location":"api/#JsonGrinder.update!-Union{Tuple{T}, Tuple{JsonGrinder.Entry{T},Number}} where T<:Number","page":"API Documentation","title":"JsonGrinder.update!","text":"\tfunction update!(a::Entry, v)\n\n\tupdates the entry when seeing value v\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.updatemaxkeys!-Tuple{Int64}","page":"API Documentation","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of leaves in JSON. Default value is 10_000.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.updatemaxlen!-Tuple{Int64}","page":"API Documentation","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum length of string values in statistics of nodes in JSON. Default value is 10_000. Longer strings will be trimmed and their length and hash will be appended to retain the uniqueness. This is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#JsonGrinder.ArrayEntry","page":"API Documentation","title":"JsonGrinder.ArrayEntry","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend\n\nkeeps statistics about an array entry in JSON.\n\nitems is typeof Entry or nothing and keeps statistics about the elements of the array\nl keeps histogram of message length\nupdated counts how many times the struct was updated.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.Entry","page":"API Documentation","title":"JsonGrinder.Entry","text":"mutable struct Entry <: JSONEntry\n\tcounts::Dict{Any,Int}\n\tupdated::Int\nend\n\nKeeps statistics about scalar values of a one key and also about items inside a key\n\ncounts counts how many times given value appeared (at most max_keys is held)\nupdated counts how many times the entry was updated\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractArray","page":"API Documentation","title":"JsonGrinder.ExtractArray","text":"struct ExtractArray{T}\n\titem::T\nend\n\nConvert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.\n\nExamples\n\njulia> ec = ExtractArray(ExtractCategorical(2:4));\n\njulia> ec([2,3,1,4]).data\nMill.ArrayNode{Mill.MaybeHotMatrix{Int64,Array{Int64,1},Int64,Bool},Nothing}:\n  true  false  false  false\n false   true  false  false\n false  false  false   true\n false  false   true  false\n\njulia> es = ExtractArray(ExtractScalar());\n\njulia> es([2,3,4])\nBagNode with 1 obs\n  └── ArrayNode(1×3 Array, Float32) with 3 obs\n\njulia> es([2,3,4]).data\nMill.ArrayNode{Array{Float32,2},Nothing}:\n 2.0f0  3.0f0  4.0f0\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractCategorical","page":"API Documentation","title":"JsonGrinder.ExtractCategorical","text":"ExtractCategorical(s::Entry)\nExtractCategorical(s::UnitRange)\nExtractCategorical(s::Vector)\n\nConverts a single item to a one-hot encoded vector. Converts array of items into matrix of one-hot encoded columns. There is always alocated an extra element for a unknown value. If passed missing, returns column of missing values.\n\nExamples\n\njulia> e = ExtractCategorical(2:4);\n\njulia> e([2,3,1,4]).data\n4×4 Mill.MaybeHotMatrix{Int64,Array{Int64,1},Int64,Bool}:\n 1  0  0  0\n 0  1  0  0\n 0  0  0  1\n 0  0  1  0\n\njulia> e([1,missing,5]).data\n4×3 Mill.MaybeHotMatrix{Union{Missing, Int64},Array{Union{Missing, Int64},1},Int64,Union{Missing, Bool}}:\n false  missing  false\n false  missing  false\n false  missing  false\n  true  missing   true\n\njulia> e(4).data\n4×1 Mill.MaybeHotMatrix{Int64,Array{Int64,1},Int64,Bool}:\n 0\n 0\n 1\n 0\n\njulia> e(missing).data\n4×1 Mill.MaybeHotMatrix{Missing,Array{Missing,1},Int64,Missing}:\n missing\n missing\n missing\n missing\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractDict","page":"API Documentation","title":"JsonGrinder.ExtractDict","text":"struct ExtractDict\n\tdict::Dict{Symbol,Any}\nend\n\nextracts all items in dict and return them as a Mill.ProductNode. If a key is missing in extracted dict, nothing is passed to the child extractors.\n\nExamples\n\njulia> e = ExtractDict(Dict(:a=>ExtractScalar(Float32, 2, 3), :b=>ExtractCategorical(1:5)))\nDict\n  ├── a: Float32\n  └── b: Categorical d = 6\n\njulia> res1 = e(Dict(\"a\"=>1, \"b\"=>1))\nProductNode with 1 obs\n  ├── a: ArrayNode(1×1 Array, Float32) with 1 obs\n  └── b: ArrayNode(6×1 MaybeHotMatrix, Bool) with 1 obs\n\njulia> res1[:a].data\n1×1 Array{Float32,2}:\n -3.0\n\njulia> res1[:b].data\n6×1 Mill.MaybeHotMatrix{Int64,Array{Int64,1},Int64,Bool}:\n 1\n 0\n 0\n 0\n 0\n 0\n\njulia> res2 = e(Dict(\"a\"=>0))\nProductNode with 1 obs\n  ├── a: ArrayNode(1×1 Array, Float32) with 1 obs\n  └── b: ArrayNode(6×1 MaybeHotMatrix, Missing) with 1 obs\n\njulia> res2[:a].data\n1×1 Array{Float32,2}:\n -6.0\n\njulia> res2[:b].data\n6×1 Mill.MaybeHotMatrix{Missing,Array{Missing,1},Int64,Missing}:\n missing\n missing\n missing\n missing\n missing\n missing\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractKeyAsField","page":"API Documentation","title":"JsonGrinder.ExtractKeyAsField","text":"struct ExtractKeyAsField{S,V} <: AbstractExtractor\n\tkey::S\n\titem::V\nend\n\nextracts all items in `vec` and in `other` and return them as a ProductNode.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractOneHot","page":"API Documentation","title":"JsonGrinder.ExtractOneHot","text":"ExtractOneHot(ks, k, v)\n\nConverts a Vector of `Dict` items to one-hot encoding by using key\n`k` to identify a name of item out of `ks` and values\nof key `v` as values.\n\njulia> samples = [\"{\"name\": \"a\", \"count\" : 1}\",\n\t\t\"{\"name\": \"b\", \"count\" : 2}\",];\njulia> samples = JSON.parse.(samples);\njulia> e = ExtractOneHot([\"a\",\"b\"], \"name\", \"count\");\njulia> e(samples).data\n3×1 SparseArrays.SparseMatrixCSC{Int64,Int64} with 2 stored entries:\n  [1, 1]  =  1\n  [2, 1]  =  2\n\nIf `v` is equal to `nothing`, then it boils down to one-hot encoding\n\njulia> e = ExtractOneHot([\"a\",\"b\"], \"name\", nothing);\njulia> e(samples).data\n3×1 SparseArrays.SparseMatrixCSC{Int64,Int64} with 2 stored entries:\n  [1, 1]  =  1\n  [2, 1]  =  1\n\nIf there is key in the data which is not known (it was not part of `vs`),\nthan it is assigned to an special designed key serving as \"unknown`\n\njulia> samples = JSON.parse.([\"{\"name\": \"c\", \"count\" : 1}\"]);\njulia> e = ExtractOneHot([\"a\",\"b\"], \"name\", nothing);\njulia> e(samples).data\n3×1 SparseArrays.SparseMatrixCSC{Bool,Int64} with 1 stored entry:\n  [3, 1]  =  1\n\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractScalar","page":"API Documentation","title":"JsonGrinder.ExtractScalar","text":"struct ExtractScalar{T}\n\tc::T\n\ts::T\nend\n\nExtracts a numerical value, centred by subtracting c and scaled by multiplying by s. Strings are converted to numbers.\n\nThe extractor returns ArrayNode{Matrix{Union{Missing, Int64}},Nothing} or it subtypes. If passed missing, it extracts missing values which Mill understands and can work with.\n\nIt can be created also using extractscalar(Float32, 5, 2)\n\nExample\n\njulia> ExtractScalar(Float32, 2, 3)(1)\nMill.ArrayNode{Array{Float32,2},Nothing}:\n -3.0f0\n\njulia> ExtractScalar(Float32, 2, 3)(missing)\nMill.ArrayNode{Array{Missing,2},Nothing}:\n missing\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractString","page":"API Documentation","title":"JsonGrinder.ExtractString","text":"struct ExtractString{T} <: AbstractExtractor\n\tn::Int\n\tb::Int\n\tm::Int\nend\n\nRepresents String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.ExtractVector","page":"API Documentation","title":"JsonGrinder.ExtractVector","text":"struct ExtractVector{T}\n\titem::Int\nend\n\nrepresents an array of a fixed length, typically a feature vector of numbers of type T\n\njulia> sc = ExtractVector(4)\njulia> sc([2,3,1,4]).data\n3×1 Array{Float32,2}:\n 2.0\n 3.0\n 1.0\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.MultiEntry","page":"API Documentation","title":"JsonGrinder.MultiEntry","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{Any}\nend\n\nsupport for JSON which does not adhere to a fixed type. Container for multiple types of entry which are observed on the same place in JSON.\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.MultipleRepresentation","page":"API Documentation","title":"JsonGrinder.MultipleRepresentation","text":"MultipleRepresentation(extractors::Tuple)\n\ncrate a `ProductNode` where each item is the json part\nprocessed by all extractors in the order\n\n\n\n\n\n","category":"type"},{"location":"api/#JsonGrinder.extractempty","page":"API Documentation","title":"JsonGrinder.extractempty","text":"extractempty\nA singleton of type [`ExtractEmpty`](@ref) is used to signal \ndownstream extractors that they should extract an Empty Array\n\n\n\n\n\n","category":"constant"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"using Mill\nusing StatsBase: nobs","category":"page"},{"location":"hierarchical/#HierarchicalUtils.jl","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"","category":"section"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"JsonGrinder.jl uses HierarchicalUtils.jl which brings a lot of additional features.","category":"page"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"using HierarchicalUtils","category":"page"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"<!– todo: finish this: We can find them programmatically by running","category":"page"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"julia> filter(e->sch[e] isa JsonGrinder.MultiEntry, list_traversal(sch))\n2-element Array{String,1}:\n \"E\"\n \"c\"","category":"page"},{"location":"hierarchical/","page":"HierarchicalUtils.jl","title":"HierarchicalUtils.jl","text":"and we see that sch[\"E\"] and sch[\"c\"] are indeed MultiEntry. todo: přidat příklad s HUtils a 2 jsony, hledáním MultiEntry podle TypeIteratoru  and take inspiration from HUtils section in Mill.kl –>","category":"page"},{"location":"citation/#Citation","page":"Citation","title":"Citation","text":"","category":"section"},{"location":"citation/","page":"Citation","title":"Citation","text":"For citing, please use the following entry:","category":"page"},{"location":"citation/","page":"Citation","title":"Citation","text":"@misc{Mill2018,\n    author = {Tomáš Pevný and Matěj Račinský},\n    title = {{JsonGrinder.jl}},\n    year = 2019,\n    howpublished = \"\\url{https://github.com/pevnak/JsonGrinder.jl}\"\n}","category":"page"},{"location":"schema/#Schema","page":"Schema","title":"Schema","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"The schema helps to understand the structure of JSON files, by which we understand the types of nodes (Dict, Array, Values) and frequency of occurrences of values and lengths of arrays. The schema also holds statistics about how many times the node has been present. All this information is taken into the account by suggestextractor function, which takes a schema and using few reasonable heuristic, suggests an extractor, which convert jsons to Mill structure. The schema might be also useful for formats with enforced schema to collect statistics on leaves.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The main function to create schema is schema, which accepts a list of (unparsed) JSONs and producing schema. Schema can be always updated to reflect new JSONs and allow streaming by update! function. Moreover, schema accepts an optional argument, a function converting an element of an array to a JSON. This a function creating schema from all jsons in a dictionary can look like","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"schema(readdir(\"jsons\", join = true)) do s\n\topen(s,\"r\") do fio\n\t\tread(fio, String)\n\tend |> JSON.parse\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"schema function has following default behavior: If passed array of strings, it consideres them to be filenames and passes each element as an argument to JSON.parse function.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"A schema can be further updated by calling function update!(sch, json). Schemas can be merged using the overloaded merge function, which facilitates distributed creation of schema following map-reduce paradigm.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema can be saved in html by generate_html allowing their interactive exploration. Calling generate_html(filename, sch) will generate self-contained file with HTML+CSS+JS. The generated visualization is interactive, implemented using VanillaJS.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema assumes the root of each JSON is dictionary.","category":"page"},{"location":"schema/#Implementation-details","page":"Schema","title":"Implementation details","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"Statistics are collected in a hierarchical structure reflecting the structured composed of DictEntry, ArrayEntry, and Entry. These structures reflect those in JSON: Dict, Array, and Value (either String or a Number). Sometimes, data are stored in JSONs not adhering to a stable schema, which happens if one key have children of different type. An example of such would be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\": [1,2,3]}\n{\"a\": {\"b\": 1}}\n{\"a\": \"hello\"}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"For such cases, we have introduced additional JSONEntry, a MultiEntry, but we discourage to rely on this feature and recommend to adapt JSONs to have stable schema (if possible). This can be achieved by modifying each sample before it's passed into the schema.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Each subtype of JSONEntry implements the update! function, which recursively updates the schema.","category":"page"},{"location":"schema/#Entry","page":"Schema","title":"Entry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct Entry{T} <: JSONEntry\n\tcounts::Dict{T,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Entry keeps information about leaf-values (e.g. \"a\" = 3) (strings or numbers) in JSONs. It consists of two statistics","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"updated counts how many times the leaf in a given position in JSON was observed,\ncounts counts how many times a particular value of that leaf was observed.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To keep counts dictionary from becoming too large, once its length exceeds JsonGrinder.max_keys (default is 10_000), then the new values will be dropped. This value can be changed by JsonGrinder.updatemaxkeys!(some_higher_value), but of course the new limit will be applied only to newly processed values, so it's advised to set it in the beginning of your scripts.","category":"page"},{"location":"schema/#ArrayEntry","page":"Schema","title":"ArrayEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct ArrayEntry <: JSONEntry\n\titems\n\tl::Dict{Int,Int}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ArrayEntry keeps information about arrays (e.g. \"a\": [1,2,3,4]). Statistics about individual items of the array are deferred to item, which can be <:JSONEntry. l keeps histogram of lengths of arrays, and updated is number of times an array has been observed in particular place in JSON.","category":"page"},{"location":"schema/#DictEntry","page":"Schema","title":"DictEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct DictEntry <: JSONEntry\n\tchilds::Dict{Symbol, Any}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"defers all statistics about its children to them, and the only statistic is again a counter updated about number of observations. Fields childs contains all keys which were observed in specific Dictionary and their corresponding <:JSONEntry values with statistics about values observed under given key.","category":"page"},{"location":"schema/#MultiEntry","page":"Schema","title":"MultiEntry","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"mutable struct MultiEntry <: JSONEntry\n\tchilds::Vector{JSONEntry}\n\tupdated::Int\nend","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"is a failsafe for cases, where the schema is not stable. For example in following two JSONs","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"{\"a\": \"Hello\"}\n{\"a\": [\"Hello\",\" world\"]}","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"the type of a value of a key \"a\" is String, whereas in the second it is \"Vector\". The JsonGrinder will deal with this by first creating an Entry, since the value is scalar, and upon encountering the second JSON, it will replace Entry with MultiEntry having Entry and ArrayEntry as children (this is the reason why entries are declared mutable).","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"While JsonGrinder can deal with non-stable jsons, it is strongly discouraged as it might have negative effect on the performance.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Usefulness of such feature comes into play also when you don't know if your schema is stable or not. In that case, you can calculate the schema, and then search for MultiEntry nodes.","category":"page"},{"location":"schema/#Illustrative-example","page":"Schema","title":"Illustrative example","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"Let's say we have following jsons. We take them and create a schema.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"using JSON, JsonGrinder\njsons = [\n       \"\"\"{\"a\": \"Hello\", \"b\":{\"c\":1, \"d\":1}}\"\"\",\n       \"\"\"{\"a\": [\"Hi\", \"Julia\"], \"b\":{\"c\":1, \"d\":[1,2,3]}}\"\"\",\n       \"\"\"{\"a\": \"World\", \"b\":{\"c\":2, \"d\":2}}\"\"\",\n]\nsch = schema(JSON.parse, jsons)","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"you can visualize schema by","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> display(sch)\n[Dict] (updated = 3)\n  ├── a: [MultiEntry] (updated = 3)\n  │        ├── 1: [Scalar - String], 2 unique values, updated = 2\n  │        └── 2: [List] (updated = 1)\n  │                 ⋮\n  └── b: [Dict] (updated = 3)\n           ├── c: [Scalar - Int64], 2 unique values, updated = 3\n           └── d: [MultiEntry] (updated = 3)\n                    ⋮","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"which shows only reasonable part.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"To see whole schema, we can use printtree(ds; htrunc=Inf, vtrunc=Inf, trav=true) from HierarchicalUtils.jl which prints the whole schema, together with identifiers of individual nodes:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> printtree(sch; htrunc=Inf, vtrunc=Inf, trav=true)\n[Dict] (updated = 3) [\"\"]\n  ├── a: [MultiEntry] (updated = 3) [\"E\"]\n  │        ├── 1: [Scalar - String], 2 unique values, updated = 2 [\"I\"]\n  │        └── 2: [List] (updated = 1) [\"M\"]\n  │                 └── [Scalar - String], 2 unique values, updated = 2 [\"O\"]\n  └── b: [Dict] (updated = 3) [\"U\"]\n           ├── c: [Scalar - Int64], 2 unique values, updated = 3 [\"Y\"]\n           └── d: [MultiEntry] (updated = 3) [\"c\"]\n                    ├── 1: [Scalar - Int64], 2 unique values, updated = 2 [\"d\"]\n                    └── 2: [List] (updated = 1) [\"e\"]\n                             └── [Scalar - Int64], 3 unique values, updated = 3 [\"eU\"]","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Strings at the end of each row can be used as a key to access individual elements of the schema. To learn more about HierarchicalUtils.jl check their docs or section about HierarchicalUtils.jl in Mill.jl documentation","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"Here, we see that we have 2 MultiEntry, thus 2 type instabilities in our jsons. The first MultiEntry (key \"E\") has 2 children: Entry and ArrayEntry.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The sch[\"E\"].updated is 3, because value under key a in json has been observed 3 times. The sch[\"I\"].updated is 2, because string value was seen 2 times under a. As expected, we can see","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"I\"].counts\nDict{String,Int64} with 2 entries:\n  \"Hello\" => 1\n  \"World\" => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"and in the ArrayEntry we can see sch[\"M\"].updated is 1, because array has been observed once in key a. The freqency of lengths is following:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"M\"].l\nDict{Int64,Int64} with 1 entry:\n  2 => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"because we have observed one array of length 2. sch[\"M\"].items is Entry.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"The Entry (can be accessed by sch[\"M\"].items or by sch[\"O\"]) has fields with following values:","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"sch[\"O\"].updated is 2, because we have observed 2 elements in array under key a.  ","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"counts is","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"julia> sch[\"O\"].counts\nDict{String,Int64} with 2 entries:\n\"Hi\"    => 1\n\"Julia\" => 1","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"which corresponds to individual elements of an array we have observed.","category":"page"},{"location":"schema/#Extra-functions","page":"Schema","title":"Extra functions","text":"","category":"section"},{"location":"schema/","page":"Schema","title":"Schema","text":"While schema can be printed to REPL, it can contain quite a lot of information. Therefore JsonGrinder.generate_html exports it to HTML, where parts can be expanded at wish.","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.generate_html","category":"page"},{"location":"schema/#JsonGrinder.generate_html","page":"Schema","title":"JsonGrinder.generate_html","text":"generate_html(sch::DictEntry; max_vals=100, max_len=1_000)\ngenerate_html(file_name, sch::DictEntry; max_vals=100, max_len=1_000)\n\nexports schema to HTML including CSS style and JS allowing to expand / hide sub-parts of schema, countmaps, and lengthmaps.\n\nArguments\n\nmax_vals controls maximum number of exported values in countmap\nmax_len controls maximum number of exported lengts of arrays\nfile_name a name of file to save HTML with schema\n\nReturn\n\nIf provided filename, it does not return anything. If not, it returns the generated HTML+CSS+JS as a String.\n\nExample\n\nYou can either open the html file in any browser, or open it directly using ElectronDisplay\n\nusing ElectronDisplay\nusing ElectronDisplay: newdisplay\ngenerated_html = generate_html(sch, max_vals = 100)\ndisplay(newdisplay(), MIME{Symbol(\"text/html\")}(), generated_html)\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"Schema supports merging using Base.merge, which facilitates parallel computation of schemas. An example might be","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"ThreadsX.mapreduce(schema, merge, Iterators.partition(jsons, div(length(jsons), Threads.nthreads())))","category":"page"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.prune_json","category":"page"},{"location":"schema/#JsonGrinder.prune_json","page":"Schema","title":"JsonGrinder.prune_json","text":"prune_json(json, schema)\n\nRemoves keys from json which are not part of the schema.\n\nExample\n\njulia> using JSON\n\njulia> j1 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1, \\\"b\\\": 1}}\");\n\njulia> j2 = JSON.parse(\"{\\\"a\\\": 4, \\\"b\\\": {\\\"a\\\":1}}\");\n\njulia> sch = JsonGrinder.schema([j1,j2])\n[Dict] (updated = 2)\n  ├── a: [Scalar - Int64], 1 unique values, updated = 2\n  └── b: [Dict] (updated = 2)\n           ├── a: [Scalar - Int64], 1 unique values, updated = 2\n           └── b: [Scalar - Int64], 1 unique values, updated = 1\n\njulia> j3 = Dict(\"a\" => 4, \"b\" => Dict(\"a\"=>1), \"c\" => 1, \"d\" => 2)\nDict{String,Any} with 4 entries:\n  \"c\" => 1\n  \"b\" => Dict(\"a\"=>1)\n  \"a\" => 4\n  \"d\" => 2\n\njulia> JsonGrinder.prune_json(j3, sch)\nDict{Any,Any} with 2 entries:\n  \"b\" => Dict{Any,Any}(\"a\"=>1)\n  \"a\" => 4\n\nso the JsonGrinder.prune_json removes keys c and d.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxkeys!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxkeys!","page":"Schema","title":"JsonGrinder.updatemaxkeys!","text":"updatemaxkeys!(n::Int)\n\nlimits the maximum number of keys in statistics of leaves in JSON. Default value is 10_000.\n\n\n\n\n\n","category":"function"},{"location":"schema/","page":"Schema","title":"Schema","text":"JsonGrinder.updatemaxlen!","category":"page"},{"location":"schema/#JsonGrinder.updatemaxlen!","page":"Schema","title":"JsonGrinder.updatemaxlen!","text":"updatemaxlen!(n::Int)\n\nlimits the maximum length of string values in statistics of nodes in JSON. Default value is 10_000. Longer strings will be trimmed and their length and hash will be appended to retain the uniqueness. This is due to some strings being very long and causing the schema to be even order of magnitute larger than needed.\n\n\n\n\n\n","category":"function"},{"location":"exfunctions/#Extractor-functions","page":"Extractor functions","title":"Extractor functions","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Below, we first describe extractors of values (i.e. lists of JSON tree), then proceed to description of extractors of Array and Dict, and finish with some specials.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extractors of scalar values are arguably the most important, but also fortunatelly the most undersood ones. They control, how values are converted to a Vector (or generally tensor) for the neural networks. For example they control, if number should be represented as a number, or as one-hot encoded categorical variable. Similarly, it constrols how String should be treated, although we admit to natively support on ngrams. Recall ","category":"page"},{"location":"exfunctions/#Numbers","page":"Extractor functions","title":"Numbers","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractScalar{T}\n\tc::T\n\ts::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extract a numerical value, centred by subtracting c and scaled by multiplying by s.  Strings are converted to numbers. The extractor returnes ArrayNode{Matrix{T}}  with a single row. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"using JsonGrinder, Mill, JSON #hide\ne = ExtractScalar(Float32, 0.5, 4.0)\ne(\"1\").data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Strings","page":"Extractor functions","title":"Strings","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractString{T}\n\tdatatype::Type{T}\n\tn::Int\n\tb::Int\n\tm::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Represent String as n-grams (NGramMatrix from Mill.jl) with base b and modulo m.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractString()\ne(\"Hello\")","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Categorical","page":"Extractor functions","title":"Categorical","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractCategorical{V,I} <: AbstractExtractor\n\tkeyvalemap::Dict{V,I}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Converts a single item to a one-hot encoded vector. For a safety, there is always an  extra item reserved for an unknown value. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e = ExtractCategorical([\"A\",\"B\",\"C\"])\ne([\"A\",\"B\",\"C\",\"D\"]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"missing value is extracted as a missing value, as it is automatically handled downstream by Mill.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(missing)","category":"page"},{"location":"exfunctions/#Array-(Lists-/-Sets)","page":"Extractor functions","title":"Array (Lists / Sets)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractArray{T}\n\titem::T\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Convert array of values to a Mill.BagNode with items converted by item. The entire array is assumed to be a single bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc = ExtractArray(ExtractCategorical([\"A\",\"B\",\"C\"]))\nsc([\"A\",\"B\",\"C\",\"D\"])","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Empty arrays are represented as an empty bag.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"sc([]).bags","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The data of empty bag can be either missing or a empty sample, which is more convenient as it makes all samples of the same type, which is nicer to AD. This behavior is controlled by Mill.emptyismissing. The extractor of a BagNode can signal to child extractors to extract a sample with zero observations using a special singleton JsonGrinder.extractempty. For example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(true)\nsc([]).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Mill.emptyismissing!(false)\nsc([]).data","category":"page"},{"location":"exfunctions/#Dict","page":"Extractor functions","title":"Dict","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractDict\n\tdict::Dict{Symbol,Any}\nend\n","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Extracts all items in dict and return them as a ProductNode. Key in dict corresponds to keys in JSON. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = ExtractDict(Dict(:a => ExtractScalar(), \n\t:b => ExtractString(), \n\t:c => ExtractCategorical([\"A\",\"B\"]),\n\t:d => ExtractArray(ExtractString())))\nex(Dict(:a => \"1\",\n\t:b => \"Hello\",\n\t:c => \"A\",\n\t:d => [\"Hello\", \"world\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Missing keys are replaced by missing and handled by child extractors.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex(Dict(:a => \"1\",\n\t:c => \"A\"))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Describe extractempty to signal that we need to extract empty variable","category":"page"},{"location":"exfunctions/#Specials","page":"Extractor functions","title":"Specials","text":"","category":"section"},{"location":"exfunctions/#ExtractKeyAsField","page":"Extractor functions","title":"ExtractKeyAsField","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered uses structure to hold an array for named lists (or other types). Having computer security background a prototypical example is storing a list of DLLs with a corresponding list of imported function in a single structure. For example a JSON","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"{ \"foo.dll\" : [\"print\",\"write\", \"open\",\"close\"],\n  \"bar.dll\" : [\"send\", \"recv\"]\n}","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"should be better written as ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\"key\" = \"foo.dll\",\n  \"item\" = [\"print\",\"write\", \"open\",\"close\"]},\n  {\"key = \"bar.dll\",\n  \"item\" = [\"send\", \"recv\"]}\n]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"JsonGrinder tries to detect these cases, as they are typically manisfested by Dicts with excessively large number of keys in a schema. The detection logic of this case in suggestextractor(e::DictEntry) is simple, if the number of keys is greater than settings.key_as_field = 500.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is simple as well. For the case above, it would look like ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"s = JSON.parse(\"{ \\\"foo.dll\\\" : [\\\"print\\\",\\\"write\\\", \\\"open\\\",\\\"close\\\"],\n  \\\"bar.dll\\\" : [\\\"send\\\", \\\"recv\\\"]\n}\")\nex = ExtractKeyAsField(ExtractString(),ExtractArray(ExtractString()))\nex(s)","category":"page"},{"location":"exfunctions/#MultipleRepresentation","page":"Extractor functions","title":"MultipleRepresentation","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Provides a dual representation for a single key. For example imagine that are extracting strings with some very freuquently occuring values and a lots of clutter, which might be important and you do not know about it. MultipleRepresentation(extractors::Tuple) contains a Tuple or NamedTuple of extractors and apply them to a single sub-tree in a json. The corresponding Mill structure will contain ProductNode of both representation.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"For example String with Categorical and NGram representation will look like.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"ex = MultipleRepresentation((c = ExtractCategorical([\"Hello\",\"world\"]), s = ExtractString()))\nreduce(catobs,ex.([\"Hello\",\"world\",\"from\",\"Prague\"]))","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"MultipleRepresentation together with handling of missing values enables JsonGrinder to deal with JSONs with non-stable schema.","category":"page"},{"location":"exfunctions/#ExtractOneHot(ks,-k,-v)","page":"Extractor functions","title":"ExtractOneHot(ks, k, v)","text":"","category":"section"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Some JSONs we have encountered encode histograms in a an array containing structures with a name of the bin and its count. In the example below, the name of the bin (further called key) and corresponding count in the bin is called value. In example below, key is equal to name and the value is equal to count.","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1},\n{\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"This histogram is extracted as a BagNode with a wrapped SparseMatrix containing the key-value pairs, each pair in a separate We represent them as SparseMatrices with one line per item for example as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"vs = JSON.parse(\"[{\\\"name\\\": \\\"a\\\", \\\"count\\\" : 1}, {\\\"name\\\": \\\"b\\\", \\\"count\\\" : 2}]\")\ne = ExtractOneHot([\"a\",\"b\"], \"name\", \"count\");\ne(vs).data","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"Notice that the matrix has an extra dimension  reserved for unknown keys. The array is handled as a bag. For example for the above example","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"e(vs)","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"The extractor itself is a structure defined as","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"struct ExtractOneHot{K,I,V} <: AbstractExtractor\n\tk::K\n\tv::V\n\tkey2id::Dict{I,Int}\n\tn::Int\nend","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"where k / v is the name of an entry indetifying key / value, and key2id converts the value of the key to the the index in the sparse array. A constructor ExtractOneHot(ks, k, v) assumes k and v as above and ks being list of key values. ","category":"page"},{"location":"exfunctions/","page":"Extractor functions","title":"Extractor functions","text":"#explain, how to customize conversion of schema to extractors extractors to ","category":"page"},{"location":"extractors/#Creating-extractor","page":"Creating extractors","title":"Creating extractor","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor is responsible for converting json to Mill structures. The main design idea is that the extractor for a whole json is created by composing (sub-)extractors while reflecting the JSON structure. This composability is achieved by the commitment of each extractor returning a subtype of Mill.AbstractDataNode. Extractor can be any function, but to ensure a composability, it is should be a subtype of AbstractExtractor, which means all of them are implemented as functors (also because they contain parameters).","category":"page"},{"location":"extractors/#Manual-creation-of-extractors","page":"Creating extractors","title":"Manual creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The simplest way to create a custom extractor is the compose it from provided extractor functions. Imagine for example json file as follows.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"name\": \"Karl\",\n \"siblings\": [\"Gertruda\", \"Heike\", \"Fritz\"],\n \"hobby\": [\"running\", \"pingpong\"],\n \"age\": 21\n}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"A corresponding extractor might look like","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"using JsonGrinder, Mill, JSON #hide\nex = ExtractDict(Dict(\n\t:name => ExtractString(),\n\t:siblings => ExtractArray(ExtractString()),\n\t:hobby => ExtractArray(ExtractCategorical([\"running\", \"swimming\",\"yoga\"])),\n\t:age => ExtractScalar(),\n\t))","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Notice, how the composability of extractors simplifies the desing and allow to reflect the same feature of JSON documents.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Applying the extractor ex on the above json yield the corresponding Mill structure.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"s = JSON.parse(\"{\\\"name\\\" : \\\"Karl\\\",\n \\\"siblings\\\" : [\\\"Gertruda\\\", \\\"Heike\\\", \\\"Fritz\\\"],\n \\\"hobby\\\" : [\\\"running\\\", \\\"pingpong\\\"],\n \\\"age\\\" : 21\n}\")\nex(s)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"The list of composable extractor function that we have found handy during our experiments are listed in Extractor functions section of the doc.","category":"page"},{"location":"extractors/#Semi-automatic-creation-of-extractors","page":"Creating extractors","title":"Semi-automatic creation of extractors","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Manually creating extractors is boring and error-prone process. Function suggestextractor(schema) tries to simplify this, since creation of most of the extractors is straightforward, once the the schema is known. This is especially true for Dict and Arrays, while extractors for leafs can be tricky, as one needs to decide, if the leaf should be represented as a  Float and String are represented as Categorical variables. suggestextractor(schema) uses a simple heuristic (described below) choosing reasonable extractors, but it can make errors. It is therefore highly recommended to check the proposed extractor manually, if it makes sense. A typical error, especially if schema is created from a small number of samples, is that some variable is treated as a categorical, while it should be String / Float.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"JsonGrinder.suggestextractor(schema, settings::NamedTuple)","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"allows to pass your own heuristic and rules for handling scalars. By default, settings = (scalar_extractors = default_scalar_extractor()). Extractors for Dict and Arrays are not configurable, as we do not feel the pressure to so, as there does not seems to be much to do, but of course there is some dark magic described below.","category":"page"},{"location":"extractors/#Scalars","page":"Creating extractors","title":"Scalars","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"scalar_extractors is a list of tuples, where the first is a condition and the second is a function creating the extractor in case of a true. The default heuristic is following and you can adjust according to your liking.","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"function default_scalar_extractor()\n\t[\n\t# all floatable keys are also intable AFAIK\n\t(e -> length(keys(e)) <= 100 && is_floatable(e),\n\t\te -> ExtractCategorical(keys(e))),\n\t# it's important that condition here would be lower than maxkeys\n\t(e -> (keys_len = length(keys(e)); keys_len / e.updated < 0.1 && keys_len < 10000),\n\t\te -> ExtractCategorical(keys(e))),\n\t(e -> is_intable(e),\n\t\te -> extractscalar(Int32, e)),\n\t(e -> is_floatable(e),\n\t \te -> extractscalar(FloatType, e)),\n\t(e -> true,\n\t\te -> extractscalar(unify_types(e), e)),]\nend","category":"page"},{"location":"extractors/#Arrays","page":"Creating extractors","title":"Arrays","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for ArrayEntry is most of the time ExtractArray converting Arrays to Mill.BagNodes. The exception is the case, when vectors are of the same length and their items are numbers. In this case, the suggestextractor returns ExtractVector, which treats convert the array to a Mill.ArrayNode, as we believe the array to represent a feature vector.","category":"page"},{"location":"extractors/#Dict","page":"Creating extractors","title":"Dict","text":"","category":"section"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"Extractor suggested for DictEntry is most of the time ExtractDict converting Dicts to ProductNodes. Again, there is an excetion. Sometimes, people use Dicts with names of keys being values. For example consider following two jsons","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"{\"a.dll\": [\"f\", \"g\", \"h\"],\n \"b.dll\": [\"a\", \"b\", \"c\"]}\n{\"c.dll\": [\"x\", \"y\", \"z\"]}","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"in the case, keys [\"a.dll\",\"b.dll\",\"c.dll\"] are actually values (names of libraries), and arrays are values as well. The dictionary therefore contain an array. If this case is detected, it is suggested to use ExtractKeyAsField, which interprests the above JSON as","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"[{key = \"a.dll\",\n  field = [\"f\", \"g\", \"h\"]},\n {key = \"b.dll\",\n field = [\"a\", \"b\", \"c\"]}\n]\n[{key = \"c.dll\",\nfield = [\"x\", \"y\", \"z\"]}]","category":"page"},{"location":"extractors/","page":"Creating extractors","title":"Creating extractors","text":"ExtractKeyAsField extractor convert it to Mill.BagNode(Mill.ProductNode((key=..., field=...)))","category":"page"},{"location":"developers/#For-developers-and-tweakers","page":"Developers","title":"For developers and tweakers","text":"","category":"section"},{"location":"developers/#Implementing-new-extractor-function","page":"Developers","title":"Implementing new extractor function","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Requirements on an extractor","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The extractor should implemented as a functor (a callable structure) with an abstract supertype JsonGrinder.AbstractExtractor.  \nThe extractor has to return a subtype of Mill.AbstractNode with the correct number of samples.\nThe extractor has to handle missing, typically by delegating this to appropriate Mill structures.\nThe extractor has to create a sample with zero observations (extractempty).","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Let's demonstrate the creation of a new extractor on an extractor, that would represent the sentence as a bag of words.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"using JsonGrinder, Mill\nstruct ExtractSentence{S} <: JsonGrinder.AbstractExtractor\n\tstring2mill::S\nend\n\nExtractSentence() = ExtractSentence(ExtractString())","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for extracting strings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(s::String)\n\tss = String.(split(s, \" \"))\n\tBagNode(e.string2mill(ss), [1:length(ss)])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Create a function for handling missing, which creates an empty bag. An empty bag can contain either missing as its child, which can create an explosion of types of extracted samples, or it can signal to extractors underneath to extract a structure with zero observations.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::Missing)\n\tx = Mill.emptyismissing() ? missing : e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, [0:-1])\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"function (e::ExtractSentence)(::JsonGrinder.ExtractEmpty)\n\tx = e.strings2mill(JsonGrider.extractempty)\n\tBagNode(x, Mill.AlignedBags(Array{UnitRange{Int64},1}()))\nend","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"And to make the function more error prone, we recommed to treat unknowns as missings","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"(e::ExtractSentence)(s) = e(missing)","category":"page"},{"location":"developers/#Handling-empty-bags","page":"Developers","title":"Handling empty bags","text":"","category":"section"},{"location":"developers/","page":"Developers","title":"Developers","text":"Handling empty bags is (almost) straigtforward by creating an empty bag, i.e. BagNode(x, [0:-1]). The fundamental question is, what the x should be? There are two philosophically different ways with different tradeoffs (both are supported).","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"x = missing is the natural approach, since empty bag does not have any instances and the inference (or backprop) on a sample does not need to descend into children. The drawback is that if one is processing a JSONs with sufficiently big schema, each BagNode can potentially create two types –- one with missing and the other with x <: AbstractNode. This will trigger a lot of compilation, which at the moment can take quite some time especially when calculating gradients with Zygote.\nx <: AbstractNode with nobs(x) = 0. In other words, x would be the same type as it is if it contains instances, but it does not any observations. This has the advantage that all extracted samples will be of the same type and therefore there will be only single compilation for inference (and gradients). This is nice, but at the expense of less elegant code and probably small overhead caused by descending into childrens. This approach also needs a support from extractors, as creating an empty sample might be a bit tricky. As mentioned in preceding section, if an extractor wants its children to extract this special sample with zero observations, it asks them to extract a special singleton JsonGrider.extractempty. See above  (e::ExtractSentence)(::Missing) for an example.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"The behavior is controled by Mill.emptyismissing!() switch, where true means the first approach, false the second.","category":"page"},{"location":"developers/","page":"Developers","title":"Developers","text":"Every neural network created by Mill can by default always handle both versions, even though it was trained with the other one. Finally, catobs can handle these situations seamlessly as well.","category":"page"},{"location":"automl/#Integrating-with-Hyperopt.jl","page":"AutoML","title":"Integrating with Hyperopt.jl","text":"","category":"section"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"JsonGrinder.jl and Mill.jl went long way to simplify creation of classifiers from data stored in JSONs, but they purposefully skipped the optimization of the architecture, as we authors believe this should be handled by other special-purpose libraries. Below, we show how to use Hyperopt.jl to do this optimization for us. Even though it is far from optimal, we can run it and forget it. The example will be based on DeviceID example, but it is quite oblivious. We start by explaining the core concepts and at the end we will include it into a full-fleged example. ","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"First, we create a simple function, which creates a feed-forward neural networks with input dimenions idim, nlayers number of hidden layers, nneurons number of neurons in hidden and output layer, fun  nonlinearity, and bnfun  nonlinearity ( nothing meanins disabled)","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"function ffnn(idim, nneurons, nlayers, fun, bnfun)\n  c = []\n  for i in 1:nlayers\n    idim = i == 1 ? idim : nneurons\n    push!(c, Dense(idim, nneurons, fun))\n    if bnfun != nothing\n      push!(c, BatchNorm(nneurons, bnfun))\n    end\n  end\n  Chain(c...)\nend","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"In our example, we will use Hyperband algorithm for its simplicity (and hopefully good results). It requires us to define two functions: first initializes the model, the second trains it for predefined number of iterations while supporting warm-start.","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"function evaluatemodel(specimen, nneurons, nlayers, fun, bnfun, η)\n  model = reflectinmodel(specimen, \n    d -> ffnn(d, nneurons, nlayers, fun, bnfun),\n    SegmentedMeanMax, \n    fsm = Dict(\"\" => d -> Chain(ffnn(d, nneurons, nlayers, fun, bnfun)..., Dense(nneurons, 2)))\n    )\n  opt = ADAM(η)\n  evaluatemodel(2000, model, opt)\nend\n\nfunction evaluatemodel(iterations, model, opt)\n  ps = Flux.params(model);\n  train!((x...) -> loss(model, x...), ps, minibatch, opt, iterations)\n  e =  error(validation_set)\n  (e, (model, opt, cby))\nend","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"The call of Hyperband from hyperband.jl, where we prescribed the possible values for each value (for futher details see docs of Hyperopt.jl). (Hyperband does not use the parameter i, therefore I set it to zero. Parameter R determines number of resources, which corresponds to the number of tried confgiurations created by RandomSamples and η determines fraction of distarded solutions (which means that 18 solutions will be discarded in the second step). The invokation of hyperband looks like","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"ho = @hyperopt for i=0,\n            sampler = Hyperband(R=27, η=3, inner=RandomSampler()),\n            nneurons = [8,16,32,64,128],\n            nlayers = [1,2,3],\n            fun = [relu, tanh],\n            # bnfun = [nothing, identity, relu, tanh],\n            bnfun = [nothing],\n            η = [1e-2,1e-3,1e-4]\n  if state === nothing\n    @show (nneurons, nlayers, fun, bnfun, η)\n    res = evaluatemodel(specimen, nneurons, nlayers, fun, bnfun, η)\n  else\n     \n      res = evaluatemodel(3000, state...)\n  end\n  res\nend\n\nmodel, opt = ho.minimizer","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"and we can fine-tune the model","category":"page"},{"location":"automl/","page":"AutoML","title":"AutoML","text":"final = evaluatemodel(20000, model, opt)\ntrn = = accuracy(model, trnfiles)","category":"page"}]
}
