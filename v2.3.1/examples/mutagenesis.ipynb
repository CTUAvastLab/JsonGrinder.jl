{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mutagenesis Example\n",
    "Following example demonstrates learning to [predict the mutagenicity on Salmonella typhimurium](https://relational.fit.cvut.cz/dataset/Mutagenesis) (dataset is stored in json format [in MLDatasets.jl](https://juliaml.github.io/MLDatasets.jl/stable/datasets/Mutagenesis/) for your convenience)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by installing JsonGrinder and few other packages we need for the example.\n",
    "Julia Ecosystem follows philosophy of many small single-purpose composable packages\n",
    "which may be different from e.g. python where we usually use fewer larger packages."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: The Pkg REPL mode is intended for interactive use only, and should not be used from scripts. It is recommended to use the functional API instead.\n",
      "└ @ Pkg.REPLMode /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.7/Pkg/src/REPLMode/REPLMode.jl:377\n",
      "     Cloning git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "    Updating git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "    Updating registry at `~/.julia/registries/General.toml`\n",
      "   Resolving package versions...\n",
      "┌ Warning: The active manifest file at `/home/runner/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml` has an old format that is being maintained.\n",
      "│ To update to the new format run `Pkg.upgrade_manifest()` which will upgrade the format without re-resolving.\n",
      "└ @ Pkg.Types /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.7/Pkg/src/manifest.jl:287\n",
      "    Updating `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Project.toml`\n",
      "  [d201646e] ~ JsonGrinder v2.3.1 `~/work/JsonGrinder.jl/JsonGrinder.jl` ⇒ v2.3.1 `https://github.com/CTUAvastLab/JsonGrinder.jl.git#master`\n",
      "    Updating `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml`\n",
      "  [d201646e] ~ JsonGrinder v2.3.1 `~/work/JsonGrinder.jl/JsonGrinder.jl` ⇒ v2.3.1 `https://github.com/CTUAvastLab/JsonGrinder.jl.git#master`\n",
      "┌ Warning: The active manifest file is an older format with no julia version entry. Dependencies may have been resolved with a different julia version.\n",
      "└ @ ~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml:0\n",
      "Precompiling project...\n",
      "\u001b[33m  ✓ \u001b[39mJsonGrinder\n",
      "  1 dependency successfully precompiled in 15 seconds (188 already precompiled)\n",
      "  \u001b[33m1\u001b[39m dependency precompiled but a different version is currently loaded. Restart julia to access the new version\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "pkg\"add JsonGrinder#master MLDatasets Flux Mill Statistics\""
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "This example is taken from the [CTUAvastLab/JsonGrinderExamples](https://github.com/CTUAvastLab/JsonGrinderExamples/blob/main/mutagenesis/tuned.jl)\n",
    "and heavily commented for more clarity."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we include libraries all necessary libraries"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using JsonGrinder, Mill, Flux, MLDatasets, Statistics, Random"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "we stabilize the seed to obtain same results every run, for pedagogic purposes"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Random.TaskLocalRNG()"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "Random.seed!(42)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define the minibatch size."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 10"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we load the training samples."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x_train, y_train = MLDatasets.Mutagenesis.traindata();"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create the schema of the training data, which is the first important step in using the JsonGrinder.\n",
    "This computes both the structure (also known as JSON schema) and histogram of occurrences of individual values in the training data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34m[Dict]\u001b[39m\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39m[Scalar - Float64], 98 unique values\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39m[Scalar - Int64], 1 unique values\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m  ⋮\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31m[List]\u001b[39m\u001b[90m \t# updated = 100\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32m[Dict]\u001b[39m\u001b[90m \t# updated = 2529\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(x_train)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we use it to create the extractor converting jsons to Mill structures.\n",
    "The `suggestextractor` is executed below with default setting, but it allows you heavy customization."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mDict\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mCategorical d = 99\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mCategorical d = 2\n\u001b[34m  ⋮\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mArray of\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mDict\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "extractor = suggestextractor(sch)"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model\n",
    "We create the model reflecting structure of the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductModel ↦ Dense(50 => 10)\u001b[39m\u001b[90m \t# 2 arrays, 510 params, 2.070 KiB\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayModel(Dense(99 => 10))\u001b[90m \t# 2 arrays, 1_000 params, 3.984 KiB\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayModel(Dense(2 => 10))\u001b[90m \t# 2 arrays, 30 params, 200 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayModel(Dense(63 => 10))\u001b[90m \t# 2 arrays, 640 params, 2.578 KiB\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayModel(Dense(3 => 10))\u001b[90m \t# 2 arrays, 40 params, 240 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagModel ↦ BagCount([SegmentedMean(10); SegmentedMax(10)]) ↦ Dense(21 => 10)\u001b[39m\u001b[90m \t# 4 arrays, 240 params, 1.094 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductModel ↦ Dense(31 => 10)\u001b[39m\u001b[90m \t# 2 arrays, 320 params, 1.328 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "encoder = reflectinmodel(sch, extractor)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "this allows us to create model flexibly, without the need to hardcode individual layers.\n",
    "Individual arguments of `reflectinmodel` are explained in [Mill.jl documentation](https://CTUAvastLab.github.io/Mill.jl/stable/manual/reflectin/#Model-Reflection).\n",
    "But briefly: for every numeric array in the sample, model will create a dense layer with `neurons` neurons (20 in this example).\n",
    "For every vector of observations (called bag in Multiple Instance Learning terminology), it will create aggregation function which will take mean, maximum of feature vectors and concatenate them.\n",
    "The `fsm` keyword argument basically says that on the end of the NN, as a last layer, we want 2 neurons `length(labelnames)` in the output layer, not 20 as in the intermediate layers.\n",
    "then we add layer with 2 output of the model at the end of the neural network"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dense(10 => 2) ∘ ProductModel ↦ Dense(50 => 10)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "model = Dense(10, 2) ∘ encoder"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "We convert jsons to mill data samples and prepare list of classes. This classification problem is two-class, but we want to infer it from labels.\n",
    "The extractor is callable, so we can pass it vector of samples to obtain vector of structures with extracted features."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "100-element Vector{Mill.ProductNode{NamedTuple{(:lumo, :inda, :logp, :ind1, :atoms), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000063, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000002, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000003f, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000003, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bonds, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bond_type, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000004, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}}:\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ⋮\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "ds_train = extractor.(x_train)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "Then, we define few handy functions and a loss function, which is logit binary crossentropy in our case.\n",
    "Here we add +1 to labels, because the labels are {0,1} and idxmax of the model output is in the {1,2} range."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "accuracy (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "loss(ds, y) = Flux.Losses.logitbinarycrossentropy(model(ds), Flux.onehotbatch(y .+ 1, 1:2))\n",
    "accuracy(ds, y) = mean(Flux.onecold(model(ds)) .== y .+ 1)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "We prepare the optimizer."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Params([Float32[-0.026599297 0.31268165 … 0.015112174 0.041570194; 0.07317401 0.35801336 … -0.47258484 -0.5491943], Float32[0.0, 0.0], Float32[-0.021358307 0.011042915 … 0.012058655 -0.12661397; -0.15317094 -0.007966665 … -0.1895075 -0.22045441; … ; -0.21869266 -0.08064376 … 0.11733952 0.19284187; 0.012676428 -0.19030786 … -0.059899725 0.10005368], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.48929775 -0.18842651; -0.21674016 0.0628332; … ; -0.14078076 0.2071043; -0.61794806 0.2987844], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.06632891 -0.2691281 … -0.13112901 0.119861856; 0.28235346 -0.2236816 … 0.07369621 0.05193251; … ; 0.2619118 0.09443781 … 0.00561584 0.0068649817; -0.21950115 -0.200245 … -0.01521892 0.17143756], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.37894922 -0.6376908 -0.45976058; 0.13071936 0.40276232 -0.13780044; … ; -0.39515987 -0.17779931 -0.18430126; -0.57551384 0.17398533 0.23547177], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.42498085 -0.31724316 … 0.07426171 0.44446707; -0.19361676 0.46978587 … -0.0063639637 0.36843964; … ; -0.12536265 0.19349262 … 0.0617546 -0.43839884; 0.38676414 0.23731998 … 0.13819249 -0.43784702], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.19880311 -0.5450751 … 0.48038882 -0.35613382; 0.4228791 0.46913278 … 0.49136662 -0.29144108; … ; -0.27131188 0.2624201 … -0.060632583 0.3509381; -0.46337524 -0.3442852 … 0.28963408 -0.026937002], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.23650631 0.24317864 0.4953948 0.17388676; 0.25632867 0.094935775 -0.5746137 -0.60480493; … ; -0.32694912 0.013013459 0.29181594 0.5927176; 0.24567696 0.42797464 0.26571167 -0.5066577], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.29698905 -0.06029414 … -0.224241 0.113249235; 0.34047693 -0.059445675 … 0.3364589 -0.3411427; … ; 0.120215386 -0.18154371 … 0.11691326 -0.14342453; 0.017598253 -0.13178419 … 0.27588 -0.014537446], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.18138763 -0.13181873 … 0.26324645 0.27328756; -0.2535053 -0.19199845 … 0.003820212 -0.20375948; … ; -0.046643928 -0.026498921 … 0.30874366 0.042625204; -0.16170737 -0.23345873 … -0.086265124 0.35003465], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.13108636 -0.35810333 … 0.28631234 0.17426461; 0.096060954 -0.13586852 … -0.20064393 0.17051904; … ; -0.3304684 -0.24985515 … -0.0930408 0.015719684; -0.38592106 0.26219028 … -0.116732605 -0.110535905], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.34361 -0.1757986 … -0.110074945 -0.35574841; 0.2707787 -0.1419396 … 0.34329966 -0.3740286; … ; 0.19883622 -0.37421685 … 0.26291245 0.3494511; -0.30978474 0.05540543 … -0.17189685 -0.056109652], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.08430045 -0.1348708 … -0.32904366 0.034573533; -0.34543124 0.15691672 … -0.039527893 -0.33803463; … ; -0.121361315 0.28855738 … 0.3455894 -0.21867226; 0.07175693 0.110732295 … 0.20974219 -0.22093377], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.40128985 -0.43734375 … -0.32160503 -0.16235423; -0.20740792 0.27612007 … -0.36485407 -0.2774104; … ; 0.0005229825 -0.205212 … -0.32888147 -0.047686648; -0.3207261 0.17391811 … -0.13586459 -0.3874142], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.25542536 0.05810724 … -0.12867136 0.01195611; 0.16091615 0.16768669 … -0.1951181 -0.17668496; … ; 0.044464592 -0.15908515 … -0.15800825 0.17587462; -0.15830451 0.18330446 … 0.14752144 0.30489743], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "opt = AdaBelief()\n",
    "ps = Flux.params(model)"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly we turn our training data to minibatches, and we can start training"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLUtils.DataLoader{Tuple{Vector{Mill.ProductNode{NamedTuple{(:lumo, :inda, :logp, :ind1, :atoms), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000063, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000002, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000003f, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000003, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bonds, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bond_type, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000004, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}}, Vector{Int64}}, Random._GLOBAL_RNG}((Mill.ProductNode{NamedTuple{(:lumo, :inda, :logp, :ind1, :atoms), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000063, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000002, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000003f, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000003, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bonds, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bond_type, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000004, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}[ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode  …  ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode, ProductNode], [1, 1, 0, 1, 1, 1, 1, 1, 1, 1  …  1, 0, 0, 1, 1, 0, 0, 1, 0, 0]), 10, 100, true, true, Random._GLOBAL_RNG())"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "data_loader = Flux.Data.DataLoader((ds_train, y_train), batchsize=BATCH_SIZE, shuffle=true)"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see the accuracy rising and obtaining over 80% quite quickly"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Epoch 1\n",
      "accuracy(ds_train, y_train) = 0.82\n",
      "[ Info: Epoch 2\n",
      "accuracy(ds_train, y_train) = 0.83\n",
      "[ Info: Epoch 3\n",
      "accuracy(ds_train, y_train) = 0.84\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "Flux.@epochs 3 begin\n",
    "    Flux.Optimise.train!(loss, ps, data_loader, opt)\n",
    "    @show accuracy(ds_train, y_train)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify test set\n",
    "The Last part is inference and evaluation on test data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Mill.ProductNode{NamedTuple{(:lumo, :inda, :logp, :ind1, :atoms), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000063, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000002, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000003f, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000003, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bonds, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.BagNode{Mill.ProductNode{NamedTuple{(:element, :bond_type, :charge, :atom_type), Tuple{Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000007, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000004, 1, 2, Vector{UInt32}}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}, Mill.ArrayNode{Matrix{Float32}, Nothing}, Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x0000001d, 1, 2, Vector{UInt32}}, Nothing}}}, Nothing}, Mill.AlignedBags{Int64}, Nothing}}}, Nothing}}:\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ⋮\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode\n ProductNode"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "x_test, y_test = MLDatasets.Mutagenesis.testdata();\n",
    "ds_test = extractor.(x_test)"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "we see that the test set accuracy is also over 80%"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(ds_test, y_test) = 0.8863636363636364\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8863636363636364"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "cell_type": "code",
   "source": [
    "@show accuracy(ds_test, y_test)\n",
    "\n",
    "probs = softmax(model(ds_test))\n",
    "o = Flux.onecold(probs)\n",
    "mean(o .== y_test .+ 1)"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "`pred_classes` contains the predictions for our test set.\n",
    "we see the accuracy is around 75% on test set\n",
    "predicted classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 2\n 1\n 2\n 1\n 1\n 2\n 1\n 1\n 2\n 2\n ⋮\n 2\n 2\n 2\n 2\n 1\n 2\n 2\n 1\n 2"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "cell_type": "code",
   "source": [
    "o"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ground truth classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 2\n 2\n 2\n 1\n 2\n 2\n 1\n 1\n 2\n 2\n ⋮\n 2\n 2\n 2\n 2\n 2\n 2\n 2\n 1\n 2"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "y_test .+ 1"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "probabilities for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×44 Matrix{Float32}:\n 0.00161392  0.66709  0.0494638  0.989868   …  0.0492495  0.702054  0.00384\n 0.998386    0.33291  0.950536   0.0101324     0.95075    0.297946  0.99616"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "probs"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can look at individual samples. For instance, some sample from test set is"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductNode\u001b[39m\u001b[90m \t# 1 obs, 104 bytes\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayNode(99×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayNode(2×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayNode(63×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayNode(3×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagNode\u001b[39m\u001b[90m \t# 1 obs, 136 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductNode\u001b[39m\u001b[90m \t# 24 obs, 64 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "cell_type": "code",
   "source": [
    "ds_test[2]"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "and the corresponding classification is"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "cell_type": "code",
   "source": [
    "y_test[2] + 1"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "if you want to see the probability distribution, it can be obtained by applying `softmax` to the output of the network."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×1 Matrix{Float32}:\n 0.66709\n 0.33291003"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "softmax(model(ds_test[2]))"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "so we can see that the probability that given sample belongs to the first class is > 60%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "kernelspec": {
   "name": "julia-1.7",
   "display_name": "Julia 1.7.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
