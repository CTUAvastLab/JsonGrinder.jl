{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mutagenesis Example\n",
    "Following example demonstrates learning to [predict the mutagenicity on Salmonella typhimurium](https://relational.fit.cvut.cz/dataset/Mutagenesis) (dataset is stored in json format [in MLDatasets.jl](https://juliaml.github.io/MLDatasets.jl/stable/datasets/Mutagenesis/) for your convenience)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we include libraries all necessary libraries"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Installing scipy via the Conda scipy package...\n",
      "[ Info: Running `conda install -q -y scipy` in root environment\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/runner/.julia/conda/3\n",
      "\n",
      "  added / updated specs:\n",
      "    - scipy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB\n",
      "    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB\n",
      "    scipy-1.7.1                |   py39h292c36d_2        16.9 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        17.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.5.0-ha8ba4b0_17\n",
      "  libgfortran4       pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17\n",
      "  scipy              pkgs/main/linux-64::scipy-1.7.1-py39h292c36d_2\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using MLDatasets, JsonGrinder, Flux, Mill, MLDataPattern, Statistics, ChainRulesCore"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we load all samples."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_x, train_y = MLDatasets.Mutagenesis.traindata();\n",
    "test_x, test_y = MLDatasets.Mutagenesis.testdata();"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define some basic parameters for the construction and training of the neural network.\n",
    "Minibatch size is self-explanatory, iterations is number of iterations of gradient descent\n",
    "Neurons is number of neurons in hidden layers for each version of part of the neural network."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "minibatchsize = 100\n",
    "iterations = 5_000\n",
    "neurons = 20"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create the schema of the training data, which is the first important step in using the JsonGrinder.\n",
    "This computes both the structure (also known as JSON schema) and histogram of occurrences of individual values in the training data."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mDict\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mCategorical d = 99\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mCategorical d = 2\n\u001b[34m  ⋮\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mArray of\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mDict\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(train_x)\n",
    "extractor = suggestextractor(sch)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we use it to create the extractor converting jsons to Mill structures.\n",
    "The `suggestextractor` is executed below with default setting, but it allows you heavy customization."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data[1] = ProductNode\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductNode\u001b[39m\u001b[90m \t# 1 obs, 104 bytes\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayNode(99×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayNode(2×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayNode(63×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayNode(3×1 OneHotArray with Bool elements)\u001b[90m \t# 1 obs, 60 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagNode\u001b[39m\u001b[90m \t# 1 obs, 136 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductNode\u001b[39m\u001b[90m \t# 26 obs, 64 bytes\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "train_data = extractor.(train_x)\n",
    "test_data = extractor.(test_x)\n",
    "labelnames = unique(train_y)\n",
    "\n",
    "@show train_data[1]"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34mProductModel ↦ ArrayModel(Dense(100, 2))\u001b[39m\u001b[90m \t# 2 arrays, 202 params, 888 bytes\u001b[39m\n\u001b[34m  ├─── lumo: \u001b[39m\u001b[39mArrayModel(Dense(99, 20, relu))\u001b[90m \t# 2 arrays, 2_000 params, 7.891 KiB\u001b[39m\n\u001b[34m  ├─── inda: \u001b[39m\u001b[39mArrayModel(Dense(2, 20, relu))\u001b[90m \t# 2 arrays, 60 params, 320 bytes\u001b[39m\n\u001b[34m  ├─── logp: \u001b[39m\u001b[39mArrayModel(Dense(63, 20, relu))\u001b[90m \t# 2 arrays, 1_280 params, 5.078 KiB\u001b[39m\n\u001b[34m  ├─── ind1: \u001b[39m\u001b[39mArrayModel(Dense(3, 20, relu))\u001b[90m \t# 2 arrays, 80 params, 400 bytes\u001b[39m\n\u001b[34m  └── atoms: \u001b[39m\u001b[31mBagModel ↦ [SegmentedMean(20); SegmentedMax(20)] ↦ ArrayModel(Dense(40, 20, relu))\u001b[39m\u001b[90m \t# 4 arrays, 860 params, 3.516 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m  └── \u001b[39m\u001b[32mProductModel ↦ ArrayModel(Dense(61, 20, relu))\u001b[39m\u001b[90m \t# 2 arrays, 1_240 params, 4.922 KiB\u001b[39m\n\u001b[34m             \u001b[39m\u001b[31m      \u001b[39m\u001b[32m  ⋮\u001b[39m"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "model = reflectinmodel(sch, extractor,\n",
    "\tlayer -> Dense(layer, neurons, relu),\n",
    "\tbag -> SegmentedMeanMax(bag),\n",
    "\tfsm = Dict(\"\" => layer -> Dense(layer, length(labelnames))),\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model\n",
    "let's define loss and some helper functions"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "#9 (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "loss(x,y) = Flux.logitcrossentropy(inference(x), Flux.onehotbatch(y, labelnames))\n",
    "inference(x::AbstractMillNode) = model(x).data\n",
    "inference(x::AbstractVector{<:AbstractMillNode}) = inference(reduce(catobs, x))\n",
    "accuracy(x,y) = mean(labelnames[Flux.onecold(inference(x))] .== y)\n",
    "loss(xy::Tuple) = loss(xy...)\n",
    "@non_differentiable Base.reduce(catobs, x::AbstractVector{<:AbstractMillNode})\n",
    "cb = () -> begin\n",
    "\ttrain_acc = accuracy(train_data, train_y)\n",
    "\ttest_acc = accuracy(test_data, test_y)\n",
    "\tprintln(\"accuracy: train = $train_acc, test = $test_acc\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "create minibatches"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: train = 0.45, test = 0.29545454545454547\n",
      "accuracy: train = 0.72, test = 0.6818181818181818\n",
      "accuracy: train = 0.81, test = 0.8863636363636364\n",
      "accuracy: train = 0.82, test = 0.8863636363636364\n",
      "accuracy: train = 0.82, test = 0.8863636363636364\n",
      "accuracy: train = 0.82, test = 0.8863636363636364\n",
      "accuracy: train = 0.82, test = 0.8863636363636364\n",
      "accuracy: train = 0.82, test = 0.8863636363636364\n",
      "accuracy: train = 0.83, test = 0.8863636363636364\n",
      "accuracy: train = 0.83, test = 0.8863636363636364\n",
      "accuracy: train = 0.83, test = 0.8863636363636364\n",
      "accuracy: train = 0.83, test = 0.8863636363636364\n",
      "accuracy: train = 0.85, test = 0.8863636363636364\n",
      "accuracy: train = 0.86, test = 0.8863636363636364\n",
      "accuracy: train = 0.86, test = 0.8863636363636364\n",
      "accuracy: train = 0.86, test = 0.8863636363636364\n",
      "accuracy: train = 0.86, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.87, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.89, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.89, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.89, test = 0.8863636363636364\n",
      "accuracy: train = 0.88, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n",
      "accuracy: train = 0.89, test = 0.8863636363636364\n",
      "accuracy: train = 0.9, test = 0.8863636363636364\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "minibatches = RandomBatches((train_data, train_y), size = minibatchsize, count = iterations)\n",
    "Flux.Optimise.train!(loss, Flux.params(model), minibatches, ADAM(), cb = Flux.throttle(cb, 2))"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8863636363636364"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "probs = softmax(inference(test_data))\n",
    "o = Flux.onecold(probs)\n",
    "pred_classes = labelnames[o]\n",
    "mean(pred_classes .== test_y)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "we see the accuracy is around 75% on test set\n",
    "predicted classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 1\n 0\n 1\n 0\n 0\n 1\n 0\n 0\n 1\n 1\n ⋮\n 1\n 1\n 1\n 1\n 0\n 1\n 1\n 0\n 1"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "pred_classes"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ground truth classes for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "44-element Vector{Int64}:\n 1\n 1\n 1\n 0\n 1\n 1\n 0\n 0\n 1\n 1\n ⋮\n 1\n 1\n 1\n 1\n 1\n 1\n 1\n 0\n 1"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "test_y"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "probabilities for test set"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2×44 Matrix{Float32}:\n 0.953016   0.382744  0.953175   0.253781  …  0.946358   0.446038  0.546188\n 0.0469837  0.617256  0.0468252  0.746219     0.0536416  0.553962  0.453812"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "cell_type": "code",
   "source": [
    "probs"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
