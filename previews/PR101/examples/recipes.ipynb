{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recipe Ingredients Example\n",
    "Following example demonstrates prediction of cuisine from set of ingredients.\n",
    "For simplicity, the repo contains small subset of the dataset, the whole dataset and problem description can\n",
    "be found [on this Kaggle page](https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLDatasets, JsonGrinder, Flux, Mill, MLDataPattern, Statistics, ChainRulesCore\n",
    "using JSON"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "start by loading all samples"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 10259,\n",
      "  \"ingredients\": [\n",
      "    \"romaine lettuce\",\n",
      "    \"black olives\",\n",
      "    \"grape tomatoes\",\n",
      "    \"garlic\",\n",
      "    \"pepper\",\n",
      "    \"purple onion\",\n",
      "    \"seasoning\",\n",
      "    \"garbanzo beans\",\n",
      "    \"feta cheese crumbles\"\n",
      "  ],\n",
      "  \"cuisine\": \"greek\"\n",
      "}\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "data_file = \"../../../data/recipes.json\" #!src\n",
    "samples = open(data_file,\"r\") do fid\n",
    "\tVector{Dict}(JSON.parse(read(fid, String)))\n",
    "end\n",
    "JSON.print(samples[1],2)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "create schema of the JSON"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34m[Dict]\u001b[39m\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  ├─────────── id: \u001b[39m\u001b[39m[Scalar - Int64], 10000 unique values\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  ├────── cuisine: \u001b[39m\u001b[39m[Scalar - String], 20 unique values\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31m[List]\u001b[39m\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39m[Scalar - String], 6714 unique values\u001b[90m \t# updated = 428275\u001b[39m"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(samples)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "create extractor and split it into one for loading targets and\n",
    "one for loading data, using custom function to set conditions for using n-gram representation"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×1 Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000015, 1, 2, Vector{UInt32}}, Nothing}:\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n 1\n ⋅\n ⋅\n ⋅\n ⋮\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "delete!(sch.childs,:id)\n",
    "\n",
    "extractor = suggestextractor(sch)\n",
    "extract_data = ExtractDict(deepcopy(extractor.dict))\n",
    "extract_target = ExtractDict(deepcopy(extractor.dict))\n",
    "delete!(extract_target.dict, :ingredients)\n",
    "delete!(extract_data.dict, :cuisine)\n",
    "\n",
    "extract_data(samples[1])\n",
    "extract_target(samples[1])[:cuisine]"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "we convert JSONs to Datasets\n",
    "advised to use all the samples, this is just speedup to demonstrate functionality"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×5000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  1  ⋅  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  1  1  1  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "data = extract_data.(samples[1:5_000])\n",
    "data = reduce(catobs, data)\n",
    "target = extract_target.(samples[1:5_000])\n",
    "target = reduce(catobs, target)[:cuisine].data"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "\tcreate the model according to the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m = reflectinmodel(sch, extract_data,\n",
    "\tlayer -> Dense(layer,20,relu),\n",
    "\tbag -> SegmentedMeanMax(bag),\n",
    "\tfsm = Dict(\"\" => layer -> Dense(layer, size(target, 1))),\n",
    ")\n",
    "\n",
    "@non_differentiable getobs(x::DataSubset{<:ProductNode})"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    " train"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(ProductNode, Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "opt = Flux.Optimise.ADAM()\n",
    "loss(x, y) = Flux.logitcrossentropy(m(x).data, y)\n",
    "loss(x::DataSubset, y) = loss(getobs(x), y)\n",
    "loss(xy::Tuple) = loss(xy...)\n",
    "valdata = data[1:1_000],target[:,1:1_000]\n",
    "data, target = data[1_001:5_000], target[:,1001:5_000]"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "for less recourse-chungry training, we use only part of data for trainng, but it is advised to used all, as i following line:\n",
    "data, target = data[1001:nobs(data)], target[:,1001:size(target,2)]"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: testing the gradient\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "cb = () -> println(\"accuracy = \",mean(Flux.onecold(m(valdata[1]).data) .== Flux.onecold(valdata[2])))\n",
    "ps = Flux.params(m)\n",
    "mean(Flux.onecold(m(data).data) .== Flux.onecold(target))\n",
    "\n",
    "iterations = 20\n",
    "minibatchsize = 4000\n",
    "minibatches = RandomBatches((data, target), size = minibatchsize, count = iterations)\n",
    "\n",
    "@info \"testing the gradient\"\n",
    "loss(first(minibatches))\n",
    "gs = gradient(() -> loss(first(minibatches)), ps)\n",
    "Flux.Optimise.update!(opt, ps, gs)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "feel free to train for longer period of time, this example is learns only 20 iterations, so it runs fast"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.035\n",
      "accuracy = 0.074\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.07125"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "loss(first(minibatches))\n",
    "gs = gradient(() -> loss(first(minibatches)), ps)\n",
    "Flux.Optimise.train!(loss, ps, minibatches, opt, cb = Flux.throttle(cb, 2))\n",
    "\n",
    "#calculate the accuracy\n",
    "mean(Flux.onecold(m(data).data) .== Flux.onecold(target))"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
