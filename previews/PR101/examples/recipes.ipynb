{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recipe Ingredients Example\n",
    "Following example demonstrates prediction of cuisine from set of ingredients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A gentle introduction to creation of neural networks reflexing structure of JSON documents"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook serves as an introduction to `Mill` and `JsonGrinder` libraries.\n",
    "The former provides support for Multi-instance learning problems, their cascades, and their Cartesian product ([see the paper](https://arxiv.org/abs/2105.09107) for theoretical explanation).\n",
    "The latter `JsonGrinder` simplifies processing of JSON documents. It allows to infer schema of JSON documents from which it suggests an extractor to convert JSON document to a `Mill` structure.\n",
    "`JsonGrinder` defines basic set of \"extractors\" converting values of keys to numeric representation (matrices) or to convert them to corresponding structures in `Mill`. Naturally, this set of extractors can be extended.\n",
    "\n",
    "Below, the intended workflow is demonstrated on a simple problem of guessing type of a cuisine from a list of ingrediences.\n",
    "The whole dataset and problem description can be found [on this Kaggle page](https://www.kaggle.com/kaggle/recipe-ingredients-dataset/home).\n",
    "Note that the goal is not to achieve state of the art, but to demonstrate the workflow."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "todo: dodělat, domigrovat z ipynb a ten pak smazat\n",
    "**Caution**\n",
    "To decrease the computational load, we keep locally in the repo only a subset of the whole dataset (39774), size of the minibatch, and size of the validation data.\n",
    "Of course these numbers are useless in practice, and therefore the resulting accuracy is poor.\n",
    "Using all samples (666920), setting minibatch size to 100, and leaving 1000 samples for validation / testing gives you accuracy 0.74 on validation data.\n",
    "\n",
    "We start by installing JsonGrinder and few other packages we need for the example.\n",
    "Julia Ecosystem follows philosophy of many small single-purpose composable packages\n",
    "which may be different from e.g. python where we usually use fewer larger packages."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Updating git-repo `https://github.com/CTUAvastLab/JsonGrinder.jl.git`\n",
      "    Updating git-repo `https://github.com/CTUAvastLab/Mill.jl.git`\n",
      "   Resolving package versions...\n",
      "  No Changes to `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Project.toml`\n",
      "  No Changes to `~/work/JsonGrinder.jl/JsonGrinder.jl/docs/Manifest.toml`\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "pkg\"add JsonGrinder#master Flux Mill#master MLDataPattern Statistics ChainRulesCore JSON\"\n",
    "\n",
    "using JsonGrinder, Flux, Mill, MLDataPattern, Statistics, ChainRulesCore, JSON"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "start by loading all samples"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": 10259,\n",
      "  \"ingredients\": [\n",
      "    \"romaine lettuce\",\n",
      "    \"black olives\",\n",
      "    \"grape tomatoes\",\n",
      "    \"garlic\",\n",
      "    \"pepper\",\n",
      "    \"purple onion\",\n",
      "    \"seasoning\",\n",
      "    \"garbanzo beans\",\n",
      "    \"feta cheese crumbles\"\n",
      "  ],\n",
      "  \"cuisine\": \"greek\"\n",
      "}\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "data_file = \"../../../data/recipes.json\"\n",
    "samples = open(data_file,\"r\") do fid\n",
    "\tVector{Dict}(JSON.parse(read(fid, String)))\n",
    "end\n",
    "JSON.print(samples[1],2)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "create schema of the JSON"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\u001b[34m[Dict]\u001b[39m\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  ├─────────── id: \u001b[39m\u001b[39m[Scalar - Int64], 10000 unique values\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  ├────── cuisine: \u001b[39m\u001b[39m[Scalar - String], 20 unique values\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m  └── ingredients: \u001b[39m\u001b[31m[List]\u001b[39m\u001b[90m \t# updated = 39774\u001b[39m\n\u001b[34m                   \u001b[39m\u001b[31m  └── \u001b[39m\u001b[39m[Scalar - String], 6714 unique values\u001b[90m \t# updated = 428275\u001b[39m"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "sch = JsonGrinder.schema(samples)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "create extractor and split it into one for loading targets and\n",
    "one for loading data, using custom function to set conditions for using n-gram representation"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×1 Mill.ArrayNode{Flux.OneHotArray{UInt32, 0x00000015, 1, 2, Vector{UInt32}}, Nothing}:\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n 1\n ⋅\n ⋅\n ⋅\n ⋮\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅\n ⋅"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "delete!(sch.childs,:id)\n",
    "\n",
    "extractor = suggestextractor(sch)\n",
    "extract_data = ExtractDict(deepcopy(extractor.dict))\n",
    "extract_target = ExtractDict(deepcopy(extractor.dict))\n",
    "delete!(extract_target.dict, :ingredients)\n",
    "delete!(extract_data.dict, :cuisine)\n",
    "\n",
    "extract_data(samples[1])\n",
    "extract_target(samples[1])[:cuisine]"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "we convert JSONs to Datasets\n",
    "advised to use all the samples, this is just speedup to demonstrate functionality"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21×5000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅\n ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  1  ⋅  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  1  1  1  ⋅  1  ⋅  1  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "data = extract_data.(samples[1:5_000])\n",
    "data = reduce(catobs, data)\n",
    "target = extract_target.(samples[1:5_000])\n",
    "target = reduce(catobs, target)[:cuisine].data"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m = reflectinmodel(sch, extract_data,\n",
    "\tlayer -> Dense(layer,20,relu),\n",
    "\tbag -> SegmentedMeanMax(bag),\n",
    "\tfsm = Dict(\"\" => layer -> Dense(layer, size(target, 1))),\n",
    ")\n",
    "\n",
    "@non_differentiable getobs(x::DataSubset{<:ProductNode})"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(ProductNode, Bool[0 0 … 0 0; 0 0 … 1 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "opt = Flux.Optimise.ADAM()\n",
    "loss(x, y) = Flux.logitcrossentropy(m(x).data, y)\n",
    "loss(x::DataSubset, y) = loss(getobs(x), y)\n",
    "loss(xy::Tuple) = loss(xy...)\n",
    "valdata = data[1:1_000],target[:,1:1_000]\n",
    "data, target = data[1_001:5_000], target[:,1001:5_000]"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "for less recourse-chungry training, we use only part of data for trainng, but it is advised to used all, as i following line:\n",
    "data, target = data[1001:nobs(data)], target[:,1001:size(target,2)]"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: testing the gradient\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "cb = () -> println(\"accuracy = \",mean(Flux.onecold(m(valdata[1]).data) .== Flux.onecold(valdata[2])))\n",
    "ps = Flux.params(m)\n",
    "mean(Flux.onecold(m(data).data) .== Flux.onecold(target))\n",
    "\n",
    "iterations = 20\n",
    "minibatchsize = 4000\n",
    "minibatches = RandomBatches((data, target), size = minibatchsize, count = iterations)\n",
    "\n",
    "@info \"testing the gradient\"\n",
    "loss(first(minibatches))\n",
    "gs = gradient(() -> loss(first(minibatches)), ps)\n",
    "Flux.Optimise.update!(opt, ps, gs)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "feel free to train for longer period of time, this example is learns only 20 iterations, so it runs fast"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.034\n",
      "accuracy = 0.067\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "loss(first(minibatches))\n",
    "gs = gradient(() -> loss(first(minibatches)), ps)\n",
    "Flux.Optimise.train!(loss, ps, minibatches, opt, cb = Flux.throttle(cb, 2))"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "calculate the accuracy"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.068"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "mean(Flux.onecold(m(data).data) .== Flux.onecold(target))"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.4",
   "language": "julia"
  }
 },
 "nbformat": 4
}
